{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XYanLI4UCnYjDIJxi-2WUImfJMif6AyX",
      "authorship_tag": "ABX9TyP/0SEj5egNX6nnv+4ZQIPg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/JAK_ML/blob/main/CoGT_MTATFP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# CoGT (need GPU)\n",
        "\n",
        "## Works for Conventional and chemberta\n",
        "\n",
        "## GraphVAE does not work, need to be performed on local env\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eGE5dguNO9hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aa5GFpC1O5xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5036692b-76d2-4b90-dba1-13328c573bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSgPSOSKeer9"
      },
      "outputs": [],
      "source": [
        "# !pip install torch\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "\n",
        "# !pip install torch-geometric==1.7.1\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "!pip install pubchempy --\n",
        "!pip install transformers\n",
        "!pip install cairosvg\n",
        "!pip install varname\n",
        "!pip install Cython\n",
        "!pip install rdkit\n",
        "!pip install molsets\n",
        "!pip install pathlib\n",
        "!pip install xgboost==1.6.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68oDaPC6e5x5",
        "outputId": "f8c0b9b7-71fb-4165-f924-07a7bf93adb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
            "Collecting torch-scatter\n",
            "  Using cached torch_scatter-2.1.1.tar.gz (107 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch\n",
        "# !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "\n",
        "# !pip install torch-geometric==1.7.1\n",
        "# !pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "!pip install pubchempy --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install cairosvg --quiet\n",
        "!pip install varname --quiet\n",
        "!pip install Cython --quiet\n",
        "!pip install rdkit --quiet\n",
        "# !pip install molsets --quiet\n",
        "!pip install pathlib --quiet\n",
        "!pip install xgboost==1.6.1 --quiet\n",
        "!pip install dgllife --quiet\n",
        "# cpu version, usable for calculation\n",
        "!pip install dgl==1.1 --quiet\n",
        "!pip install molvs --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZcrbKzxml4o",
        "outputId": "7f96857a-4b78-459e-e6fa-8f58e82448a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pubchempy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.5/268.5 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.6/51.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pomegranate (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.9/192.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for molvs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dgl cuda version for training using gpu\n",
        "!pip uninstall dgl -y\n",
        "!pip install  dgl -f https://data.dgl.ai/wheels/cu118/repo.html --quiet\n",
        "!pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrZbXsqpMnnE",
        "outputId": "7156f173-0e11-4fd7-e2e4-b2556d8f5dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: dgl 1.1.0\n",
            "Uninstalling dgl-1.1.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/dgl-1.1.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/dgl/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled dgl-1.1.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "import torch\n",
        "print('torch version: ', torch.__version__)\n",
        "print('cuda available: ', torch.cuda.is_available())\n",
        "import dgl\n",
        "print('dgl version: ', dgl.__version__)\n",
        "import dgllife\n",
        "print('dgllife version: ', dgllife.__version__)\n",
        "import rdkit\n",
        "print('rdkit version: ', rdkit.__version__)\n",
        "import molvs\n",
        "print('molvs version: ', molvs.__version__)\n",
        "import matplotlib\n",
        "print('matplotlib version: ', matplotlib.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njwrF23Tm6k2",
        "outputId": "21b03422-93da-4920-d002-e8daa2ab928a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "torch version:  2.0.1+cu118\n",
            "cuda available:  True\n",
            "dgl version:  1.1.0\n",
            "dgllife version:  0.3.2\n",
            "rdkit version:  2023.03.2\n",
            "molvs version:  0.1.1\n",
            "matplotlib version:  3.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/JAK_ML"
      ],
      "metadata": {
        "id": "wrYZw6f_exyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf62347-7195-4e1e-c127-5562fce316f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/JAK_ML\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ],
      "metadata": {
        "id": "LnU6t843gLYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from dgllife.model import model_zoo\n",
        "from dgllife.utils import smiles_to_bigraph\n",
        "from dgllife.utils import AttentiveFPAtomFeaturizer\n",
        "from dgllife.utils import AttentiveFPBondFeaturizer\n",
        "from dgllife.data import MoleculeCSVDataset\n",
        "import dgl\n",
        "import matplotlib\n",
        "import matplotlib.cm as cm\n",
        "from IPython.display import SVG, display\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdDepictor\n",
        "from rdkit.Chem.Draw import rdMolDraw2D\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('use GPU')\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print('use CPU')\n",
        "    device = 'cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpSls8snIC1h",
        "outputId": "0a61dedb-0654-4025-b2d7-e07fbc25c867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_molgraphs(data):\n",
        "    assert len(data[0]) in [3, 4], \\\n",
        "        'Expect the tuple to be of length 3 or 4, got {:d}'.format(len(data[0]))\n",
        "    if len(data[0]) == 3:\n",
        "        smiles, graphs, labels = map(list, zip(*data))\n",
        "        masks = None\n",
        "    else:\n",
        "        smiles, graphs, labels, masks = map(list, zip(*data))\n",
        "\n",
        "    bg = dgl.batch(graphs)\n",
        "    bg.set_n_initializer(dgl.init.zero_initializer)\n",
        "    bg.set_e_initializer(dgl.init.zero_initializer)\n",
        "    labels = torch.stack(labels, dim=0)\n",
        "\n",
        "    if masks is None:\n",
        "        masks = torch.ones(labels.shape)\n",
        "    else:\n",
        "        masks = torch.stack(masks, dim=0)\n",
        "    return smiles, bg, labels, masks"
      ],
      "metadata": {
        "id": "JVyx-U2pIEid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from co_model_JAK import *"
      ],
      "metadata": {
        "id": "ZJJGxk5dgOvU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "9491a5b5-b274-4317-d2ea-72d13dbc2e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ad9794f317d7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mco_model_JAK\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/MyDrive/JAK_ML/co_model_JAK.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/Yimeng-Wang/JAK-MTATFP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTXc3JqOIMDV",
        "outputId": "8490986b-681e-4dc2-cb72-098bbd94e338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'JAK-MTATFP'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 54 (delta 2), reused 14 (delta 2), pack-reused 37\u001b[K\n",
            "Unpacking objects: 100% (54/54), 39.91 MiB | 6.37 MiB/s, done.\n",
            "Updating files: 100% (37/37), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/JAK-MTATFP/MTATFP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSgadMrGISBf",
        "outputId": "7b22416c-346f-419e-d9f7-b8f499ca505d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/JAK-MTATFP/MTATFP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smiles = {}\n",
        "# smiles['test'] = max_len_smi\n",
        "# smiles['remove_k'] = new\n",
        "smiles['MMT3-72'] = 'O=C(NCCC(O)=O)C(C=C1)=CC=C1/N=N/C(C=C2C(O)=O)=CC=C2OCCOC3=CC=C(NC4=NC=C(C)C(NC5=CC=CC(S(NC(C)(C)C)(=O)=O)=C5)=N4)C=C3'\n",
        "smiles['M1'] = 'OCCOC1=CC=C(NC2=NC=C(C)C(NC3=CC=CC(S(N)(=O)=O)=C3)=N2)C=C1'\n",
        "smiles['M2'] = 'OCCOC1=CC=C(NC2=NC=C(C)C(NC3=CC=CC(S(NC(C)(C)C)(=O)=O)=C3)=N2)C=C1'\n",
        "smiles['M3'] = 'OC(COC1=CC=C(NC2=NC=C(C)C(NC3=CC=CC(S(NC(C)(C)C)(=O)=O)=C3)=N2)C=C1)=O'\n",
        "smiles['M4'] = 'O=C(NCCC(O)=O)C(C=C1)=CC=C1/N=N/C(C=C2C(O)=O)=CC=C2OCCOC3=CC=C(NC4=NC=C(C)C(NC5=CC=CC(S(N)(=O)=O)=C5)=N4)C=C3'\n",
        "smiles['M5'] = 'OC1=CC=C(NC2=NC=C(C)C(NC3=CC=CC(S(NC(C)(C)C)(=O)=O)=C3)=N2)C=C1'\n"
      ],
      "metadata": {
        "id": "14NlPQQKgThf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd ../JAK-MTATFP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69kDWEfVIXQ7",
        "outputId": "07b21242-37c9-446f-defc-db0db9d82492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '../MTATFP'\n",
            "/content/drive/MyDrive/JAK-MTATFP/JAK-MTATFP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atom_featurizer = AttentiveFPAtomFeaturizer(atom_data_field='hv')\n",
        "bond_featurizer = AttentiveFPBondFeaturizer(bond_data_field='he')\n",
        "n_feats = atom_featurizer.feat_size('hv')\n",
        "e_feats = bond_featurizer.feat_size('he')\n",
        "\n",
        "dc_listings = pd.read_csv('../MTATFP/Data/JAK_inhibitor_series.csv')\n",
        "extest_datasets = MoleculeCSVDataset(dc_listings,\n",
        "                            smiles_to_graph=smiles_to_bigraph,\n",
        "                            node_featurizer=atom_featurizer,\n",
        "                            edge_featurizer= bond_featurizer,\n",
        "                            smiles_column='SMILES',\n",
        "                            cache_file_path='../MTATFP/Data/jak_extest.bin',\n",
        "                            task_names=['pIC50_JAK1','pIC50_JAK2','pIC50_JAK3','pIC50_TYK2'],\n",
        "                            load=True,init_mask=True\n",
        "                            )\n",
        "\n",
        "extest_loader = DataLoader(extest_datasets,batch_size=256,shuffle=True,collate_fn=collate_molgraphs)\n",
        "print('ExTest sets: ',len(extest_datasets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sH0dvqWIiIz",
        "outputId": "26f50ba4-8f36-4f17-8a36-c1567a994574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading previously saved dgl graphs...\n",
            "ExTest sets:  38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fn = '../MTATFP/Models/MTATFP_jak.pt'\n",
        "model = model_zoo.AttentiveFPPredictor(node_feat_size=n_feats,\n",
        "                                   edge_feat_size=e_feats,\n",
        "                                   num_layers=2,\n",
        "                                   num_timesteps=1,\n",
        "                                   graph_feat_size=300,\n",
        "                                   n_tasks=4,\n",
        "                                    )\n",
        "model.load_state_dict(torch.load(fn,map_location=torch.device(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Npj7r7wIzsZ",
        "outputId": "42c99e3b-7274-4701-f2fd-f69be3347a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def draw(mol_id, dataset, timestep):\n",
        "    smiles, g, label, _ = dataset[mol_id]\n",
        "    g = dgl.batch([g])\n",
        "    atom_feats, bond_feats = g.ndata.pop('hv'), g.edata.pop('he')\n",
        "    preds, atom_weights1 = model(g, atom_feats, bond_feats, get_node_weight=True)\n",
        "    assert timestep < len(atom_weights1)\n",
        "    atom_weights1 = atom_weights1[timestep]\n",
        "    min_value = torch.min(atom_weights1)\n",
        "    max_value = torch.max(atom_weights1)\n",
        "    atom_weights = (atom_weights1 - min_value) / (max_value - min_value)\n",
        "    c=atom_weights.detach().cpu().numpy().flatten().tolist()\n",
        "    norm = matplotlib.colors.Normalize(vmin=0,vmax=(sum(c)/len(c)))\n",
        "    cmap = cm.get_cmap('summer_r')\n",
        "    plt_colors = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
        "    atom_colors = {i: plt_colors.to_rgba(atom_weights[i].data.item()) for i in range(g.number_of_nodes())}\n",
        "    plt_colors._A = []\n",
        "    cb = plt.colorbar(plt_colors)\n",
        "    cb.set_ticks([])\n",
        "\n",
        "\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    rdDepictor.Compute2DCoords(mol)\n",
        "    drawer = rdMolDraw2D.MolDraw2DSVG(300,300)\n",
        "\n",
        "    drawer.SetFontSize(1)\n",
        "    op = drawer.drawOptions().addAtomIndices=True\n",
        "\n",
        "    mol = rdMolDraw2D.PrepareMolForDrawing(mol)\n",
        "    drawer.DrawMolecule(mol,highlightAtoms=range(g.number_of_nodes()),highlightBonds=[],\n",
        "    highlightAtomColors=atom_colors)\n",
        "    drawer.FinishDrawing()\n",
        "    svg = drawer.GetDrawingText()\n",
        "    svg = svg.replace('svg:','')\n",
        "    display(SVG(svg))\n",
        "    return smiles,label,preds,atom_weights"
      ],
      "metadata": {
        "id": "EdwlZcOjI9gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw(0,extest_datasets, 0)"
      ],
      "metadata": {
        "id": "GRar3e9TI_-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python MTATFP_train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc2p13pCKIA8",
        "outputId": "75f7952b-07b5-45c7-bfba-f3c5b1b58c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use GPU\n",
            "Loading previously saved dgl graphs...\n",
            "Loading previously saved dgl graphs...\n",
            "  0% 0/501 [00:00<?, ?it/s]epoch 1/501, training_r2 0.0005, training_loss 0.8310\n",
            "epoch 1/501, validation r2 0.0456, validation loss 0.6505, best validation r2 0.0456\n",
            "  2% 10/501 [00:25<16:52,  2.06s/it]epoch 11/501, training_r2 0.3449, training_loss 0.3896\n",
            "epoch 11/501, validation r2 0.4151, validation loss 0.3440, best validation r2 0.4151\n",
            "  4% 20/501 [00:47<15:50,  1.98s/it]epoch 21/501, training_r2 0.5164, training_loss 0.2861\n",
            "EarlyStopping counter: 1 out of 20\n",
            "epoch 21/501, validation r2 0.5722, validation loss 0.2484, best validation r2 0.5796\n",
            "  5% 27/501 [01:01<15:39,  1.98s/it]EarlyStopping counter: 1 out of 20\n",
            "  6% 30/501 [01:07<15:37,  1.99s/it]epoch 31/501, training_r2 0.6125, training_loss 0.2315\n",
            "epoch 31/501, validation r2 0.6595, validation loss 0.2090, best validation r2 0.6595\n",
            "  6% 31/501 [01:09<15:53,  2.03s/it]EarlyStopping counter: 1 out of 20\n",
            "  7% 33/501 [01:13<15:46,  2.02s/it]EarlyStopping counter: 1 out of 20\n",
            "  7% 34/501 [01:15<15:25,  1.98s/it]EarlyStopping counter: 2 out of 20\n",
            "  7% 35/501 [01:17<15:10,  1.95s/it]EarlyStopping counter: 3 out of 20\n",
            "  8% 38/501 [01:23<15:50,  2.05s/it]EarlyStopping counter: 1 out of 20\n",
            "  8% 39/501 [01:25<15:56,  2.07s/it]EarlyStopping counter: 2 out of 20\n",
            "  8% 40/501 [01:27<16:02,  2.09s/it]epoch 41/501, training_r2 0.6742, training_loss 0.1938\n",
            "epoch 41/501, validation r2 0.6996, validation loss 0.1835, best validation r2 0.6996\n",
            "  9% 43/501 [01:33<15:17,  2.00s/it]EarlyStopping counter: 1 out of 20\n",
            "  9% 45/501 [01:37<14:55,  1.96s/it]EarlyStopping counter: 1 out of 20\n",
            "  9% 46/501 [01:39<15:08,  2.00s/it]EarlyStopping counter: 2 out of 20\n",
            " 10% 48/501 [01:43<15:42,  2.08s/it]EarlyStopping counter: 1 out of 20\n",
            " 10% 50/501 [01:47<15:06,  2.01s/it]epoch 51/501, training_r2 0.7198, training_loss 0.1665\n",
            "EarlyStopping counter: 1 out of 20\n",
            "epoch 51/501, validation r2 0.7136, validation loss 0.1683, best validation r2 0.7213\n",
            " 11% 53/501 [01:53<14:41,  1.97s/it]EarlyStopping counter: 1 out of 20\n",
            " 11% 54/501 [01:55<14:52,  2.00s/it]EarlyStopping counter: 2 out of 20\n",
            " 11% 56/501 [01:59<15:18,  2.06s/it]EarlyStopping counter: 1 out of 20\n",
            " 12% 58/501 [02:03<14:48,  2.00s/it]EarlyStopping counter: 1 out of 20\n",
            " 12% 60/501 [02:07<14:33,  1.98s/it]epoch 61/501, training_r2 0.7578, training_loss 0.1440\n",
            "EarlyStopping counter: 1 out of 20\n",
            "epoch 61/501, validation r2 0.7421, validation loss 0.1547, best validation r2 0.7448\n",
            " 12% 62/501 [02:11<14:40,  2.01s/it]EarlyStopping counter: 1 out of 20\n",
            " 13% 63/501 [02:13<14:54,  2.04s/it]EarlyStopping counter: 2 out of 20\n",
            " 13% 64/501 [02:15<15:08,  2.08s/it]EarlyStopping counter: 3 out of 20\n",
            " 14% 69/501 [02:25<14:22,  2.00s/it]EarlyStopping counter: 1 out of 20\n",
            " 14% 70/501 [02:27<14:28,  2.02s/it]epoch 71/501, training_r2 0.7912, training_loss 0.1246\n",
            "EarlyStopping counter: 2 out of 20\n",
            "epoch 71/501, validation r2 0.7550, validation loss 0.1484, best validation r2 0.7596\n",
            " 14% 71/501 [02:29<14:39,  2.05s/it]EarlyStopping counter: 3 out of 20\n",
            " 14% 72/501 [02:31<14:50,  2.08s/it]EarlyStopping counter: 4 out of 20\n",
            " 15% 73/501 [02:34<15:01,  2.11s/it]EarlyStopping counter: 5 out of 20\n",
            " 15% 74/501 [02:35<14:40,  2.06s/it]EarlyStopping counter: 6 out of 20\n",
            " 15% 75/501 [02:37<14:23,  2.03s/it]EarlyStopping counter: 7 out of 20\n",
            " 16% 79/501 [02:46<14:44,  2.10s/it]EarlyStopping counter: 1 out of 20\n",
            " 16% 80/501 [02:48<14:51,  2.12s/it]epoch 81/501, training_r2 0.8177, training_loss 0.1084\n",
            "EarlyStopping counter: 2 out of 20\n",
            "epoch 81/501, validation r2 0.7524, validation loss 0.1467, best validation r2 0.7620\n",
            " 16% 81/501 [02:50<14:32,  2.08s/it]EarlyStopping counter: 3 out of 20\n",
            " 16% 82/501 [02:52<14:35,  2.09s/it]EarlyStopping counter: 4 out of 20\n",
            " 17% 84/501 [02:56<14:54,  2.15s/it]EarlyStopping counter: 1 out of 20\n",
            " 17% 85/501 [02:58<14:35,  2.11s/it]EarlyStopping counter: 2 out of 20\n",
            " 17% 87/501 [03:03<14:52,  2.16s/it]EarlyStopping counter: 1 out of 20\n",
            " 18% 88/501 [03:05<14:50,  2.16s/it]EarlyStopping counter: 2 out of 20\n",
            " 18% 90/501 [03:09<14:11,  2.07s/it]epoch 91/501, training_r2 0.8361, training_loss 0.0975\n",
            "EarlyStopping counter: 1 out of 20\n",
            "epoch 91/501, validation r2 0.7662, validation loss 0.1381, best validation r2 0.7698\n",
            " 18% 91/501 [03:11<13:59,  2.05s/it]EarlyStopping counter: 2 out of 20\n",
            " 19% 94/501 [03:17<14:18,  2.11s/it]EarlyStopping counter: 1 out of 20\n",
            " 19% 95/501 [03:19<14:29,  2.14s/it]EarlyStopping counter: 2 out of 20\n",
            " 19% 96/501 [03:22<14:27,  2.14s/it]EarlyStopping counter: 3 out of 20\n",
            " 19% 97/501 [03:24<14:11,  2.11s/it]EarlyStopping counter: 4 out of 20\n",
            " 20% 98/501 [03:26<14:01,  2.09s/it]EarlyStopping counter: 5 out of 20\n",
            " 20% 99/501 [03:28<13:50,  2.07s/it]EarlyStopping counter: 6 out of 20\n",
            " 20% 100/501 [03:30<13:42,  2.05s/it]epoch 101/501, training_r2 0.8475, training_loss 0.0909\n",
            "EarlyStopping counter: 7 out of 20\n",
            "epoch 101/501, validation r2 0.7620, validation loss 0.1388, best validation r2 0.7745\n",
            " 20% 101/501 [03:32<13:47,  2.07s/it]EarlyStopping counter: 8 out of 20\n",
            " 20% 102/501 [03:34<13:59,  2.10s/it]EarlyStopping counter: 9 out of 20\n",
            " 21% 103/501 [03:36<14:13,  2.15s/it]EarlyStopping counter: 10 out of 20\n",
            " 21% 105/501 [03:40<13:55,  2.11s/it]EarlyStopping counter: 1 out of 20\n",
            " 21% 106/501 [03:42<13:42,  2.08s/it]EarlyStopping counter: 2 out of 20\n",
            " 21% 107/501 [03:44<13:29,  2.05s/it]EarlyStopping counter: 3 out of 20\n",
            " 22% 108/501 [03:47<13:40,  2.09s/it]EarlyStopping counter: 4 out of 20\n",
            " 22% 109/501 [03:49<13:41,  2.10s/it]EarlyStopping counter: 5 out of 20\n",
            " 22% 110/501 [03:51<13:47,  2.12s/it]epoch 111/501, training_r2 0.8615, training_loss 0.0827\n",
            "EarlyStopping counter: 6 out of 20\n",
            "epoch 111/501, validation r2 0.7744, validation loss 0.1325, best validation r2 0.7795\n",
            " 22% 111/501 [03:53<13:57,  2.15s/it]EarlyStopping counter: 7 out of 20\n",
            " 22% 112/501 [03:55<13:41,  2.11s/it]EarlyStopping counter: 8 out of 20\n",
            " 23% 113/501 [03:57<13:26,  2.08s/it]EarlyStopping counter: 9 out of 20\n",
            " 23% 114/501 [03:59<13:14,  2.05s/it]EarlyStopping counter: 10 out of 20\n",
            " 23% 116/501 [04:03<13:01,  2.03s/it]EarlyStopping counter: 1 out of 20\n",
            " 23% 117/501 [04:05<13:10,  2.06s/it]EarlyStopping counter: 2 out of 20\n",
            " 24% 118/501 [04:07<13:21,  2.09s/it]EarlyStopping counter: 3 out of 20\n",
            " 24% 119/501 [04:10<13:35,  2.13s/it]EarlyStopping counter: 4 out of 20\n",
            " 24% 120/501 [04:12<13:18,  2.10s/it]epoch 121/501, training_r2 0.8644, training_loss 0.0810\n",
            "EarlyStopping counter: 5 out of 20\n",
            "epoch 121/501, validation r2 0.7797, validation loss 0.1336, best validation r2 0.7848\n",
            " 24% 121/501 [04:14<13:06,  2.07s/it]EarlyStopping counter: 6 out of 20\n",
            " 24% 122/501 [04:16<12:56,  2.05s/it]EarlyStopping counter: 7 out of 20\n",
            " 25% 123/501 [04:18<12:48,  2.03s/it]EarlyStopping counter: 8 out of 20\n",
            " 25% 124/501 [04:20<12:41,  2.02s/it]EarlyStopping counter: 9 out of 20\n",
            " 25% 125/501 [04:22<12:52,  2.06s/it]EarlyStopping counter: 10 out of 20\n",
            " 25% 126/501 [04:24<13:02,  2.09s/it]EarlyStopping counter: 11 out of 20\n",
            " 25% 127/501 [04:26<13:10,  2.11s/it]EarlyStopping counter: 12 out of 20\n",
            " 26% 128/501 [04:28<12:56,  2.08s/it]EarlyStopping counter: 13 out of 20\n",
            " 26% 129/501 [04:30<12:44,  2.06s/it]EarlyStopping counter: 14 out of 20\n",
            " 26% 130/501 [04:32<12:37,  2.04s/it]epoch 131/501, training_r2 0.8789, training_loss 0.0724\n",
            "EarlyStopping counter: 15 out of 20\n",
            "epoch 131/501, validation r2 0.7816, validation loss 0.1298, best validation r2 0.7848\n",
            " 26% 131/501 [04:34<12:31,  2.03s/it]EarlyStopping counter: 16 out of 20\n",
            " 26% 132/501 [04:36<12:31,  2.04s/it]EarlyStopping counter: 17 out of 20\n",
            " 27% 134/501 [04:41<13:03,  2.13s/it]EarlyStopping counter: 1 out of 20\n",
            " 27% 135/501 [04:43<13:03,  2.14s/it]EarlyStopping counter: 2 out of 20\n",
            " 27% 136/501 [04:45<12:45,  2.10s/it]EarlyStopping counter: 3 out of 20\n",
            " 28% 138/501 [04:49<12:25,  2.05s/it]EarlyStopping counter: 1 out of 20\n",
            " 28% 139/501 [04:51<12:17,  2.04s/it]EarlyStopping counter: 2 out of 20\n",
            " 28% 140/501 [04:53<12:17,  2.04s/it]epoch 141/501, training_r2 0.8860, training_loss 0.0677\n",
            "EarlyStopping counter: 3 out of 20\n",
            "epoch 141/501, validation r2 0.7825, validation loss 0.1284, best validation r2 0.7863\n",
            " 28% 141/501 [04:55<12:31,  2.09s/it]EarlyStopping counter: 4 out of 20\n",
            " 28% 142/501 [04:57<12:45,  2.13s/it]EarlyStopping counter: 5 out of 20\n",
            " 29% 143/501 [04:59<12:43,  2.13s/it]EarlyStopping counter: 6 out of 20\n",
            " 29% 144/501 [05:02<12:45,  2.14s/it]EarlyStopping counter: 7 out of 20\n",
            " 29% 145/501 [05:04<12:28,  2.10s/it]EarlyStopping counter: 8 out of 20\n",
            " 29% 147/501 [05:08<12:08,  2.06s/it]EarlyStopping counter: 1 out of 20\n",
            " 30% 148/501 [05:10<12:11,  2.07s/it]EarlyStopping counter: 2 out of 20\n",
            " 30% 149/501 [05:12<12:19,  2.10s/it]EarlyStopping counter: 3 out of 20\n",
            " 30% 150/501 [05:14<12:33,  2.15s/it]epoch 151/501, training_r2 0.8921, training_loss 0.0637\n",
            "EarlyStopping counter: 4 out of 20\n",
            "epoch 151/501, validation r2 0.7831, validation loss 0.1285, best validation r2 0.7878\n",
            " 30% 151/501 [05:16<12:26,  2.13s/it]EarlyStopping counter: 5 out of 20\n",
            " 31% 153/501 [05:20<12:00,  2.07s/it]EarlyStopping counter: 1 out of 20\n",
            " 31% 155/501 [05:24<11:48,  2.05s/it]EarlyStopping counter: 1 out of 20\n",
            " 31% 156/501 [05:26<11:53,  2.07s/it]EarlyStopping counter: 2 out of 20\n",
            " 31% 157/501 [05:29<12:04,  2.11s/it]EarlyStopping counter: 3 out of 20\n",
            " 32% 158/501 [05:31<12:15,  2.14s/it]EarlyStopping counter: 4 out of 20\n",
            " 32% 159/501 [05:33<12:05,  2.12s/it]EarlyStopping counter: 5 out of 20\n",
            " 32% 160/501 [05:35<11:50,  2.08s/it]epoch 161/501, training_r2 0.8981, training_loss 0.0603\n",
            "EarlyStopping counter: 6 out of 20\n",
            "epoch 161/501, validation r2 0.7938, validation loss 0.1268, best validation r2 0.7942\n",
            " 32% 161/501 [05:37<11:48,  2.08s/it]EarlyStopping counter: 7 out of 20\n",
            " 32% 162/501 [05:39<11:57,  2.12s/it]EarlyStopping counter: 8 out of 20\n",
            " 33% 163/501 [05:41<12:04,  2.14s/it]EarlyStopping counter: 9 out of 20\n",
            " 33% 164/501 [05:44<12:20,  2.20s/it]EarlyStopping counter: 10 out of 20\n",
            " 33% 166/501 [05:48<12:28,  2.24s/it]EarlyStopping counter: 1 out of 20\n",
            " 33% 167/501 [05:50<12:08,  2.18s/it]EarlyStopping counter: 2 out of 20\n",
            " 34% 168/501 [05:52<11:48,  2.13s/it]EarlyStopping counter: 3 out of 20\n",
            " 34% 169/501 [05:54<11:33,  2.09s/it]EarlyStopping counter: 4 out of 20\n",
            " 34% 170/501 [05:56<11:23,  2.06s/it]epoch 171/501, training_r2 0.9052, training_loss 0.0571\n",
            "EarlyStopping counter: 5 out of 20\n",
            "epoch 171/501, validation r2 0.7842, validation loss 0.1289, best validation r2 0.7948\n",
            " 34% 171/501 [05:58<11:14,  2.04s/it]EarlyStopping counter: 6 out of 20\n",
            " 34% 172/501 [06:00<11:21,  2.07s/it]EarlyStopping counter: 7 out of 20\n",
            " 35% 173/501 [06:03<11:29,  2.10s/it]EarlyStopping counter: 8 out of 20\n",
            " 35% 174/501 [06:05<11:39,  2.14s/it]EarlyStopping counter: 9 out of 20\n",
            " 35% 175/501 [06:07<11:27,  2.11s/it]EarlyStopping counter: 10 out of 20\n",
            " 35% 176/501 [06:09<11:15,  2.08s/it]EarlyStopping counter: 11 out of 20\n",
            " 35% 177/501 [06:11<11:05,  2.05s/it]EarlyStopping counter: 12 out of 20\n",
            " 36% 178/501 [06:13<10:56,  2.03s/it]EarlyStopping counter: 13 out of 20\n",
            " 36% 179/501 [06:15<11:08,  2.08s/it]EarlyStopping counter: 14 out of 20\n",
            " 36% 180/501 [06:17<11:15,  2.10s/it]epoch 181/501, training_r2 0.9051, training_loss 0.0556\n",
            "EarlyStopping counter: 15 out of 20\n",
            "epoch 181/501, validation r2 0.7906, validation loss 0.1258, best validation r2 0.7948\n",
            " 36% 181/501 [06:19<11:21,  2.13s/it]EarlyStopping counter: 16 out of 20\n",
            " 36% 182/501 [06:22<11:23,  2.14s/it]EarlyStopping counter: 17 out of 20\n",
            " 37% 183/501 [06:24<11:08,  2.10s/it]EarlyStopping counter: 18 out of 20\n",
            " 37% 184/501 [06:26<10:55,  2.07s/it]EarlyStopping counter: 19 out of 20\n",
            " 37% 185/501 [06:28<10:46,  2.05s/it]EarlyStopping counter: 20 out of 20\n",
            " 37% 185/501 [06:30<11:06,  2.11s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "import tqdm\n",
        "# store builtin print\n",
        "old_print = print\n",
        "def new_print(*args, **kwargs):\n",
        "    # if tqdm.tqdm.write raises error, use builtin print\n",
        "    try:\n",
        "        tqdm.tqdm.write(*args, **kwargs)\n",
        "    except:\n",
        "        old_print(*args, ** kwargs)\n",
        "# globaly replace print with new_print\n",
        "inspect.builtins.print = new_print"
      ],
      "metadata": {
        "id": "fnqA6lLZNtH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "\n",
        "def blabla():\n",
        "  print (\"Foo blabla\")\n",
        "\n",
        "for k in tqdm(range(3)):\n",
        "  blabla()\n",
        "  sleep(.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH0pvIckPmlx",
        "outputId": "956706a4-c0fc-4ae1-b062-4fad11209c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Foo blabla\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 1/3 [00:00<00:01,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Foo blabla\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [00:01<00:00,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Foo blabla\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conventional models test**"
      ],
      "metadata": {
        "id": "yM6dQ0hajQKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from rdkit.Chem import MACCSkeys\n",
        "from rdkit import Chem\n",
        "import pandas as pd\n",
        "model_path = 'model/'\n",
        "def smile_list_to_MACCS(smi_list):\n",
        "    MACCS_list = []\n",
        "    # maccs = None\n",
        "    if isinstance(smi_list, str):\n",
        "        smi_list = [smi_list]\n",
        "    for smi in smi_list:\n",
        "        mol = Chem.MolFromSmiles(smi)\n",
        "        maccs = list(MACCSkeys.GenMACCSKeys(mol).ToBitString())\n",
        "        MACCS_list.append(maccs)\n",
        "\n",
        "    header = ['bit' + str(i) for i in range(167)]\n",
        "    df = pd.DataFrame(MACCS_list,columns=header)\n",
        "        # maccs = df.values\n",
        "    return df.values\n",
        "def simp_model_predict(smi_list, enzyme, ml): # Works for SVM_poly, RF, XGBoost\n",
        "    if isinstance(smi_list, str):\n",
        "        smi_list = [smi_list]\n",
        "    modelname = ml + '_' + enzyme + '.sav'\n",
        "    model = pickle.load(open(model_path+modelname, 'rb'))\n",
        "    # maccs = smile_list_to_MACCS(smi)\n",
        "    pred = model.predict(smile_list_to_MACCS(smi_list))\n",
        "    prob = model.predict_proba(smile_list_to_MACCS(smi_list))\n",
        "#     type(prob[0][1])\n",
        "#     print(ml, pred, prob, prob[0][1])\n",
        "    return prob[:, 1], pred\n",
        "\n",
        "\n",
        "# Single smiles\n",
        "s = [smiles['M1'], smiles['M2']]\n",
        "prob, pred = simp_model_predict(s, 'JAK1', 'SVM_poly')\n",
        "print('SVM poly:', prob, pred)\n",
        "prob, pred = simp_model_predict(s, 'JAK1', 'RF')\n",
        "print('RF:', prob, pred)\n",
        "prob, pred = simp_model_predict(s, 'JAK1', 'XGBoost')\n",
        "print('XGBoost: ', prob, pred)"
      ],
      "metadata": {
        "id": "6801nF3lgyeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c3554d-4563-4a4b-d3dd-e4060b263205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM poly: [0.11809338 0.6003182 ] [0 1]\n",
            "RF: [0.45283019 0.45283019] [0 0]\n",
            "XGBoost:  [0.14273576 0.566864  ] [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from function import evaluate\n",
        "# CAN handle list of smiles\n",
        "def chembert_predict(smi, enzyme):\n",
        "    # Turn single smi into list\n",
        "    if isinstance(smi, str):\n",
        "        smi = [smi]\n",
        "    ml = 'chembert'\n",
        "    file_path = 'model/' + ml + '_' + enzyme + '.pt'\n",
        "\n",
        "    model = chembert()\n",
        "    optimizer = optim.AdamW(params=model.parameters(), lr=1e-5, weight_decay=1e-2)\n",
        "    model.load_state_dict(torch.load(file_path, map_location=torch.device('cuda')))\n",
        "    model = model.cuda()\n",
        "    weight_dict = {1: torch.tensor([3.0, 1.0]), 2: torch.tensor([2.0, 1.0]),\n",
        "                   3: torch.tensor([2.0, 1.0]),4: torch.tensor([2.0, 1.0])}\n",
        "    params = {'batch_size': 32, 'shuffle': False,\n",
        "              'drop_last': False, 'num_workers': 0}\n",
        "    model.eval()\n",
        "\n",
        "    known_df = pd.DataFrame(smi)\n",
        "    known_df.columns = ['Smiles']\n",
        "    known_df['Activity'] = 0\n",
        "    known_data = jak_dataset_chembert(known_df)\n",
        "    known_loader = DataLoader(known_data, **params)\n",
        "    y_pred_list = []\n",
        "    y_prob_list = []\n",
        "    X_list = []\n",
        "    for idx, (X, _) in tqdm(enumerate(known_loader), total=len(known_loader)):\n",
        "        model.eval()\n",
        "        output = model(list(X))\n",
        "        _, y_pred = torch.max(output, 1)\n",
        "        y_pred_list.extend(y_pred.tolist())\n",
        "        y_prob_list.extend(torch.softmax(output,1)[:,1].tolist())\n",
        "        X_list.extend(list(X))\n",
        "\n",
        "\n",
        "    return y_prob_list, y_pred_list\n",
        "\n",
        "# chemberta exmaple usage\n",
        "# works on GPU\n",
        "\n",
        "# import pandas as pd\n",
        "# jak1_data = pd.read_csv('data/JAK1_final.csv')\n",
        "# jak1_data.head()\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from function import evaluate\n",
        "# train_df, test_df = train_test_split(jak1_data, test_size=0.2, random_state=42)\n",
        "# probs, preds = chembert_predict(test_df['Smiles'].tolist(), 'JAK1')\n",
        "# evaluate(test_df['Activity'].tolist(), preds, probs)\n",
        "\n",
        "chembert_predict(list(smiles.values())[:4], 'JAK1')"
      ],
      "metadata": {
        "id": "m1ZQ-VnEtlK-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "e5a041a1-89ce-4947-a65a-a875d24d0a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d0a7aca1c0e1>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# evaluate(test_df['Activity'].tolist(), preds, probs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mchembert_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'JAK1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-d0a7aca1c0e1>\u001b[0m in \u001b[0;36mchembert_predict\u001b[0;34m(smi, enzyme)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0menzyme\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchembert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'chembert' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "amdpiCHEsH8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smi = ['COOC', 'ClCOP', 'CON']\n",
        "type(prob.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmOddyowsQZk",
        "outputId": "cac98481-1bdc-4d3e-958e-653f12c0ae6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob, pred = simp_model_predict(smi, 'JAK1', 'RF')\n",
        "prob, pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTNDX_Et2KlF",
        "outputId": "bad6ebd8-aeba-4cb9-f549-27f0a0844270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.20754717, 0.19622642, 0.18867925]), array([0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "type(test_df['Smiles'].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esjq_uNo2yq_",
        "outputId": "a57780ca-029e-44ca-cadf-ac1ecf46cd24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_jak, pred_jak = simp_model_predict(test_df['Smiles'].tolist(), 'JAK2', 'XGBoost')\n",
        "evaluate(test_df['Activity'].tolist(), pred_jak, prob_jak)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erghF2fO208u",
        "outputId": "971f21f8-ddf4-4c4b-c357-d1ad084890b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.912  &  0.889  &          0.913  &     0.960  &0.817  &0.936 &0.959 &   0.801 &   0.976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "jak1_data = pd.read_csv('data/JAK2_final.csv')\n",
        "jak1_data.head()\n",
        "from sklearn.model_selection import train_test_split\n",
        "from function import evaluate\n",
        "train_df, test_df = train_test_split(jak1_data, test_size=0.2, random_state=42)\n",
        "probs, preds = chembert_predict(test_df['Smiles'].tolist(), 'JAK2')\n",
        "print()\n",
        "evaluate(test_df['Activity'].tolist(), preds, probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcwtG_x855tp",
        "outputId": "743319ac-26d9-4b5e-92cf-ed2959bdf8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:04<00:00, 13.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.897  &  0.893  &          0.939  &     0.903  &0.884  &0.921 &0.957 &   0.773 &   0.976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def GVAE_predict(smi, enzyme, model_path=model_path, device='cpu'):\n",
        "#     if isinstance(smi, str):\n",
        "#         smi = [smi]\n",
        "#     smiles, nodes, edges, relations = preprocess_test(smi)\n",
        "#     y = [0]*len(smiles)\n",
        "# #     print(len(smiles))\n",
        "\n",
        "#     test_set = GDataset(nodes, edges, relations,y, range(len(smiles)))\n",
        "#     test_loader = DataLoader(test_set, batch_size=len(smiles), shuffle=False)\n",
        "\n",
        "#     model = torch.load(model_path+'GVAE'+ '_' + enzyme + '.pt')\n",
        "# #     print(model_path+'GVAE'+ '_' + enzyme + '.pt')\n",
        "#     model.eval()\n",
        "#     for data in test_loader:\n",
        "#         data.to(device)\n",
        "#         preds = model(data.x, data.edge_index, data.edge_type, data.batch, 'fintune')\n",
        "# #         print(preds)\n",
        "# #         print(get_preds(preds)[0])\n",
        "\n",
        "#     return preds, get_preds(preds)[0]\n",
        "# GVAE_predict(smi, 'JAK2', 'model/')"
      ],
      "metadata": {
        "id": "ERUOg7l85_Qs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNdwBtwjjVIy86BRGHl6aEF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/JAK_ML/blob/main/examples/experiments/ADMET_M_MLP_AT_GIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPJj7KCT3u9x",
        "outputId": "337dbaaf-4e42-41ce-8715-aefbe22c6df0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rdkit --quiet\n",
        "! pip install PyTDC --quiet\n",
        "! pip install mycolorpy --quiet\n",
        "\n",
        "! pip install dgllife --quiet\n",
        "! pip install molvs --quiet\n",
        "! pip install dgl -f https://data.dgl.ai/wheels/cu118/repo.html --quiet\n",
        "! pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html --quiet\n",
        "\n",
        "! pip install DeepPurpose --quiet\n",
        "! pip install git+https://github.com/bp-kelley/descriptastorus --quiet\n",
        "! pip install pandas-flavor --quiet"
      ],
      "metadata": {
        "id": "v8pFVExr34EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ADMET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T5y78pl37lp",
        "outputId": "a4cd9ce9-f0fb-4486-f14b-e738bfff0e88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ADMET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Functions\n",
        "#### classification already writen in scripts eval_utils\n",
        "\n",
        "#### regression: here:"
      ],
      "metadata": {
        "id": "WnphAzt1OFLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.eval_utils import *\n",
        "from scripts.preprocess_mols import *\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
        "\n",
        "device = 'cuda'\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def reg_evaluate(label_clean, preds_clean):\n",
        "    mae = metrics.mean_absolute_error(label_clean, preds_clean)\n",
        "    mse = metrics.mean_squared_error(label_clean, preds_clean)\n",
        "    rmse = np.sqrt(mse) #mse**(0.5)\n",
        "    r2 = metrics.r2_score(label_clean, preds_clean)\n",
        "\n",
        "    print('MAE,   MSE,   RMSE,   R2')\n",
        "    print(\"& %5.3f\" % (mae), \" &%5.3f\" % (mse), \" &%5.3f\" % (rmse),\n",
        "      \" &%5.3f\" % (r2))\n",
        "\n",
        "    eval_result_r2 =   f'R2:     {r2:.3f}'\n",
        "    eval_result_mae =  f'MAE:   {mae:.3f}'\n",
        "    eval_result_rmse = f'RMSE: {rmse:.3f}'\n",
        "\n",
        "    return eval_result_r2, eval_result_mae, eval_result_rmse\n",
        "\n",
        "from mycolorpy import colorlist as mcp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def eval_dict(y_probs:dict, y_label:dict, names:list, IS_R=False, draw_fig=False):\n",
        "    if isinstance(IS_R, list): task_list = IS_R\n",
        "    else: task_list = [IS_R] * len(names)\n",
        "    for i, name in enumerate(names):\n",
        "        IS_R = task_list[i]\n",
        "        print('*'*15, name, '*'*15)\n",
        "        probs = y_probs[name]\n",
        "        label = y_label[name]\n",
        "        assert len(probs) == len(label)\n",
        "        if IS_R == False:\n",
        "            preds = get_preds(0.5, probs)\n",
        "            evaluate(label, preds, probs)\n",
        "\n",
        "        else:\n",
        "            r2, mae, rmse = reg_evaluate(label, probs)\n",
        "            if draw_fig:\n",
        "                color = mcp.gen_color_normalized(cmap='viridis',\n",
        "                                                data_arr=label)\n",
        "                plt.scatter(label, probs, cmap='viridis', marker='.',\n",
        "                            s=10, alpha=0.5, edgecolors='none', c=color)\n",
        "                plt.xlabel(f'True {name}')\n",
        "                plt.ylabel(f'Predicted {name}')\n",
        "                plt.title(f'{name} prediction on test set')\n",
        "\n",
        "                x0, xmax = plt.xlim()\n",
        "                y0, ymax = plt.ylim()\n",
        "                data_width = xmax - x0\n",
        "                data_height = ymax - y0\n",
        "                # print(x0, xmax, y0, ymax, data_width, data_height)\n",
        "                plt.text(x0 + 0.1*data_width, y0 + data_height * 0.8/0.95, r2)\n",
        "                plt.text(x0 + 0.1*data_width, y0 + data_height * 0.8,  mae)\n",
        "                plt.text(x0 + 0.1*data_width, y0 + data_height * 0.8*0.95, rmse)\n",
        "\n",
        "                plt.show()\n",
        "                plt.cla()\n",
        "                plt.clf()\n",
        "                plt.close()\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "CrCatroO4uF6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models architecture\n",
        "\n",
        "#### Classifier: MLP\n",
        "\n",
        "#### AttentiveFP\n"
      ],
      "metadata": {
        "id": "zQ0kehloOUGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, **config):\n",
        "        super(Classifier, self).__init__()\n",
        "        dims = [config['in_dim'], config['hid_dims'], config['out_dim']]\n",
        "        self.dims = dims\n",
        "        neurons = [config['in_dim'], *config['hid_dims']]\n",
        "        linear_layers = [nn.Linear(neurons[i-1], neurons[i]) \\\n",
        "                         for i in range(1, len(neurons))]\n",
        "        self.hidden = nn.ModuleList(linear_layers)\n",
        "        self.final = nn.Linear(config['hid_dims'][-1], config['out_dim'])\n",
        "        self.dropout = nn.Dropout(config['dropout'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden: x = F.relu(layer(x))\n",
        "        x = self.final(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "    def get_dim(self): return self.dims\n"
      ],
      "metadata": {
        "id": "GHxFRDt74xcQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from dgllife.model import model_zoo\n",
        "from dgllife.utils import smiles_to_bigraph\n",
        "from dgllife.utils import EarlyStopping, Meter\n",
        "from dgllife.utils import AttentiveFPAtomFeaturizer\n",
        "from dgllife.utils import AttentiveFPBondFeaturizer\n",
        "from dgllife.data import MoleculeCSVDataset\n",
        "\n",
        "\n",
        "\n",
        "def get_model_AT_10_17(names, n_layers, graph_feat_size, dropout):\n",
        "    atom_featurizer = AttentiveFPAtomFeaturizer(atom_data_field='hv')\n",
        "    bond_featurizer = AttentiveFPBondFeaturizer(bond_data_field='he')\n",
        "    n_feats_num = atom_featurizer.feat_size('hv')\n",
        "    e_feats_num = bond_featurizer.feat_size('he')\n",
        "\n",
        "    model = model_zoo.AttentiveFPPredictor(\n",
        "            node_feat_size=n_feats_num, edge_feat_size=e_feats_num,\n",
        "            num_layers=n_layers, num_timesteps=1,\n",
        "            graph_feat_size=graph_feat_size,\n",
        "            n_tasks=len(names), dropout=dropout)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Yd8Qr2TiOzGk"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# config_AttentiveFP = {'model_type': 'AttentiveFP',\n",
        "#           'in_dim': graph_feat_size,\n",
        "#           'n_layers': n_layers,\n",
        "#           'out_dim': len(names),\n",
        "#           'prop_names': names,\n",
        "#           'dropout': dropout,\n",
        "#           'IS_R': IS_R,\n",
        "#           'lr': lr,\n",
        "#           'wd': wd,\n",
        "#           'patience': patience,\n",
        "#           'model_path': 'ckpt.pt'}\n",
        "\n",
        "def AttentiveFP(**config):\n",
        "    return get_model_AT_10_17(config['prop_names'], config['n_layers'],\n",
        "                                    config['in_dim'], config['dropout'])"
      ],
      "metadata": {
        "id": "qzLXFtcJPN2h"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AttentiveFP(**config_AttentiveFP)"
      ],
      "metadata": {
        "id": "cgV8fNggQ7Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GIN"
      ],
      "metadata": {
        "id": "7iOfGbV5bRg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GIN_MOD(nn.Module):\n",
        "    \"\"\"\n",
        "    Reference: https://github.com/kexinhuang12345/DeepPurpose/blob/master/DeepPurpose/encoders.py#L392\n",
        "    \"\"\"\n",
        "\t## adapted from https://github.com/awslabs/dgl-lifesci/blob/2fbf5fd6aca92675b709b6f1c3bc3c6ad5434e96/examples/property_prediction/moleculenet/utils.py#L76\n",
        "    def __init__(self, **config):\n",
        "        super(GIN_MOD, self).__init__()\n",
        "        self.gnn = load_pretrained('gin_supervised_contextpred')\n",
        "        self.readout = AvgPooling()\n",
        "        self.transform = nn.Linear(300, config['in_dim'])\n",
        "        self.dropout = nn.Dropout(config['dropout'])\n",
        "        self.hidden_dims = config['hid_dims']\n",
        "        self.out_dim = config['out_dim']\n",
        "        layer_size = len(self.hidden_dims)\n",
        "        neurons = [config['in_dim'], *self.hidden_dims]\n",
        "        linear_layers = [nn.Linear(neurons[i-1], neurons[i]) \\\n",
        "                         for i in range(1, len(neurons))]\n",
        "        self.hidden = nn.ModuleList(linear_layers)\n",
        "        self.final = nn.Linear(self.hidden_dims[-1], self.out_dim)\n",
        "\n",
        "    def forward(self, bg):\n",
        "        # bg = bg.to(device)\n",
        "        node_feats = [\n",
        "            bg.ndata.pop('atomic_number'),\n",
        "            bg.ndata.pop('chirality_type')\n",
        "        ]\n",
        "        edge_feats = [\n",
        "            bg.edata.pop('bond_type'),\n",
        "            bg.edata.pop('bond_direction_type')\n",
        "        ]\n",
        "\n",
        "        node_feats = self.gnn(bg, node_feats, edge_feats)\n",
        "        x = self.readout(bg, node_feats)\n",
        "        x = self.transform(x)\n",
        "        for layer in self.hidden: x = F.leaky_relu(layer(x))\n",
        "        x = self.final(x)\n",
        "        return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "61Bo07lebRFy"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train eval test functions"
      ],
      "metadata": {
        "id": "9jXDq3gwQsac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch_MLP(model, loader, IS_R, names, device, epoch=None,\n",
        "                    optimizer=None, MASK=-100):\n",
        "    if optimizer==None: # no optimizer, either validation or test\n",
        "        model.eval()    # model evaluation for either valid or test\n",
        "        if epoch != None: train_type='Valid' # if epoch is inputted, its valid\n",
        "        else: train_type = 'Test' # if no epoch information, its test\n",
        "    else: model.train(); train_type='Train' # if optimizer inputted, its train\n",
        "\n",
        "    if isinstance(IS_R, list): IS_R_list = IS_R\n",
        "    else: IS_R_list = [IS_R] * len(names)\n",
        "    losses = 0\n",
        "    y_probs = {}\n",
        "    y_label = {}\n",
        "    for idx, batch_data in enumerate(loader):\n",
        "        \"\"\"\n",
        "        len(batch_data) could determine which algorithm\n",
        "        len(batch_data) == 2: MLP, GIN\n",
        "        len(batch_data) == 4: AttentiveFP\n",
        "        \"\"\"\n",
        "        if len(batch_data) == 2:  # MLP or GIN\n",
        "            fp, labels = batch_data\n",
        "            fp, labels = fp.to(device), labels.to(device)\n",
        "            mask = labels == MASK\n",
        "            pred = model(fp)\n",
        "        elif len(batch_data) == 4: # attentiveFP\n",
        "            smiles, bg, labels, masks = batch_data\n",
        "            bg, labels, masks = bg.to(device), labels.to(device), masks.to(device)\n",
        "            n_feats = bg.ndata.pop('hv').to(device)\n",
        "            e_feats = bg.edata.pop('he').to(device)\n",
        "            pred = model(bg, n_feats, e_feats)\n",
        "            mask = masks < 1\n",
        "\n",
        "        for j, (name, IS_R) in enumerate(zip(names, IS_R_list)):\n",
        "            loss_func = get_loss_fn(IS_R)\n",
        "            probs = pred[:, j][~mask[:, j]]\n",
        "            label = labels[:, j][~mask[:, j]]\n",
        "            if j == 0: loss = loss_func(probs, label)\n",
        "            else: loss += loss_func(probs, label)\n",
        "            if IS_R == False: probs = F.sigmoid(probs)\n",
        "\n",
        "            if train_type != 'Train': # validation\n",
        "                probs = probs.cpu().detach().numpy().tolist()\n",
        "                label = label.cpu().detach().numpy().tolist()\n",
        "                if idx ==0: y_probs[name], y_label[name] = probs, label\n",
        "                else:\n",
        "                    y_probs[name] += probs\n",
        "                    y_label[name] += label\n",
        "\n",
        "        losses += loss.item()\n",
        "        if optimizer != None: optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "\n",
        "    total_loss = losses / len(loader.dataset)\n",
        "    if epoch != None:\n",
        "        print(f'Epoch:{epoch}, [{train_type}] Loss: {total_loss:.3f}')\n",
        "    else:\n",
        "        print(f'[{train_type}] Loss: {total_loss:.3f}')\n",
        "        eval_dict(y_probs, y_label, names, IS_R, True)\n",
        "\n",
        "    if train_type == 'train': return total_loss\n",
        "    else: return total_loss, y_probs, y_label\n",
        "\n"
      ],
      "metadata": {
        "id": "_OEp4cid9HiQ"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch_AT(model, loader, IS_R, names, device, epoch=None,\n",
        "                    optimizer=None, MASK=-100):\n",
        "    if optimizer==None: # no optimizer, either validation or test\n",
        "        model.eval()    # model evaluation for either valid or test\n",
        "        if epoch != None: train_type='Valid' # if epoch is inputted, its valid\n",
        "        else: train_type = 'Test' # if no epoch information, its test\n",
        "    else: model.train(); train_type='Train' # if optimizer inputted, its train\n",
        "\n",
        "    if isinstance(IS_R, list): IS_R_list = IS_R\n",
        "    else: IS_R_list = [IS_R] * len(names)\n",
        "    losses = 0\n",
        "    y_probs = {}\n",
        "    y_label = {}\n",
        "    for idx, batch_data in enumerate(loader):\n",
        "        smiles, bg, labels, masks = batch_data\n",
        "        bg, labels, masks = bg.to(device), labels.to(device), masks.to(device)\n",
        "        n_feats = bg.ndata.pop('hv').to(device)\n",
        "        e_feats = bg.edata.pop('he').to(device)\n",
        "\n",
        "        pred = model(bg, n_feats, e_feats)\n",
        "        mask = masks < 1\n",
        "\n",
        "        for j, (name, IS_R) in enumerate(zip(names, IS_R_list)):\n",
        "            loss_func = get_loss_fn(IS_R)\n",
        "            probs = pred[:, j][~mask[:, j]]\n",
        "            label = labels[:, j][~mask[:, j]]\n",
        "            if j == 0: loss = loss_func(probs, label)\n",
        "            else: loss += loss_func(probs, label)\n",
        "            if IS_R == False: probs = F.sigmoid(probs)\n",
        "\n",
        "            if train_type != 'Train': # validation\n",
        "                probs = probs.cpu().detach().numpy().tolist()\n",
        "                label = label.cpu().detach().numpy().tolist()\n",
        "                if idx ==0: y_probs[name], y_label[name] = probs, label\n",
        "                else:\n",
        "                    y_probs[name] += probs\n",
        "                    y_label[name] += label\n",
        "\n",
        "        losses += loss.item()\n",
        "        if optimizer != None: optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "\n",
        "    total_loss = losses / len(loader.dataset)\n",
        "    if epoch != None:\n",
        "        print(f'Epoch:{epoch}, [{train_type}] Loss: {total_loss:.3f}')\n",
        "    else:\n",
        "        print(f'[{train_type}] Loss: {total_loss:.3f}')\n",
        "        eval_dict(y_probs, y_label, names, IS_R, True)\n",
        "\n",
        "    if train_type == 'train': return total_loss\n",
        "    else: return total_loss, y_probs, y_label\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHdwabz7UX_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataset and dataloader functions"
      ],
      "metadata": {
        "id": "T_oi5JtxQwjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import pandas as pd\n",
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.MACCSkeys import GenMACCSKeys\n",
        "import torch.nn.functional as F\n",
        "\n",
        "m = Chem.MolFromSmiles\n",
        "header = ['bit' + str(i) for i in range(167)]\n",
        "\n",
        "def smile_list_to_MACCS(smi_list:list):\n",
        "    MACCS_list = []\n",
        "    for smi in smi_list:\n",
        "        maccs = [float(i) for i in list(GenMACCSKeys(m(smi)).ToBitString())]\n",
        "        MACCS_list.append(maccs)\n",
        "    return MACCS_list\n",
        "\n",
        "import torch\n",
        "def process(data):\n",
        "\n",
        "    # data = convert_with_qed_sa(data)\n",
        "    print('---> converting SMILES to MACCS...')\n",
        "    MACCS_list = smile_list_to_MACCS(data['Drug'].tolist())\n",
        "    data[header] = pd.DataFrame(MACCS_list)\n",
        "    print('---> FINISHED')\n",
        "    return data\n",
        "\n",
        "MASK = -100\n",
        "\n",
        "class nn_dataset(Dataset):\n",
        "    def __init__(self, df, prop_names, mask=MASK):\n",
        "        super(nn_dataset, self).__init__()\n",
        "        df = process(df)\n",
        "        df = df.fillna(mask)\n",
        "        self.df = df\n",
        "        self.len = len(df)\n",
        "        self.fp = self.df[header]\n",
        "        if isinstance(prop_names, str): prop_names = [prop_names]\n",
        "        self.props = self.df[prop_names]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fp = torch.tensor(self.fp.iloc[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.props.iloc[idx], dtype=torch.float32)\n",
        "        return fp, label\n",
        "\n",
        "    def __len__(self): return self.len\n",
        "\n",
        "    def get_df(self): return self.df"
      ],
      "metadata": {
        "id": "PaOCkCsuJLi8"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AttentiveFP"
      ],
      "metadata": {
        "id": "EjBnqkMURjrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_molgraphs(data):\n",
        "    assert len(data[0]) in [3, 4], \\\n",
        "        'Expect the tuple to be of length 3 or 4, got {:d}'.format(len(data[0]))\n",
        "    if len(data[0]) == 3:\n",
        "        smiles, graphs, labels = map(list, zip(*data))\n",
        "        masks = None\n",
        "    else:\n",
        "        smiles, graphs, labels, masks = map(list, zip(*data))\n",
        "\n",
        "    bg = dgl.batch(graphs)\n",
        "    bg.set_n_initializer(dgl.init.zero_initializer)\n",
        "    bg.set_e_initializer(dgl.init.zero_initializer)\n",
        "    labels = torch.stack(labels, dim=0)\n",
        "\n",
        "    if masks is None:\n",
        "        masks = torch.ones(labels.shape)\n",
        "    else:\n",
        "        masks = torch.stack(masks, dim=0)\n",
        "        # masks = (labels == MASK).long()\n",
        "    return smiles, bg, labels, masks\n",
        "\n",
        "def get_AttentiveFP_dataset(df, name):\n",
        "    atom_featurizer = AttentiveFPAtomFeaturizer(atom_data_field='hv')\n",
        "    bond_featurizer = AttentiveFPBondFeaturizer(bond_data_field='he')\n",
        "    time_string = time.strftime(\"%m_%d_%Y_%H:%M:%S\", time.localtime())\n",
        "\n",
        "    params = {'smiles_to_graph': smiles_to_bigraph,\n",
        "            'node_featurizer': atom_featurizer,\n",
        "            'edge_featurizer': bond_featurizer,\n",
        "            'smiles_column': 'Drug',\n",
        "            'cache_file_path': time_string+'.bin',\n",
        "            'task_names': name, 'load': True, 'n_jobs': len(name)*2}\n",
        "    graph_dataset = MoleculeCSVDataset(df, **params)\n",
        "    return graph_dataset\n",
        "\n",
        "def get_AttentiveFP_loader(df, name, **loader_params):\n",
        "    dataset = get_AttentiveFP_dataset(df, name)\n",
        "    loader_params['collate_fn'] = collate_molgraphs\n",
        "    loader = DataLoader(dataset, **loader_params)\n",
        "    return loader"
      ],
      "metadata": {
        "id": "2aesXzmSRibZ"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GIN data set and data loader"
      ],
      "metadata": {
        "id": "J4ZTJdZ7Z-DD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgllife.model import load_pretrained\n",
        "from dgl.nn.pytorch.glob import AvgPooling\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from functools import partial\n",
        "import torch\n",
        "from dgllife.utils import smiles_to_bigraph, PretrainAtomFeaturizer, PretrainBondFeaturizer\n",
        "\n",
        "MASK = -100\n",
        "\n",
        "class GIN_dataset(Dataset):\n",
        "    def __init__(self, df, names, mask=MASK):\n",
        "        df = df.fillna(mask)\n",
        "        self.names = names\n",
        "        self.df = df\n",
        "        self.len = len(df)\n",
        "        self.props = self.df[names]\n",
        "        self.node_featurizer = PretrainAtomFeaturizer()\n",
        "        self.edge_featurizer = PretrainBondFeaturizer()\n",
        "        self.fc = partial(smiles_to_bigraph, add_self_loop=True)\n",
        "    def __len__(self): return self.len\n",
        "    def __getitem__(self, idx):\n",
        "        v_d = self.df.iloc[idx]['Drug']\n",
        "        v_d = self.fc(smiles=v_d, node_featurizer = self.node_featurizer,\n",
        "                      edge_featurizer = self.edge_featurizer)\n",
        "        label = torch.tensor(self.props.iloc[idx], dtype=torch.float32)\n",
        "        return v_d, label\n",
        "\n",
        "import dgl\n",
        "def get_GIN_dataloader(datasets, **loader_params):\n",
        "    def dgl_collate_func(data):\n",
        "        x, labels = map(list, zip(*data))\n",
        "        bg = dgl.batch(x)\n",
        "        labels = torch.stack(labels, dim=0)\n",
        "        bg.set_n_initializer(dgl.init.zero_initializer)\n",
        "        bg.set_e_initializer(dgl.init.zero_initializer)\n",
        "        return bg, labels\n",
        "    loader_params['collate_fn'] = dgl_collate_func\n",
        "    return DataLoader(datasets, **loader_params)"
      ],
      "metadata": {
        "id": "bnJVCWB0aBRW"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_model(**config):\n",
        "    \"\"\"need incorporate all models here! \"\"\"\n",
        "    if config['model_type'] == 'MLP':\n",
        "        model = Classifier(**config)\n",
        "    elif config['model_type'] == 'GIN':\n",
        "        model = GIN_MOD(**config) # need work config GIN out_dim\n",
        "    elif config['model_type'] == 'AttentiveFP':\n",
        "        model = AttentiveFP(**config)\n",
        "    elif config['model_type'] == 'RNN': pass\n",
        "    return model\n",
        "\n",
        "def get_loss_fn(IS_R):\n",
        "    if IS_R: return nn.MSELoss(reduction='sum')\n",
        "    else: return nn.BCEWithLogitsLoss(reduction='sum')\n",
        "\n",
        "def get_train_fn(model_type):\n",
        "    if model_type == 'MLP': return train_epoch_MLP\n",
        "\n",
        "    elif model_type == 'GIN': return train_epoch_MLP\n",
        "    elif model_type == 'AttentiveFP': return train_epoch_MLP\n",
        "    elif model_type == 'RNN': pass\n",
        "\n",
        "def get_eval_fn(model_type):\n",
        "    if model_type == 'MLP': return train_epoch_MLP\n",
        "\n",
        "    elif model_type == 'GIN': return train_epoch_MLP\n",
        "    elif model_type == 'AttentiveFP': return train_epoch_MLP\n",
        "    elif model_type == 'RNN': pass\n",
        "\n",
        "\n",
        "def get_loader(df, names, params, model_type):\n",
        "    print('--> preparing data loader for model type ', model_type)\n",
        "    if model_type == 'MLP': return DataLoader(nn_dataset(df, names), **params)\n",
        "\n",
        "    elif model_type == 'GIN':\n",
        "        return get_GIN_dataloader(GIN_dataset(df, names), **params)\n",
        "\n",
        "    elif model_type == 'AttentiveFP':\n",
        "        return get_AttentiveFP_loader(df, names, **params)\n",
        "\n",
        "    elif model_type == 'RNN': pass\n"
      ],
      "metadata": {
        "id": "eR2Wal37Bc2A"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.preprocess_mols import preprocess, rename_cols, clean_mol\n",
        "from tdc.single_pred import ADME\n",
        "def collect_data_10_17(names:list, type_tdc='ADME', clean_mol_=False):\n",
        "    for i, name in enumerate(names):\n",
        "        print('*'*15, name, '*'*15)\n",
        "        if type_tdc == 'ADME':\n",
        "            data = ADME(name=name)\n",
        "            # data.label_distribution()\n",
        "            split = data.get_split()\n",
        "        train, valid, test = split['train'], split['valid'], split['test']\n",
        "        if clean_mol_:\n",
        "            train, valid, test = clean_mol(train), clean_mol(valid), clean_mol(test)\n",
        "\n",
        "        train = rename_cols(train[['Drug', 'Y']], name)\n",
        "        valid = rename_cols(valid[['Drug', 'Y']], name)\n",
        "        test  = rename_cols(test[['Drug', 'Y']],  name)\n",
        "\n",
        "        # if IS_R and SCALE: train, valid, test = scal(train), scal(valid), scal(test)\n",
        "\n",
        "        if i == 0: trains, valids, tests = train, valid, test\n",
        "        else:\n",
        "            trains = trains.merge(train, how='outer')\n",
        "            valids = valids.merge(valid, how='outer')\n",
        "            tests = tests.merge(test, how='outer')\n",
        "    return trains, valids, tests\n",
        "\n"
      ],
      "metadata": {
        "id": "7aU29JDBJcCt"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgllife.utils import EarlyStopping, Meter\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class PRED:\n",
        "    def __init__(self, **config):\n",
        "        cuda = torch.cuda.is_available()\n",
        "        if cuda: self.device = 'cuda'\n",
        "        else:    self.device = 'cpu'\n",
        "        self.prop_names = config['prop_names']\n",
        "        self.config = config\n",
        "        self.model_type = config['model_type']\n",
        "        print('model type: ', self.model_type)\n",
        "        self.model_path = config['model_path']\n",
        "\n",
        "        self.eval_fn = get_eval_fn(self.model_type)\n",
        "        self.train_fn = get_train_fn(self.model_type)\n",
        "\n",
        "        self.model = init_model(**config).to(self.device)\n",
        "\n",
        "        self.IS_R = config['IS_R'] # could be list, could be true/false\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(),\n",
        "                        lr=config['lr'], weight_decay=config['wd'])\n",
        "        self.stopper = EarlyStopping(mode='lower', patience=config['patience'])\n",
        "\n",
        "        self.min_loss = np.inf\n",
        "        self.best_epoch = 0\n",
        "\n",
        "    def load_model(self, path):\n",
        "        con = self.config.copy()\n",
        "        con['dropout'] = 0\n",
        "        self.model = init_model(**con).to(self.device)\n",
        "        print('load pretrained model from ', path)\n",
        "        self.model.load_state_dict(torch.load(path, map_location=self.device))\n",
        "\n",
        "    def eval(self, loader, path=None):\n",
        "        if path != None: self.load_model(path)\n",
        "        self.eval_fn(self.model, loader, self.IS_R, self.prop_names,\n",
        "                     self.device, epoch=None, optimizer=None, MASK=-100)\n",
        "\n",
        "    def train(self, data_loader, val_loader, test_loader=None):\n",
        "        if self.best_epoch != 0: self.load_model(self.model_path)\n",
        "\n",
        "        for epoch in range(500):\n",
        "            score = self.train_fn(self.model, data_loader, self.IS_R,\n",
        "                                  self.prop_names, self.device, epoch,\n",
        "                                  self.optimizer)\n",
        "            val_score, probs, labels = \\\n",
        "                    self.train_fn(self.model, val_loader, self.IS_R,\n",
        "                                  self.prop_names, self.device, epoch)\n",
        "\n",
        "            early_stop = self.stopper.step(val_score, self.model)\n",
        "            if val_score < self.min_loss:\n",
        "                print(f'prev min loss {self.min_loss:.3f}, '\n",
        "                      f'now loss {val_score:.3f} |',\n",
        "                      f'save model at epoch: {epoch}')\n",
        "                self.min_loss = val_score\n",
        "                torch.save(self.model.state_dict(), self.model_path)\n",
        "                self.best_epoch = epoch\n",
        "                eval_dict(probs, labels, self.prop_names, IS_R=self.IS_R)\n",
        "            if early_stop: print('early stop'); break\n",
        "\n",
        "        print(f\"best epoch: {self.best_epoch}, min loss: {self.min_loss:.4f}\")\n",
        "        print()\n",
        "        if test_loader != None: self.eval(test_loader, self.model_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "gCDdCyi_8rml"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST MLP MO"
      ],
      "metadata": {
        "id": "N7mnGF8DX68x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['CYP2C19_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith',\n",
        "         'CYP1A2_Veith', 'CYP2C9_Veith']\n",
        "\n",
        "IS_R = [False] * len(names)\n",
        "\n",
        "trains, valids, tests = collect_data_10_17(names)"
      ],
      "metadata": {
        "id": "98_qXe12K9uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def count_(df:pd.DataFrame):\n",
        "    for col in df.columns:\n",
        "        if col != 'Drug':\n",
        "            try:\n",
        "                ones = df[col].value_counts()[1]\n",
        "                zero = df[col].value_counts()[0]\n",
        "            except: ones = 'Nan'; zero = 'Nan'\n",
        "            print(col, f'\\t 0: {zero} | 1: {ones}')\n",
        "    print()\n",
        "\n",
        "count_(trains), count_(valids), count_(tests)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXP3AFUjfAEj",
        "outputId": "3e64fc79-338e-4888-fb9e-8dfe7207f967"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CYP2C19_Veith \t 0: 4803 | 1: 4063\n",
            "CYP2D6_Veith \t 0: 7425 | 1: 1766\n",
            "CYP3A4_Veith \t 0: 5052 | 1: 3577\n",
            "CYP1A2_Veith \t 0: 4745 | 1: 4060\n",
            "CYP2C9_Veith \t 0: 5652 | 1: 2813\n",
            "\n",
            "CYP2C19_Veith \t 0: 673 | 1: 593\n",
            "CYP2D6_Veith \t 0: 1053 | 1: 260\n",
            "CYP3A4_Veith \t 0: 717 | 1: 516\n",
            "CYP1A2_Veith \t 0: 677 | 1: 581\n",
            "CYP2C9_Veith \t 0: 796 | 1: 413\n",
            "\n",
            "CYP2C19_Veith \t 0: 1370 | 1: 1163\n",
            "CYP2D6_Veith \t 0: 2138 | 1: 488\n",
            "CYP3A4_Veith \t 0: 1449 | 1: 1017\n",
            "CYP1A2_Veith \t 0: 1328 | 1: 1188\n",
            "CYP2C9_Veith \t 0: 1599 | 1: 819\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "loader_params = {'batch_size': batch_size, 'shuffle': True}\n",
        "train_loader = get_loader(trains, names, loader_params, 'MLP')\n",
        "valid_loader = get_loader(valids, names, loader_params, 'MLP')\n",
        "\n",
        "test_params = {'batch_size': batch_size, 'shuffle': False}\n",
        "test_loader  = get_loader(tests,  names,  test_params,  'MLP')"
      ],
      "metadata": {
        "id": "rjHyI5_1fFiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = 167\n",
        "hid_dims = [256]\n",
        "dropout = 0.1\n",
        "lr = 3e-4\n",
        "wd = 1e-5\n",
        "patience = 10\n",
        "\n",
        "config = {'model_type': 'MLP',\n",
        "          'in_dim': in_dim,\n",
        "          'hid_dims': hid_dims,\n",
        "          'out_dim': len(names),\n",
        "          'prop_names': names,\n",
        "          'dropout': dropout,\n",
        "          'IS_R': IS_R,\n",
        "          'lr': lr,\n",
        "          'wd': wd,\n",
        "          'patience': patience,\n",
        "          'model_path': 'ckpt.pt'}\n",
        "print(config)\n",
        "models = PRED(**config)\n",
        "models.train(train_loader, valid_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z_vivd8H4EM",
        "outputId": "0de3c7b1-bc92-4ed6-c3ce-e4fdc60729e5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_type': 'MLP', 'in_dim': 167, 'hid_dims': [256], 'out_dim': 5, 'prop_names': ['CYP2C19_Veith', 'CYP2D6_Veith', 'CYP3A4_Veith', 'CYP1A2_Veith', 'CYP2C9_Veith'], 'dropout': 0.1, 'IS_R': [False, False, False, False, False], 'lr': 0.0003, 'wd': 1e-05, 'patience': 10, 'model_path': 'ckpt.pt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models.eval(test_loader, config['model_path'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xLR-KOgN3xs",
        "outputId": "8f2a1d85-6195-48de-b0d0-19b70f5c47c8"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load pretrained model from  ckpt.pt\n",
            "[Test] Loss: 0.550\n",
            "*************** CYP2C19_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.803  &  0.802  &          0.782  &     0.791  &0.812  &0.786 &0.879 &   0.603 &   0.850\n",
            "\n",
            "*************** CYP2D6_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.869  &  0.722  &          0.715  &     0.488  &0.956  &0.580 &0.852 &   0.518 &   0.659\n",
            "\n",
            "*************** CYP3A4_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.777  &  0.761  &          0.764  &     0.667  &0.855  &0.712 &0.860 &   0.535 &   0.806\n",
            "\n",
            "*************** CYP1A2_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.836  &  0.837  &          0.812  &     0.848  &0.825  &0.830 &0.914 &   0.672 &   0.903\n",
            "\n",
            "*************** CYP2C9_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.812  &  0.787  &          0.729  &     0.709  &0.865  &0.719 &0.880 &   0.578 &   0.766\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST ATTENTIVEFP MO"
      ],
      "metadata": {
        "id": "gIH_wfngYALf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader_params = {'batch_size': batch_size, 'shuffle': True}\n",
        "train_loader = get_loader(trains, names, loader_params, 'AttentiveFP')\n",
        "valid_loader = get_loader(valids, names, loader_params, 'AttentiveFP')\n",
        "\n",
        "test_params = {'batch_size': batch_size, 'shuffle': False}\n",
        "test_loader  = get_loader(tests,  names,  test_params,  'AttentiveFP')"
      ],
      "metadata": {
        "id": "Tk0gQ5B5TjIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers = 5\n",
        "graph_feat_size = 300\n",
        "config_AT = {'model_type': 'AttentiveFP',\n",
        "          'in_dim': graph_feat_size,\n",
        "          'n_layers': n_layers,\n",
        "          'out_dim': len(names),\n",
        "          'prop_names': names,\n",
        "          'dropout': dropout,\n",
        "          'IS_R': IS_R,\n",
        "          'lr': lr,\n",
        "          'wd': wd,\n",
        "          'patience': patience,\n",
        "          'model_path': 'ckpt_AT.pt'}\n",
        "\n",
        "print(config_AT)\n",
        "models = PRED(**config_AT)\n",
        "models.train(train_loader, valid_loader)"
      ],
      "metadata": {
        "id": "4aMzDAxVX1yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models.eval(test_loader, config_AT['model_path'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjuVs3gMYQfl",
        "outputId": "42992802-3974-4206-856c-25b041cf4c1e"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load pretrained model from  ckpt_AT.pt\n",
            "[Test] Loss: 0.480\n",
            "*************** CYP2C19_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.835  &  0.837  &          0.801  &     0.853  &0.820  &0.826 &0.909 &   0.671 &   0.889\n",
            "\n",
            "*************** CYP2D6_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.887  &  0.771  &          0.753  &     0.586  &0.956  &0.659 &0.887 &   0.599 &   0.726\n",
            "\n",
            "*************** CYP3A4_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.822  &  0.814  &          0.794  &     0.767  &0.861  &0.780 &0.909 &   0.631 &   0.867\n",
            "\n",
            "*************** CYP1A2_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.878  &  0.876  &          0.895  &     0.840  &0.912  &0.867 &0.944 &   0.756 &   0.941\n",
            "\n",
            "*************** CYP2C9_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.848  &  0.830  &          0.778  &     0.773  &0.887  &0.775 &0.919 &   0.661 &   0.838\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train GIN"
      ],
      "metadata": {
        "id": "5non0thza4DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader_params = {'batch_size': batch_size, 'shuffle': True}\n",
        "train_loader = get_loader(trains, names, loader_params, 'GIN')\n",
        "valid_loader = get_loader(valids, names, loader_params, 'GIN')\n",
        "\n",
        "test_params = {'batch_size': batch_size, 'shuffle': False}\n",
        "test_loader  = get_loader(tests,  names,  test_params,  'GIN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54PPNo9za7fH",
        "outputId": "960d7357-29b5-44e2-a2bd-23680d59d46e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> preparing data loader for model type  GIN\n",
            "--> preparing data loader for model type  GIN\n",
            "--> preparing data loader for model type  GIN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_GIN = {'model_type': 'GIN',\n",
        "          'in_dim': in_dim,\n",
        "          'hid_dims': hid_dims,\n",
        "          'out_dim': len(names),\n",
        "          'prop_names': names,\n",
        "          'dropout': dropout,\n",
        "          'IS_R': IS_R,\n",
        "          'lr': lr,\n",
        "          'wd': wd,\n",
        "          'patience': patience,\n",
        "          'model_path': 'ckpt_GIN.pt'}\n",
        "\n",
        "print(config_GIN)\n",
        "models = PRED(**config_GIN)\n",
        "models.train(train_loader, valid_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS1H86T7bzxd",
        "outputId": "9fb8f4f2-1d84-40fe-812f-7bca9d72b86c"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:27, [Train] Loss: 1.079\n",
            "Epoch:27, [Valid] Loss: 0.363\n",
            "EarlyStopping counter: 8 out of 10\n",
            "Epoch:28, [Train] Loss: 1.083\n",
            "Epoch:28, [Valid] Loss: 0.366\n",
            "EarlyStopping counter: 9 out of 10\n",
            "Epoch:29, [Train] Loss: 1.075\n",
            "Epoch:29, [Valid] Loss: 0.364\n",
            "EarlyStopping counter: 10 out of 10\n",
            "early stop\n",
            "best epoch: 19, min loss: 0.3622\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models.eval(test_loader, config_GIN['model_path'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEfobFpth5NP",
        "outputId": "c83b1d20-3bfa-4110-9069-7cc15496d217"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gin_supervised_contextpred_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gin_supervised_contextpred.pth...\n",
            "Pretrained model loaded\n",
            "load pretrained model from  ckpt_GIN.pt\n",
            "[Test] Loss: 0.427\n",
            "*************** CYP2C19_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.856  &  0.856  &          0.836  &     0.854  &0.858  &0.845 &0.929 &   0.710 &   0.915\n",
            "\n",
            "*************** CYP2D6_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.888  &  0.783  &          0.741  &     0.615  &0.951  &0.672 &0.904 &   0.609 &   0.760\n",
            "\n",
            "*************** CYP3A4_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.837  &  0.833  &          0.801  &     0.806  &0.859  &0.804 &0.920 &   0.665 &   0.886\n",
            "\n",
            "*************** CYP1A2_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.885  &  0.885  &          0.866  &     0.894  &0.877  &0.880 &0.950 &   0.770 &   0.945\n",
            "\n",
            "*************** CYP2C9_Veith ***************\n",
            "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
            "& 0.871  &  0.849  &          0.828  &     0.781  &0.917  &0.804 &0.937 &   0.709 &   0.871\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# names = ['k', 'b', 'd', 'f', 'a']\n",
        "# IS_R = True\n",
        "patience = 30\n",
        "dropout = 0.1\n",
        "in_dim = 167 # len of fingerprint\n",
        "out_dim = len(names)\n",
        "hid_dims = [128, 64, 32, 16] # hidden dims changeable\n",
        "lr = 3e-4\n",
        "wd = 1e-5\n",
        "\n",
        "dims = [in_dim, hid_dims, out_dim]\n",
        "print(dims)\n",
        "\n",
        "config = {'model_type': 'MLP',\n",
        "          'in_dim': in_dim,\n",
        "          'hid_dims': hid_dims,\n",
        "          'out_dim': len(names),\n",
        "          'prop_names': names,\n",
        "          'dropout': dropout,\n",
        "          'IS_R': IS_R,\n",
        "          'lr': lr,\n",
        "          'wd': wd,\n",
        "          'patience': patience,\n",
        "          'model_path': 'ckpt.pt'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxupTtFX5euj",
        "outputId": "7b121c1d-a568-4488-8fdb-cded67892545"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[167, [128, 64, 32, 16], 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(**config)\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "if cuda: model = model.cuda(); device = 'cuda'\n",
        "else: device = 'cpu'\n",
        "from torchsummary import summary\n",
        "batch_size = 128\n",
        "summary(model, (batch_size, config['in_dim']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYux5xre75hZ",
        "outputId": "e79a56c8-d4cb-4ad4-9897-c350619ac8e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1             [-1, 128, 128]          21,504\n",
            "            Linear-2              [-1, 128, 64]           8,256\n",
            "            Linear-3              [-1, 128, 32]           2,080\n",
            "            Linear-4              [-1, 128, 16]             528\n",
            "            Linear-5               [-1, 128, 5]              85\n",
            "           Dropout-6               [-1, 128, 5]               0\n",
            "================================================================\n",
            "Total params: 32,453\n",
            "Trainable params: 32,453\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.08\n",
            "Forward/backward pass size (MB): 0.24\n",
            "Params size (MB): 0.12\n",
            "Estimated Total Size (MB): 0.45\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(**config)\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "if cuda: model = model.cuda(); device = 'cuda'\n",
        "else: device = 'cpu'\n",
        "from torchsummary import summary\n",
        "batch_size = 128\n",
        "summary(model, (batch_size, config['in_dim']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niI47yMF7kcX",
        "outputId": "7ca61e43-9763-40d5-8cdc-c6185a4d2f54"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1             [-1, 128, 128]          21,504\n",
            "            Linear-2              [-1, 128, 64]           8,256\n",
            "            Linear-3              [-1, 128, 32]           2,080\n",
            "            Linear-4              [-1, 128, 16]             528\n",
            "            Linear-5               [-1, 128, 1]              17\n",
            "           Dropout-6               [-1, 128, 1]               0\n",
            "================================================================\n",
            "Total params: 32,385\n",
            "Trainable params: 32,385\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.08\n",
            "Forward/backward pass size (MB): 0.24\n",
            "Params size (MB): 0.12\n",
            "Estimated Total Size (MB): 0.44\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_loss_dict = {}\n",
        "valid_loss_dict = {}\n",
        "\n",
        "epochs = 1000\n",
        "best_epoch = 0\n",
        "\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(model, (batch_size, config['in_dim']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xww8kbxQ5APr",
        "outputId": "9c13d34c-47c1-4a05-e3f4-2334f36490b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1             [-1, 128, 128]          21,504\n",
            "            Linear-2              [-1, 128, 64]           8,256\n",
            "            Linear-3              [-1, 128, 32]           2,080\n",
            "            Linear-4              [-1, 128, 16]             528\n",
            "            Linear-5               [-1, 128, 1]              17\n",
            "           Dropout-6               [-1, 128, 1]               0\n",
            "================================================================\n",
            "Total params: 32,385\n",
            "Trainable params: 32,385\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.08\n",
            "Forward/backward pass size (MB): 0.24\n",
            "Params size (MB): 0.12\n",
            "Estimated Total Size (MB): 0.44\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B239AXyW5MzG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ea302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data \n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score, roc_auc_score\n",
    "model_path = 'model/'\n",
    "from function import get_tpr_fpr, save_tpr_fpr, load_tpr_fpr, evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch_geometric.nn import GATConv, RGCNConv, GCNConv, global_add_pool, global_mean_pool, global_max_pool, GlobalAttention, Set2Set\n",
    "from sklearn.metrics import f1_score, accuracy_score, average_precision_score, roc_auc_score\n",
    "\n",
    "import rdkit\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "\n",
    "from itertools import compress\n",
    "import random\n",
    "from collections import defaultdict\n",
    "if torch.cuda.is_available():\n",
    "    map_location=lambda storage, loc: storage.cuda()\n",
    "else:\n",
    "    map_location='cpu'\n",
    "\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import math\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "# from itertools import compress\n",
    "# import random\n",
    "# from collections import defaultdict\n",
    "import pickle\n",
    "device = 'cpu'\n",
    "model_path = 'model/'\n",
    "\n",
    "adj_max=80\n",
    "fps_len=167\n",
    "max_len=120\n",
    "\n",
    "vocabulary = {'C': 1, 'c': 2, '1': 3, '(': 4, '-': 5, '2': 6, 's': 7, 'N': 8, '=': 9, ')': 10, 'n': 11, '[': 12,\n",
    "                  '@': 13,\n",
    "                  'H': 14, ']': 15, 'O': 16, 'S': 17, '3': 18, 'l': 19, 'B': 20, 'r': 21, '/': 22, '\\\\': 23, 'o': 24,\n",
    "                  '4': 25,\n",
    "                  '5': 26, '6': 27, '7': 28, '+': 29, '.': 30, 'I': 31, 'F': 32, '8': 33, '#': 34, 'P': 35, '9': 36,\n",
    "                  'a': 37,\n",
    "                  '%': 38, '0': 39, 'i': 40, 'e': 41, 'L': 42, 'K': 43, 't': 44, 'T': 45, 'A': 46, 'g': 47, 'Z': 48,\n",
    "                  'M': 49,\n",
    "                  'R': 50, 'p': 51, 'b': 52, 'X': 53}\n",
    "\n",
    "known_drugs = ['O=C(NCCC(O)=O)C(C=C1)=CC=C1/N=N/C(C=C2C(O)=O)=CC=C2OCCOC3=CC=C(NC4=NC=C(C)C(NC5=CC=CC(S(NC(C)(C)C)(=O)=O)=C5)=N4)C=C3',\n",
    "        'OCCOC1=CC=C(NC2=NC=C(C)C(NC3=CC=CC(S(NC(C)(C)C)(=O)=O)=C3)=N2)C=C1',\n",
    "        'C1CCC(C1)C(CC#N)N2C=C(C=N2)C3=C4C=CNC4=NC=N3',\n",
    "        'CC1CCN(CC1N(C)C2=NC=NC3=C2C=CN3)C(=O)CC#N',\n",
    "        'CCS(=O)(=O)N1CC(C1)(CC#N)N2C=C(C=N2)C3=C4C=CNC4=NC=N3',\n",
    "        'C1CC1C(=O)NC2=NN3C(=N2)C=CC=C3C4=CC=C(C=C4)CN5CCS(=O)(=O)CC5',\n",
    "        'CCC1CN(CC1C2=CN=C3N2C4=C(NC=C4)N=C3)C(=O)NCC(F)(F)F',\n",
    "        'OC(COC1=CC=C(NC2=NC=C(C)C(NC3=CC=CC(S(NC(C)(C)C)(=O)=O)=C3)=N2)C=C1)=O',\n",
    "        'O=C(NCCC(O)=O)C(C=C1)=CC=C1/N=N/C(C=C2C(O)=O)=CC=C2OCCOC3=CC=C(NC4=NC=C(C)C(NC5=CC=CC(S(N)(=O)=O)=C5)=N4)C=C3',\n",
    "        'OC1=CC=C(NC2=NC=C(C)C(NC3=CC=CC(S(NC(C)(C)C)(=O)=O)=C3)=N2)C=C1',\n",
    "        'OCCOC1=CC=C(NC2=NC=C(C)C(NC3=CC=CC(S(N)(=O)=O)=C3)=N2)C=C1',\n",
    "        'CC1=CN=C(N=C1NC2=CC(=CC=C2)S(=O)(=O)NC(C)(C)C)NC3=CC=C(C=C3)OCCN4CCCC4',\n",
    "        'C1CCN(C1)CCOC2=C3COCC=CCOCC4=CC(=CC=C4)C5=NC(=NC=C5)NC(=C3)C=C2']\n",
    "\n",
    "device = torch.device('cpu')\n",
    "    \n",
    "class jak_dataset(Dataset):\n",
    "    def __init__(self, dataframe, max_len=80):\n",
    "        super(jak_dataset, self).__init__()\n",
    "        self.len = len(dataframe)\n",
    "        self.dataframe = dataframe\n",
    "        self.max_len = max_len\n",
    "    def __getitem__(self, idx):\n",
    "        y = 1 if self.dataframe.Activity[idx]==1 else 0\n",
    "        X = torch.zeros(self.max_len)\n",
    "        for idx, atom in enumerate(list(self.dataframe.Smiles[idx])[:self.max_len]):\n",
    "            X[idx] = vocabulary[atom]\n",
    "        \n",
    "        return X.long(), y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self, input_length, num_words, embedding_size=32, inner_size=32, output_size=fps_len, stride=1):\n",
    "        super(encoder, self).__init__()\n",
    "\n",
    "        self.input_length = input_length\n",
    "        self.num_words = num_words\n",
    "        self.embedding_size = embedding_size\n",
    "        self.inner_size = inner_size\n",
    "        self.output_size = output_size\n",
    "        self.stride = stride\n",
    "\n",
    "        self.embedding = nn.Embedding(self.num_words + 1, self.embedding_size, padding_idx=0)\n",
    "\n",
    "        self.conv_1 = nn.Conv1d(self.embedding_size, self.inner_size, 1, self.stride)\n",
    "        self.conv_2 = nn.Conv1d(self.embedding_size, self.inner_size, 2, self.stride)\n",
    "        self.conv_3 = nn.Conv1d(self.embedding_size, self.inner_size, 3, self.stride)\n",
    "\n",
    "        self.w = nn.Linear(self.inner_size * 3, self.output_size)\n",
    "\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.xavier_uniform_(self.conv_1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.conv_2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.conv_3.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.w.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).permute(0, 2, 1)\n",
    "        tri = self.conv_3(x)\n",
    "        bi = self.conv_2(x)\n",
    "        uni = self.conv_1(x)\n",
    "\n",
    "        tri_maxpool = nn.MaxPool1d(tri.shape[2])\n",
    "        bi_maxpool = nn.MaxPool1d(bi.shape[2])\n",
    "        uni_maxpool = nn.MaxPool1d(uni.shape[2])\n",
    "        integrate_feat = torch.cat(\n",
    "            (tri_maxpool(tri).squeeze(2), bi_maxpool(bi).squeeze(2), uni_maxpool(uni).squeeze(2)), dim=1)\n",
    "        #print(integrate_feat.shape)\n",
    "        return self.w(self.activation(integrate_feat))\n",
    "\n",
    "def generate_scaffold(smiles, include_chirality=False):\n",
    "    \"\"\"\n",
    "    Obtain Bemis-Murcko scaffold from smiles\n",
    "    :param smiles:\n",
    "    :param include_chirality:\n",
    "    :return: smiles of scaffold\n",
    "    \"\"\"\n",
    "    scaffold = MurckoScaffold.MurckoScaffoldSmiles(\n",
    "        smiles=smiles, includeChirality=include_chirality\n",
    "    )\n",
    "    return scaffold\n",
    "\n",
    "def random_scaffold_split(\n",
    "    dataset,\n",
    "    smiles_list,\n",
    "    task_idx=None,\n",
    "    null_value=0,\n",
    "    frac_train=0.8,\n",
    "    frac_valid=0.1,\n",
    "    frac_test=0.1,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Adapted from https://github.com/pfnet-research/chainer-chemistry/blob/master/\\\n",
    "        chainer_chemistry/dataset/splitters/scaffold_splitter.py\n",
    "    Split dataset by Bemis-Murcko scaffolds\n",
    "    This function can also ignore examples containing null values for a\n",
    "    selected task when splitting. Deterministic split\n",
    "    :param dataset: pytorch geometric dataset obj\n",
    "    :param smiles_list: list of smiles corresponding to the dataset obj\n",
    "    :param task_idx: column idx of the data.y tensor. Will filter out\n",
    "    examples with null value in specified task column of the data.y tensor\n",
    "    prior to splitting. If None, then no filtering\n",
    "    :param null_value: float that specifies null value in data.y to filter if\n",
    "    task_idx is provided\n",
    "    :param frac_train:\n",
    "    :param frac_valid:\n",
    "    :param frac_test:\n",
    "    :param seed;\n",
    "    :return: train, valid, test slices of the input dataset obj\n",
    "    \"\"\"\n",
    "\n",
    "    np.testing.assert_almost_equal(frac_train + frac_valid + frac_test, 1.0)\n",
    "\n",
    "    if task_idx is not None:\n",
    "        # filter based on null values in task_idx\n",
    "        # get task array\n",
    "        y_task = np.array([data.y[task_idx].item() for data in dataset])\n",
    "        # boolean array that correspond to non null values\n",
    "        non_null = y_task != null_value\n",
    "        smiles_list = list(compress(enumerate(smiles_list), non_null))\n",
    "    else:\n",
    "        non_null = np.ones(len(dataset)) == 1\n",
    "        smiles_list = list(compress(enumerate(smiles_list), non_null))\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    scaffolds = defaultdict(list)\n",
    "    for ind, smiles in smiles_list:\n",
    "        scaffold = generate_scaffold(smiles, include_chirality=True)\n",
    "        scaffolds[scaffold].append(ind)\n",
    "\n",
    "    scaffold_sets = rng.permutation(list(scaffolds.values()))\n",
    "\n",
    "    n_total_valid = int(np.floor(frac_valid * len(dataset)))\n",
    "    n_total_test = int(np.floor(frac_test * len(dataset)))\n",
    "\n",
    "    train_idx = []\n",
    "    valid_idx = []\n",
    "    test_idx = []\n",
    "\n",
    "    for scaffold_set in scaffold_sets:\n",
    "        if len(valid_idx) + len(scaffold_set) <= n_total_valid:\n",
    "            valid_idx.extend(scaffold_set)\n",
    "        elif len(test_idx) + len(scaffold_set) <= n_total_test:\n",
    "            test_idx.extend(scaffold_set)\n",
    "        else:\n",
    "            train_idx.extend(scaffold_set)\n",
    "\n",
    "    return train_idx, valid_idx, test_idx\n",
    "\n",
    "def load_smi_y(enzyme):\n",
    "    try:\n",
    "        path = 'data/' + enzyme + '_' + 'MACCS.csv'\n",
    "        data = pd.read_csv(path)\n",
    "    except:\n",
    "        path = enzyme + '_' + 'MACCS.csv'\n",
    "        data = pd.read_csv(path)\n",
    "    \n",
    "    X = data['Smiles']\n",
    "    y = data['Activity']\n",
    "    return X, y\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNforclassification(nn.Module):\n",
    "    def __init__(self, max_len, voc_len, load_path='model/CNN_encoder_pretrain2.pt',\n",
    "                 last_layer_size=fps_len, output_size=2):\n",
    "        super(CNNforclassification, self).__init__()\n",
    "\n",
    "        self.last_layer_size = last_layer_size\n",
    "        self.output_size = output_size\n",
    "        self.pretrained = encoder(max_len, voc_len)\n",
    "        self.pretrained.load_state_dict(\n",
    "            torch.load(load_path, map_location=device))\n",
    "\n",
    "        self.w = nn.Linear(self.last_layer_size, self.output_size)\n",
    "\n",
    "        self.activation = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.w(self.activation(self.pretrained(x)))\n",
    "\n",
    "\n",
    "def CNN_predict(smi, enzyme):\n",
    "    ml = 'CNN'\n",
    "    known_drugs = [smi]\n",
    "\n",
    "    file_path = 'model/' + ml + '_' + enzyme + '.pt'\n",
    "#     print(file_path)\n",
    "    weight_dict = {1: torch.tensor([3.0, 1.0]), 2: torch.tensor([2.0, 1.0]), 3: torch.tensor([2.0, 1.0]),\n",
    "                    4: torch.tensor([2.0, 1.0])}\n",
    "    model = CNNforclassification(max_len, len(vocabulary))\n",
    "    model.load_state_dict(torch.load(file_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "\n",
    "    params = {'batch_size':16, 'shuffle':False, 'drop_last':False, 'num_workers':0}\n",
    "\n",
    "    known_df = pd.DataFrame(known_drugs)\n",
    "    known_df.columns = ['Smiles']\n",
    "    known_df['Activity'] = 0\n",
    "    known_data = jak_dataset(known_df)\n",
    "    known_loader = DataLoader(known_data, **params)\n",
    "    for idx, (X, y_true) in tqdm(enumerate(known_loader), total=len(known_loader)):\n",
    "#         print(X)\n",
    "        model.eval()\n",
    "#         print(X)\n",
    "        output = model(X.clone().detach())\n",
    "#         print(output)\n",
    "        a, y_pred = torch.max(output, 1)\n",
    "    #     print(a)\n",
    "    #     print(output)\n",
    "    #     print(torch.max(torch.softmax(output, 1), 1)[0].tolist())\n",
    "    #     print(a.tolist())\n",
    "    #     print(torch.max(torch.softmax(output, 1), 1)[1].tolist())\n",
    "        y_prob = torch.softmax(output,1)[:, 1].tolist()\n",
    "        # print(y_prob)\n",
    "        # print(y_pred.tolist())\n",
    "    return y_prob, y_pred\n",
    "\n",
    "class RGCN_VAE(torch.nn.Module):\n",
    "    def __init__(self, in_embd, layer_embd, out_embd, num_relations, dropout):\n",
    "        super(RGCN_VAE, self).__init__()\n",
    "        self.embedding = nn.ModuleList([nn.Embedding(35,in_embd), nn.Embedding(10,in_embd), \\\n",
    "                          nn.Embedding(5,in_embd), nn.Embedding(7,in_embd), \\\n",
    "                          nn.Embedding(5,in_embd), nn.Embedding(5,in_embd)])\n",
    "        \n",
    "        self.GATConv1 = RGCNConv(6*in_embd, layer_embd, num_relations)\n",
    "        self.GATConv2 = RGCNConv(layer_embd, out_embd*2, num_relations)\n",
    "        \n",
    "#         self.GATConv1 = GCNConv(6*in_embd, layer_embd, num_relations)\n",
    "#         self.GATConv2 = GCNConv(layer_embd, out_embd*2, num_relations)\n",
    "        \n",
    "        self.GATConv1.reset_parameters()\n",
    "        self.GATConv2.reset_parameters()\n",
    "        \n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.d = out_embd        \n",
    "        \n",
    "        self.pool = GlobalAttention(gate_nn=nn.Sequential( \\\n",
    "                nn.Linear(out_embd, out_embd), nn.BatchNorm1d(out_embd), nn.ReLU(), nn.Linear(out_embd, 1)))\n",
    "        \n",
    "        self.graph_linear = nn.Linear(out_embd, 1)\n",
    "        \n",
    "    def recognition_model(self, x, edge_index, edge_type, batch):\n",
    "        for i in range(6):\n",
    "            embds = self.embedding[i](x[:,i])\n",
    "            if i == 0:\n",
    "                x_ = embds\n",
    "            else:\n",
    "                x_ = torch.cat((x_, embds), 1)\n",
    "        out = self.activation(self.GATConv1(x_, edge_index, edge_type))\n",
    "        out = self.activation(self.GATConv2(out, edge_index, edge_type))  \n",
    "        \n",
    "#         out = self.activation(self.GATConv1(x_, edge_index))\n",
    "#         out = self.activation(self.GATConv2(out, edge_index))  \n",
    "        \n",
    "        mu = out[:,0:self.d] \n",
    "        logvar = out[:,self.d:2*self.d]\n",
    "        \n",
    "        return mu, logvar\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = Variable(std.data.new(std.size()).normal_())\n",
    "        \n",
    "        return eps.mul(std) + mu\n",
    "\n",
    "    def generation_model(self, Z): \n",
    "        out = self.activation(Z@Z.T)\n",
    "        \n",
    "        return out\n",
    "      \n",
    "    def forward(self, x, edge_index, edge_type, batch, type_):\n",
    "        if type_=='pretrain':\n",
    "            mu, logvar = self.recognition_model(x, edge_index, edge_type, batch)\n",
    "            Z = self.reparametrize(mu, logvar)\n",
    "            A_hat = self.generation_model(Z)\n",
    "\n",
    "            N = x.size(0)\n",
    "            A = torch.zeros((N,N), device=device)\n",
    "            with torch.no_grad():\n",
    "                for i in range(edge_index.size(1)):\n",
    "                    A[edge_index[0,i], edge_index[1,i]] = 1\n",
    "          # print(A.size(),A_hat.size())\n",
    "            return A, A_hat, mu, logvar\n",
    "        else:\n",
    "            mu = self.cal_mu(x, edge_index, edge_type, batch)\n",
    "            out = self.pool(mu, batch)\n",
    "            out = self.graph_linear(out)\n",
    "            out = self.activation(out)\n",
    "            return out\n",
    "  \n",
    "    def cal_mu(self, x, edge_index, edge_type, batch):\n",
    "        mu, _ = self.recognition_model(x, edge_index, edge_type, batch)\n",
    "        \n",
    "        return mu\n",
    "    \n",
    "class GCN_VAE(torch.nn.Module):\n",
    "    def __init__(self, in_embd, layer_embd, out_embd, num_relations, dropout):\n",
    "        super(GCN_VAE, self).__init__()\n",
    "        self.embedding = nn.ModuleList([nn.Embedding(35,in_embd), nn.Embedding(10,in_embd), \\\n",
    "                          nn.Embedding(5,in_embd), nn.Embedding(7,in_embd), \\\n",
    "                          nn.Embedding(5,in_embd), nn.Embedding(5,in_embd)])\n",
    "        \n",
    "        self.GATConv1 = GCNConv(6*in_embd, layer_embd, num_relations)\n",
    "        self.GATConv2 = GCNConv(layer_embd, out_embd*2, num_relations)\n",
    "        \n",
    "        self.GATConv1.reset_parameters()\n",
    "        self.GATConv2.reset_parameters()\n",
    "        \n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.d = out_embd        \n",
    "        \n",
    "        self.pool = GlobalAttention(gate_nn=nn.Sequential( \\\n",
    "                nn.Linear(out_embd, out_embd), nn.BatchNorm1d(out_embd), nn.ReLU(), nn.Linear(out_embd, 1)))\n",
    "        \n",
    "        self.graph_linear = nn.Linear(out_embd, 1)\n",
    "        \n",
    "    def recognition_model(self, x, edge_index, edge_type, batch):\n",
    "        for i in range(6):\n",
    "            embds = self.embedding[i](x[:,i])\n",
    "            if i == 0:\n",
    "                x_ = embds\n",
    "            else:\n",
    "                x_ = torch.cat((x_, embds), 1)\n",
    "        \n",
    "        out = self.activation(self.GATConv1(x_, edge_index))\n",
    "        out = self.activation(self.GATConv2(out, edge_index))  \n",
    "        \n",
    "        mu = out[:,0:self.d] \n",
    "        logvar = out[:,self.d:2*self.d]\n",
    "        \n",
    "        return mu, logvar\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = Variable(std.data.new(std.size()).normal_())\n",
    "        \n",
    "        return eps.mul(std) + mu\n",
    "\n",
    "    def generation_model(self, Z): \n",
    "        out = self.activation(Z@Z.T)\n",
    "        \n",
    "        return out\n",
    "      \n",
    "    def forward(self, x, edge_index, edge_type, batch, type_):\n",
    "        if type_=='pretrain':\n",
    "            mu, logvar = self.recognition_model(x, edge_index, edge_type, batch)\n",
    "            Z = self.reparametrize(mu, logvar)\n",
    "            A_hat = self.generation_model(Z)\n",
    "\n",
    "            N = x.size(0)\n",
    "            A = torch.zeros((N,N), device=device)\n",
    "            with torch.no_grad():\n",
    "                for i in range(edge_index.size(1)):\n",
    "                    A[edge_index[0,i], edge_index[1,i]] = 1\n",
    "          # print(A.size(),A_hat.size())\n",
    "            return A, A_hat, mu, logvar\n",
    "        else:\n",
    "            mu = self.cal_mu(x, edge_index, edge_type, batch)\n",
    "            out = self.pool(mu, batch)\n",
    "            out = self.graph_linear(out)\n",
    "            out = self.activation(out)\n",
    "            return out\n",
    "  \n",
    "    def cal_mu(self, x, edge_index, edge_type, batch):\n",
    "        mu, _ = self.recognition_model(x, edge_index, edge_type, batch)\n",
    "        \n",
    "        return mu\n",
    "    \n",
    "class GAT_VAE(torch.nn.Module):\n",
    "    def __init__(self, in_embd, layer_embd, out_embd, num_relations, dropout):\n",
    "        super(GAT_VAE, self).__init__()\n",
    "        self.embedding = nn.ModuleList([nn.Embedding(35,in_embd), nn.Embedding(10,in_embd), \\\n",
    "                          nn.Embedding(5,in_embd), nn.Embedding(7,in_embd), \\\n",
    "                          nn.Embedding(5,in_embd), nn.Embedding(5,in_embd)])\n",
    "        \n",
    "        self.GATConv1 = GATConv(6*in_embd, layer_embd, num_relations)\n",
    "        self.GATConv2 = GATConv(layer_embd, out_embd*2, num_relations)\n",
    "        \n",
    "        self.GATConv1.reset_parameters()\n",
    "        self.GATConv2.reset_parameters()\n",
    "        \n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.d = out_embd        \n",
    "        \n",
    "        self.pool = GlobalAttention(gate_nn=nn.Sequential( \\\n",
    "                nn.Linear(out_embd, out_embd), nn.BatchNorm1d(out_embd), nn.ReLU(), nn.Linear(out_embd, 1)))\n",
    "        \n",
    "        self.graph_linear = nn.Linear(out_embd, 1)\n",
    "        \n",
    "    def recognition_model(self, x, edge_index, edge_type, batch):\n",
    "        for i in range(6):\n",
    "            embds = self.embedding[i](x[:,i])\n",
    "            if i == 0:\n",
    "                x_ = embds\n",
    "            else:\n",
    "                x_ = torch.cat((x_, embds), 1)\n",
    "        \n",
    "        out = self.activation(self.GATConv1(x_, edge_index))\n",
    "        out = self.activation(self.GATConv2(out, edge_index))  \n",
    "        \n",
    "        mu = out[:,0:self.d] \n",
    "        logvar = out[:,self.d:2*self.d]\n",
    "        \n",
    "        return mu, logvar\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = Variable(std.data.new(std.size()).normal_())\n",
    "        \n",
    "        return eps.mul(std) + mu\n",
    "\n",
    "    def generation_model(self, Z): \n",
    "        out = self.activation(Z@Z.T)\n",
    "        \n",
    "        return out\n",
    "      \n",
    "    def forward(self, x, edge_index, edge_type, batch, type_):\n",
    "        if type_=='pretrain':\n",
    "            mu, logvar = self.recognition_model(x, edge_index, edge_type, batch)\n",
    "            Z = self.reparametrize(mu, logvar)\n",
    "            A_hat = self.generation_model(Z)\n",
    "\n",
    "            N = x.size(0)\n",
    "            A = torch.zeros((N,N), device=device)\n",
    "            with torch.no_grad():\n",
    "                for i in range(edge_index.size(1)):\n",
    "                    A[edge_index[0,i], edge_index[1,i]] = 1\n",
    "          # print(A.size(),A_hat.size())\n",
    "            return A, A_hat, mu, logvar\n",
    "        else:\n",
    "            mu = self.cal_mu(x, edge_index, edge_type, batch)\n",
    "            out = self.pool(mu, batch)\n",
    "            out = self.graph_linear(out)\n",
    "            out = self.activation(out)\n",
    "            return out\n",
    "  \n",
    "    def cal_mu(self, x, edge_index, edge_type, batch):\n",
    "        mu, _ = self.recognition_model(x, edge_index, edge_type, batch)\n",
    "        \n",
    "        return mu\n",
    "        \n",
    "class GDataset(Dataset):\n",
    "    def __init__(self, nodes, edges, relations, y, idx):\n",
    "        super(GDataset, self).__init__()\n",
    "        \n",
    "        self.nodes = nodes\n",
    "        self.edges = edges\n",
    "        self.y = y\n",
    "        self.relations = relations\n",
    "        self.idx = idx\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.idx[idx]\n",
    "        edge_index = torch.tensor(self.edges[idx].T, dtype=torch.long)\n",
    "        x = torch.tensor(self.nodes[idx], dtype=torch.long)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.float)\n",
    "        edge_type = torch.tensor(self.relations[idx], dtype=torch.float)\n",
    "        return Data(x=x,edge_index=edge_index,edge_type=edge_type,y=y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n",
    "    \n",
    "    def collate_fn(self,batch):\n",
    "        pass\n",
    "\n",
    "def preprocess_test(smiles):\n",
    "    nodes = []\n",
    "    edges = []\n",
    "    relations = []\n",
    "    lens = []\n",
    "    adjs = []\n",
    "    ords = []\n",
    "    for i in range(len(smiles)):\n",
    "        node, adj, order = gen_smiles2graph(smiles[i])\n",
    "        if node == 'error':\n",
    "            print(i, smiles, 'error')\n",
    "            continue\n",
    "        lens.append(adj.shape[0])\n",
    "        adjs.append(adj)  \n",
    "        ords.append(order)\n",
    "        node[:,2] += 1\n",
    "        node[:,3] -= 1\n",
    "        nodes.append(node)\n",
    "\n",
    "    adjs = np.array(adjs)\n",
    "    lens = np.array(lens)\n",
    "\n",
    "    def file2array(path, delimiter=' '):     \n",
    "        fp = open(path, 'r', encoding='utf-8')\n",
    "        string = fp.read()              \n",
    "        fp.close()\n",
    "        row_list = string.splitlines()  \n",
    "        data_list = [[float(i) for i in row.strip().split(',')] for row in row_list]\n",
    "        return np.array(data_list)\n",
    "\n",
    "    def adj2idx(adj):\n",
    "        idx = []\n",
    "        for i in range(adj.shape[0]):\n",
    "            for j in range(adj.shape[1]):\n",
    "                if adj[i,j] == 1:\n",
    "                    idx.append([i,j])\n",
    "        return np.array(idx)\n",
    "\n",
    "    def order2relation(adj):\n",
    "        idx = []\n",
    "        for i in range(adj.shape[0]):\n",
    "            for j in range(adj.shape[1]):\n",
    "                if adj[i,j] != 0:\n",
    "                    idx.extend([adj[i,j]])\n",
    "        return np.array(idx)\n",
    "\n",
    "    for i in range(lens.shape[0]):\n",
    "        adj = adjs[i]\n",
    "        order = ords[i]\n",
    "        idx = adj2idx(adj)\n",
    "        relation = order2relation(order)-1\n",
    "        edges.append(idx)\n",
    "        relations.append(relation)\n",
    "\n",
    "    return smiles, nodes, edges, relations\n",
    "\n",
    "\n",
    "def gen_smiles2graph(sml):\n",
    "    \"\"\"Argument for the RD2NX function should be a valid SMILES sequence\n",
    "    returns: the graph\n",
    "    \"\"\"\n",
    "    ls = [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 30, 33, 34, 35, 36, 37, 38, 47, 52, 53, 54, 55, 56, 83, 88]\n",
    "    dic = {}\n",
    "    for i in range(len(ls)):\n",
    "        dic[ls[i]] = i\n",
    "    m = rdkit.Chem.MolFromSmiles(sml)\n",
    "#    m = rdkit.Chem.AddHs(m)\n",
    "    order_string = {\n",
    "        rdkit.Chem.rdchem.BondType.SINGLE: 1,\n",
    "        rdkit.Chem.rdchem.BondType.DOUBLE: 2,\n",
    "        rdkit.Chem.rdchem.BondType.TRIPLE: 3,\n",
    "        rdkit.Chem.rdchem.BondType.AROMATIC: 4,\n",
    "    }\n",
    "    N = len(list(m.GetAtoms()))\n",
    "    nodes = np.zeros((N, 6))\n",
    "\n",
    "    try:\n",
    "        test = m.GetAtoms()\n",
    "    except:\n",
    "        return 'error', 'error', 'error'\n",
    "\n",
    "    for i in m.GetAtoms():\n",
    "        atom_types= dic[i.GetAtomicNum()]\n",
    "        atom_degree= i.GetDegree()\n",
    "        atom_form_charge= i.GetFormalCharge()\n",
    "        atom_hybridization= i.GetHybridization()\n",
    "        atom_aromatic= i.GetIsAromatic()\n",
    "        atom_chirality= i.GetChiralTag()\n",
    "        nodes[i.GetIdx()] = [atom_types, atom_degree, atom_form_charge, atom_hybridization, atom_aromatic, atom_chirality]\n",
    "\n",
    "    adj = np.zeros((N, N))\n",
    "    orders = np.zeros((N, N))\n",
    "    for j in m.GetBonds():\n",
    "        u = min(j.GetBeginAtomIdx(), j.GetEndAtomIdx())\n",
    "        v = max(j.GetBeginAtomIdx(), j.GetEndAtomIdx())\n",
    "        order = j.GetBondType()\n",
    "        if order in order_string:\n",
    "            order = order_string[order]        \n",
    "        else:\n",
    "            raise Warning(\"Ignoring bond order\" + order)\n",
    "        adj[u, v] = 1\n",
    "        adj[v, u] = 1\n",
    "        orders[u, v] = order\n",
    "        orders[v, u] = order\n",
    "#    adj += np.eye(N)\n",
    "    return nodes, adj, orders\n",
    "\n",
    "def get_preds(probabilities, threshold=0.5):\n",
    "            return [1 if prob > threshold else 0 for prob in probabilities]\n",
    "    \n",
    "    \n",
    "def GVAE_predict(smi, enzyme, model_path=model_path, device='cpu'): \n",
    "    \n",
    "    smiles, nodes, edges, relations = preprocess_test([smi])\n",
    "    y = [0]*len(smiles)\n",
    "#     print(len(smiles))\n",
    "    \n",
    "    test_set = GDataset(nodes, edges, relations,y, range(len(smiles)))\n",
    "    test_loader = DataLoader(test_set, batch_size=len(smiles), shuffle=False)\n",
    "\n",
    "    model = torch.load(model_path+'GVAE'+ '_' + enzyme + '.pt')\n",
    "#     print(model_path+'GVAE'+ '_' + enzyme + '.pt')\n",
    "    model.eval()\n",
    "    for data in test_loader:\n",
    "        data.to(device)\n",
    "        preds = model(data.x, data.edge_index, data.edge_type, data.batch, 'fintune')\n",
    "#         print(preds)\n",
    "#         print(get_preds(preds)[0])\n",
    "        \n",
    "    return preds, get_preds(preds)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b71972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If cuda available: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "adj_max=80\n",
    "fps_len=167\n",
    "max_len=120\n",
    "\n",
    "adj_max=80\n",
    "fps_len=167\n",
    "max_len=120\n",
    "device = torch.device('cpu')\n",
    "model_path = 'model/'\n",
    "class chembert_encoder(nn.Module):\n",
    "    def __init__(self, output_dim=fps_len,dropout=0.5):\n",
    "        super(chembert_encoder, self).__init__()\n",
    "        self.bert = AutoModelWithLMHead.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.w=nn.Linear(767,output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_feat = self.tokenizer.batch_encode_plus(x, max_length=512,\n",
    "                                                 padding='longest',  # implements dynamic padding\n",
    "                                                 truncation=True,\n",
    "                                                 return_tensors='pt',\n",
    "                                                 return_attention_mask=True,\n",
    "                                                 return_token_type_ids=True\n",
    "                                                 )\n",
    "\n",
    "        if cuda_available:\n",
    "            input_feat['attention_mask'] = input_feat['attention_mask'].cuda()\n",
    "            input_feat['input_ids'] = input_feat['input_ids'].cuda()\n",
    "\n",
    "\n",
    "        outputs = self.bert(input_feat['input_ids'], attention_mask=input_feat['attention_mask'],output_hidden_states=None).logits[:,0,:]\n",
    "        return self.w(self.dropout(outputs))\n",
    "class pretrain_dataset(Dataset):\n",
    "    def __init__(self,dataframe, max_len=max_len):\n",
    "        super(pretrain_dataset, self).__init__()\n",
    "        self.len = len(dataframe)\n",
    "        self.dataframe = dataframe\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sml = self.dataframe.canonical_smiles[idx]\n",
    "        chem_id = self.dataframe.chembl_id[idx]\n",
    "        s = self.dataframe.fps[idx]\n",
    "        s = list(s)\n",
    "        adj = torch.tensor([int(b) for b in s])\n",
    "        return sml, adj, chem_id\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "class jak_dataset_chembert(Dataset):\n",
    "    def __init__(self,dataframe):\n",
    "        super(jak_dataset_chembert, self).__init__()\n",
    "        self.len = len(dataframe)\n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sml = self.dataframe.Smiles[idx]\n",
    "        y = 1 if self.dataframe.Activity[idx] ==  1 else 0\n",
    "        return sml, y\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "class chembert(nn.Module):\n",
    "    def __init__(self, load_path='model/chem_bert_encoder_pretrain_9.pt', \n",
    "                 last_layer_size=fps_len, output_size=2, dropout=0.5):\n",
    "        super(chembert, self).__init__()\n",
    "        self.last_layer_size = last_layer_size\n",
    "        self.output_size = output_size\n",
    "        self.pretrained = chembert_encoder()\n",
    "        self.pretrained.load_state_dict(torch.load(load_path, map_location=device))\n",
    "        self.w = nn.Linear(self.last_layer_size, self.output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        return self.w(self.dropout(self.pretrained(x)))\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"If cuda available:\", cuda_available)    \n",
    "def chembert_predict(smi, enzyme):\n",
    "    ml = 'chembert'\n",
    "    known_drugs = [smi]\n",
    "\n",
    "    file_path = 'model/' + ml + '_' + enzyme + '.pt'\n",
    "    model = chembert()\n",
    "    optimizer = optim.AdamW(params=model.parameters(), lr=1e-5, weight_decay=1e-2)\n",
    "    model.load_state_dict(torch.load(file_path, map_location=torch.device('cpu')))\n",
    "    weight_dict = {1: torch.tensor([3.0, 1.0]), 2: torch.tensor([2.0, 1.0]), 3: torch.tensor([2.0, 1.0]),\n",
    "                    4: torch.tensor([2.0, 1.0])}\n",
    "    params = {'batch_size': 16, 'shuffle': False, 'drop_last': False, 'num_workers': 0}\n",
    "    model.eval()\n",
    "\n",
    "    known_df = pd.DataFrame(known_drugs)\n",
    "    known_df.columns = ['Smiles']\n",
    "    known_df['Activity'] = 0\n",
    "    known_data = jak_dataset_chembert(known_df)\n",
    "    known_loader = DataLoader(known_data, **params)\n",
    "    for idx, (X, y_true) in tqdm(enumerate(known_loader), total=len(known_loader)):\n",
    "        model.eval()\n",
    "        output = model(list(X))\n",
    "        a, y_pred = torch.max(output, 1)\n",
    "        y_prob = torch.softmax(output,1)[:, 1].tolist()\n",
    "\n",
    "    return y_prob, y_pred\n",
    "def smile_list_to_MACCS(smi_list):\n",
    "    MACCS_list = []\n",
    "    if isinstance(smi_list, str):\n",
    "        smi_list = [smi_list]\n",
    "    for smi in smi_list:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        maccs = list(MACCSkeys.GenMACCSKeys(mol).ToBitString())\n",
    "        MACCS_list.append(maccs)\n",
    "        \n",
    "        header = ['bit' + str(i) for i in range(167)]\n",
    "        df = pd.DataFrame(MACCS_list,columns=header)\n",
    "        maccs = df.values\n",
    "    return maccs\n",
    "def simp_model_predict(smi, enzyme, ml): # Works for SVM_poly, RF, XGBoost\n",
    "    modelname = ml + '_' + enzyme + '.sav'\n",
    "    model = pickle.load(open(model_path+modelname, 'rb'))\n",
    "    maccs = smile_list_to_MACCS(smi)\n",
    "    pred = model.predict(maccs)\n",
    "    prob = model.predict_proba(maccs)\n",
    "#     type(prob[0][1])\n",
    "#     print(ml, pred, prob, prob[0][1])\n",
    "    return prob[0][1], pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47877c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49a2f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GVAE_predict(smi, enzyme, model_path=model_path, device='cpu'): \n",
    "    \n",
    "    smiles, nodes, edges, relations = preprocess_test(smi)\n",
    "    y = [0]*len(smiles)\n",
    "#     print(len(smiles))\n",
    "    \n",
    "    test_set = GDataset(nodes, edges, relations,y, range(len(smiles)))\n",
    "    test_loader = DataLoader(test_set, batch_size=len(smiles), shuffle=False)\n",
    "\n",
    "    model = torch.load(model_path+'GVAE'+ '_' + enzyme + '.pt')\n",
    "#     print(model_path+'GVAE'+ '_' + enzyme + '.pt')\n",
    "    model.eval()\n",
    "    for data in test_loader:\n",
    "        data.to(device)\n",
    "        preds = model(data.x, data.edge_index, data.edge_type, data.batch, 'fintune')\n",
    "#         print(preds)\n",
    "#         print(get_preds(preds)[0])\n",
    "        \n",
    "    return preds, get_preds(preds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca17ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chembert_predict(smi, enzyme):\n",
    "    ml = 'chembert'\n",
    "    known_drugs = smi\n",
    "\n",
    "    file_path = 'model/' + ml + '_' + enzyme + '.pt'\n",
    "    model = chembert()\n",
    "    optimizer = optim.AdamW(params=model.parameters(), lr=1e-5, weight_decay=1e-2)\n",
    "    model.load_state_dict(torch.load(file_path, map_location=torch.device('cpu')))\n",
    "    weight_dict = {1: torch.tensor([3.0, 1.0]), 2: torch.tensor([2.0, 1.0]), 3: torch.tensor([2.0, 1.0]),\n",
    "                    4: torch.tensor([2.0, 1.0])}\n",
    "    params = {'batch_size': 32, 'shuffle': False, 'drop_last': False, 'num_workers': 0}\n",
    "    model.eval()\n",
    "\n",
    "    known_df = pd.DataFrame(known_drugs)\n",
    "    known_df.columns = ['Smiles']\n",
    "    known_df['Activity'] = 0\n",
    "    known_data = jak_dataset_chembert(known_df)\n",
    "    known_loader = DataLoader(known_data, **params)\n",
    "    for idx, (X, y_true) in tqdm(enumerate(known_loader), total=len(known_loader)):\n",
    "        model.eval()\n",
    "        output = model(list(X))\n",
    "        a, y_pred = torch.max(output, 1)\n",
    "        if idx == 0:\n",
    "            y_prob = torch.softmax(output,1)[:, 1].tolist()\n",
    "        else:\n",
    "            y_prob.extend(torch.softmax(output,1)[:, 1].tolist())\n",
    "        \n",
    "\n",
    "    return y_prob, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fe32e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:998: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|███████████████████████████████████████████| 76/76 [00:52<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for enzyme in ['TYK2']:\n",
    "    data_path = 'data/' + enzyme + '_new.csv'\n",
    "    data = pd.read_csv(data_path)\n",
    "    smiles = data['Smiles']\n",
    "#     header = ['bit' + str(i) for i in range(167)]\n",
    "#     maccs = data[header]\n",
    "    y = data['Activity']\n",
    "#     new_data = pd.DataFrame()\n",
    "#     new_data['Smiles'] = smiles\n",
    "#     new_data['Activity'] = y\n",
    "    prob, _ = chembert_predict(smiles, enzyme)\n",
    "    data['prob_bert'] = prob\n",
    "    \n",
    "    \n",
    "    \n",
    "#     data['prob_graph'] = [p[0] for p in prob.detach().numpy().tolist()]\n",
    "#     print(data)\n",
    "#     data.to_csv('data/'+enzyme+'_new.csv')\n",
    "# #     for ml in ['SVM_poly', 'RF', 'XGBoost']:\n",
    "#         modelname = ml + '_' + enzyme + '.sav'\n",
    "#         model = pickle.load(open(model_path+modelname, 'rb'))\n",
    "#         prob = model.predict_proba(maccs)\n",
    "#         print(prob[:,1].shape)\n",
    "#         new_data['prob_'+ml] = prob[:,1]\n",
    "#     new_data.to_csv('data/' + enzyme + '_new.csv')\n",
    "#         print(prob[0,0])\n",
    "#         print(prob[0,1])\n",
    "# new_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47964106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Activity</th>\n",
       "      <th>prob_SVM_poly</th>\n",
       "      <th>prob_RF</th>\n",
       "      <th>prob_XGBoost</th>\n",
       "      <th>prob_graph</th>\n",
       "      <th>prob_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CC1=CC(=NN1)NC2=NC(=NC=C2Cl)NC(C)C3=NC=C(C=N3)F</td>\n",
       "      <td>1</td>\n",
       "      <td>0.946587</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.946195</td>\n",
       "      <td>0.070088</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>COC1=C(C=CC(=C1)N2CCOCC2)NC3=NC4=C(C=CN4)C(=N3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063768</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.047611</td>\n",
       "      <td>0.044365</td>\n",
       "      <td>0.005377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>C1CC1NC2CCC(C(C2)C#N)N3C=C(C(=N3)NC4=CC=C(C=C4...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>CC1(CN(C1)C2CCC(C(C2)C#N)N3C=C(C(=N3)NC4=CC=CC...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>CC1CN(C1)C2CCC(C(C2)C#N)N3C=C(C(=N3)NC4=CC=CC=...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>2419</td>\n",
       "      <td>2419</td>\n",
       "      <td>C1COCCN1CCN2C=C(C(=N2)C3=CC(=CC=C3)Cl)NC(=O)C4...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063729</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.077699</td>\n",
       "      <td>0.219703</td>\n",
       "      <td>0.007970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>2420</td>\n",
       "      <td>2420</td>\n",
       "      <td>CC1=CC(=C(C=N1)C2=CC(=CC=C2)Cl)NC(=O)C3=C4N=CC...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063798</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.136815</td>\n",
       "      <td>0.267499</td>\n",
       "      <td>0.025846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>2421</td>\n",
       "      <td>2421</td>\n",
       "      <td>CN1C=C(C(=N1)NC(=O)C2=C3N=CC=CN3N=C2)C4=CC(=CC...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063536</td>\n",
       "      <td>0.059798</td>\n",
       "      <td>0.389533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>2422</td>\n",
       "      <td>2422</td>\n",
       "      <td>CC1=CC=CC=C1C2=NN(C=C2NC(=O)C3=C4N=C(C=CN4N=C3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222232</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.166867</td>\n",
       "      <td>0.235252</td>\n",
       "      <td>0.028835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>2423</td>\n",
       "      <td>2423</td>\n",
       "      <td>CC1=NN(C(=C1)NC(=O)C2=C3N=C(C=CN3N=C2)N)C4=CC(...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063781</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.159411</td>\n",
       "      <td>0.653921</td>\n",
       "      <td>0.302964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2424 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0  \\\n",
       "0                0           0   \n",
       "1                1           1   \n",
       "2                2           2   \n",
       "3                3           3   \n",
       "4                4           4   \n",
       "...            ...         ...   \n",
       "2419          2419        2419   \n",
       "2420          2420        2420   \n",
       "2421          2421        2421   \n",
       "2422          2422        2422   \n",
       "2423          2423        2423   \n",
       "\n",
       "                                                 Smiles  Activity  \\\n",
       "0       CC1=CC(=NN1)NC2=NC(=NC=C2Cl)NC(C)C3=NC=C(C=N3)F         1   \n",
       "1     COC1=C(C=CC(=C1)N2CCOCC2)NC3=NC4=C(C=CN4)C(=N3...         0   \n",
       "2     C1CC1NC2CCC(C(C2)C#N)N3C=C(C(=N3)NC4=CC=C(C=C4...         1   \n",
       "3     CC1(CN(C1)C2CCC(C(C2)C#N)N3C=C(C(=N3)NC4=CC=CC...         1   \n",
       "4     CC1CN(C1)C2CCC(C(C2)C#N)N3C=C(C(=N3)NC4=CC=CC=...         1   \n",
       "...                                                 ...       ...   \n",
       "2419  C1COCCN1CCN2C=C(C(=N2)C3=CC(=CC=C3)Cl)NC(=O)C4...         0   \n",
       "2420  CC1=CC(=C(C=N1)C2=CC(=CC=C2)Cl)NC(=O)C3=C4N=CC...         0   \n",
       "2421  CN1C=C(C(=N1)NC(=O)C2=C3N=CC=CN3N=C2)C4=CC(=CC...         0   \n",
       "2422  CC1=CC=CC=C1C2=NN(C=C2NC(=O)C3=C4N=C(C=CN4N=C3...         0   \n",
       "2423  CC1=NN(C(=C1)NC(=O)C2=C3N=C(C=CN3N=C2)N)C4=CC(...         0   \n",
       "\n",
       "      prob_SVM_poly   prob_RF  prob_XGBoost  prob_graph  prob_bert  \n",
       "0          0.946587  0.846154      0.946195    0.070088   0.999986  \n",
       "1          0.063768  0.153846      0.047611    0.044365   0.005377  \n",
       "2          0.978703  1.000000      0.999970    1.000000   0.999998  \n",
       "3          0.985461  1.000000      0.997468    1.000000   0.999998  \n",
       "4          0.957758  1.000000      0.996922    1.000000   0.999998  \n",
       "...             ...       ...           ...         ...        ...  \n",
       "2419       0.063729  0.307692      0.077699    0.219703   0.007970  \n",
       "2420       0.063798  0.076923      0.136815    0.267499   0.025846  \n",
       "2421       0.060402  0.000000      0.063536    0.059798   0.389533  \n",
       "2422       0.222232  0.230769      0.166867    0.235252   0.028835  \n",
       "2423       0.063781  0.076923      0.159411    0.653921   0.302964  \n",
       "\n",
       "[2424 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enzyme ='JAK2'\n",
    "# data_path = 'data/' + enzyme + '_new.csv'\n",
    "# data = pd.read_csv(data_path)\n",
    "# data['prob_bert'] = prob\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "779ebad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme = 'TYK2'\n",
    "data.iloc[:,2:].to_csv('data/'+ enzyme+'_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ff9d655f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enzymes = ['JAK1', 'JAK2', 'JAK3', 'TYK2']\n",
    "ind = enzymes.index(enzyme)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5d22961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.array([[0.8725, 0.8156, 0.8013, 1.1736, 1.5972],\\\n",
    "          [1.1116, 0.8958, 0.7605, 1.3776, 1.7598],\\\n",
    "          [0.7654, 1.1997, 0.3108, 1.2645, 1.5275],\\\n",
    "          [0.4161, 0.2859, 1.1439, 1.2353, 0.4284]\n",
    "         ])\n",
    "bias = [-2.1325, -2.955, -2.5899, -1.7482]\n",
    "\n",
    "def get_preds(probabilities, threshold=0.5):\n",
    "            return [1 if prob > threshold else 0 for prob in probabilities]\n",
    "sigmoid(np.array(prob_all)@params[3]+bias[3])\n",
    "\n",
    "def comodel_predict(smi, enzyme):\n",
    "    prob_all = []\n",
    "    for ml in ['SVM_poly', 'RF', 'XGBoost']:\n",
    "        prob, pred = simp_model_predict(smi, enzyme, ml)\n",
    "        prob_all.append(prob)\n",
    "    prob, pred = GVAE_predict(smi, enzyme)\n",
    "    prob_all.append(prob.detach().numpy()[0][0])\n",
    "    prob, pred = chembert_predict(smi, enzyme)\n",
    "    prob_all.append(prob[0])\n",
    "#     print(prob_all)\n",
    "    params = np.array([[0.8725, 0.8156, 0.8013, 1.1736, 1.5972],\\\n",
    "          [1.1116, 0.8958, 0.7605, 1.3776, 1.7598],\\\n",
    "          [0.7654, 1.1997, 0.3108, 1.2645, 1.5275],\\\n",
    "          [0.4161, 0.2859, 1.1439, 1.2353, 0.4284]\n",
    "         ])\n",
    "    bias = [-2.1325, -2.955, -2.5899, -1.7482]\n",
    "    enzymes = ['JAK1', 'JAK2', 'JAK3', 'TYK2']\n",
    "    ind = enzymes.index(enzyme)\n",
    "\n",
    "    prob = sigmoid(np.array(prob_all)@params[ind]+bias[ind])\n",
    "#     print(prob)\n",
    "    pred = 0\n",
    "    if prob > 0.5: pred = 1\n",
    "    return prob, pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4e2ea94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/var/folders/gf/vwysj66x7v9ftw5l2pbq6mkh0000gn/T/ipykernel_17480/1433744090.py:554: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if node == 'error':\n",
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:998: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 32.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7084340221697142, 0.9230769230769231, 0.99970907, 0.99999976, 0.9842766523361206]\n",
      "0.8335526906200444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8335526906200444, 1)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob, pred = comodel_predict(Ruxo, 'TYK2')\n",
    "prob, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f1f34763",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = {}\n",
    "smiles['RUXOLITINIB'] = 'N#CC[C@H](C1CCCC1)n1cc(-c2ncnc3[nH]ccc23)cn1'\n",
    "smiles['TOFACITINIB'] = 'C[C@@H]1CCN(C(=O)CC#N)C[C@@H]1N(C)c1ncnc2[nH]ccc12'\n",
    "smiles['BARICITINIB'] = 'CCS(=O)(=O)N1CC(CC#N)(n2cc(-c3ncnc4[nH]ccc34)cn2)C1'\n",
    "smiles['FEDRATINIB'] = 'Cc1cnc(Nc2ccc(OCCN3CCCC3)cc2)nc1Nc1cccc(S(=O)(=O)NC(C)(C)C)c1'\n",
    "smiles['UPADACITINIB'] = 'CC[C@@H]1CN(C(=O)NCC(F)(F)F)C[C@@H]1c1cnc2cnc3[nH]ccc3n12'\n",
    "smiles['FILGOTINIB'] = 'O=C(Nc1nc2cccc(-c3ccc(CN4CCS(=O)(=O)CC4)cc3)n2n1)C1CC1'\n",
    "smiles['FOSTAMATINIB'] = 'COc1cc(Nc2ncc(F)c(Nc3ccc4c(n3)N(COP(=O)(O)O)C(=O)C(C)(C)O4)n2)cc(OC)c1OC'\n",
    "smiles['PRALSETINIB'] = 'CO[C@]1(C(=O)N[C@@H](C)c2ccc(-n3cc(F)cn3)nc2)CC[C@H](c2nc(C)cc(Nc3cc(C)[nH]n3)n2)CC1'\n",
    "smiles['ABROCITINIB'] = 'CCCS(=O)(=O)N[C@H]1C[C@@H](N(C)c2ncnc3[nH]ccc23)C1'\n",
    "smiles['IVARMACITINIB'] = 'CN(C1CC2CN(CC2C1)C(=O)NC3=NC(=NS3)OC)C4=NC=NC5=C4C=CN5'\n",
    "smiles['ENTRECTIN'] = 'CN1CCN(c2ccc(C(=O)Nc3n[nH]c4ccc(Cc5cc(F)cc(F)c5)cc34)c(NC3CCOCC3)c2)CC1'\n",
    "smiles['ZANUBRUTINIB'] = 'C=CC(=O)N1CCC([C@@H]2CCNc3c(C(N)=O)c(-c4ccc(Oc5ccccc5)cc4)nn32)CC1'\n",
    "smiles['PACRITINIB'] = 'C1=C/COCc2cc(ccc2OCCN2CCCC2)Nc2nccc(n2)-c2cccc(c2)COC/1'\n",
    "smiles['DEUCRAVACITINIB'] = 'CNC(=O)c1nnc(NC(=O)C2CC2)cc1Nc1cccc(-c2ncn(C)n2)c1OC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b3b2d8a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 39.53it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 36.15it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 29.26it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 34.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUXOLITINIB : [0.9310353712561901, 0.8964419142988697, 0.8848545012204965, 0.8335526906200444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 34.28it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.01it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 24.35it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOFACITINIB : [0.9047597896240225, 0.6888824415592857, 0.8986511011553572, 0.8476106049185537]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.73it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 35.30it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 28.17it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 29.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BARICITINIB : [0.9414459852284875, 0.6431020033676541, 0.8953655423176606, 0.8333883467977719]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 17.37it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 27.94it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.86it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 26.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEDRATINIB : [0.9514361885643929, 0.9109518787413518, 0.10292761982410945, 0.8406588964593642]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 31.45it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.26it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 27.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPADACITINIB : [0.9518874560596083, 0.930210621168223, 0.8258720675402623, 0.8114001442718035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 31.48it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 27.69it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 24.18it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 18.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILGOTINIB : [0.9450338818173494, 0.6980818040052356, 0.9090048079542682, 0.5225626249325388]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 24.97it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 22.40it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 32.66it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 26.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOSTAMATINIB : [0.39084098859754984, 0.37344704218716684, 0.2735588421421813, 0.39590688739797836]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 30.75it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 24.85it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 28.52it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 25.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRALSETINIB : [0.9355536591875716, 0.43564518049568174, 0.6808769674088112, 0.8312344465471059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 40.82it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 42.99it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 26.21it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 43.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABROCITINIB : [0.957647955861615, 0.09386063453842206, 0.10799649139325414, 0.8402939448507186]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 32.12it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 28.63it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 32.54it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 37.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IVARMACITINIB : [0.9321728395464168, 0.6905835657332553, 0.8054671665056146, 0.8310606461777141]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 31.70it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 27.22it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 32.24it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 34.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRECTIN : [0.7717344584885198, 0.9016146244386689, 0.8808620217834259, 0.7630760343626596]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 31.78it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 40.80it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 34.88it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 36.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZANUBRUTINIB : [0.8607885569310624, 0.9017749621633505, 0.883788436139553, 0.5630746732854711]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 29.03it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 28.75it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 25.92it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 36.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PACRITINIB : [0.2325799206979232, 0.9415492725345418, 0.7037219748671781, 0.8502065997045194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 29.49it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 33.63it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 29.99it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 33.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEUCRAVACITINIB : [0.923821852859347, 0.46364615617043814, 0.7619599473915099, 0.8341708687421043]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for i in smiles:\n",
    "    smi = smiles.get(i)\n",
    "    enzymes = ['JAK1', 'JAK2', 'JAK3', 'TYK2']\n",
    "#     print(i)\n",
    "    probs = []\n",
    "    for enzyme in enzymes: \n",
    "        prob, _ = comodel_predict(smi, enzyme)\n",
    "        probs.append(prob)\n",
    "    print(i, ':', probs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7c7bae9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/var/folders/gf/vwysj66x7v9ftw5l2pbq6mkh0000gn/T/ipykernel_17480/1433744090.py:554: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if node == 'error':\n",
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:998: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for  SVM_poly\n",
      "0.7084340221697142 1\n",
      "for  RF\n",
      "0.9230769230769231 1\n",
      "for  XGBoost\n",
      "0.99970907 1\n",
      "tensor([[1.0000]], grad_fn=<SigmoidBackward0>)\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 43.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9842766523361206]\n",
      "tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7084340221697142,\n",
       " 0.9230769230769231,\n",
       " 0.99970907,\n",
       " 0.99999976,\n",
       " 0.9842766523361206]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ruxo = 'N#CC[C@H](C1CCCC1)n1cc(-c2ncnc3[nH]ccc23)cn1'\n",
    "prob_all = []\n",
    "\n",
    "for ml in ['SVM_poly', 'RF', 'XGBoost']:\n",
    "    jak = 'TYK2'\n",
    "    prob, pred = simp_model_predict(Ruxo, jak, ml)\n",
    "    print('for ', ml)\n",
    "    print(prob, pred)\n",
    "    prob_all.append(prob)\n",
    "\n",
    "prob, pred = GVAE_predict(Ruxo, 'TYK2')\n",
    "print(prob)\n",
    "print(pred)\n",
    "prob_all.append(prob.detach().numpy()[0][0])\n",
    "prob, pred = chembert_predict(Ruxo, 'TYK2')\n",
    "print(prob)\n",
    "print(pred)\n",
    "prob_all.append(prob[0])\n",
    "\n",
    "prob_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "77f8fe48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8335526906200444"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.array([[0.8725, 0.8156, 0.8013, 1.1736, 1.5972],\\\n",
    "          [1.1116, 0.8958, 0.7605, 1.3776, 1.7598],\\\n",
    "          [0.7654, 1.1997, 0.3108, 1.2645, 1.5275],\\\n",
    "          [0.4161, 0.2859, 1.1439, 1.2353, 0.4284]\n",
    "         ])\n",
    "bias = [-2.1325, -2.955, -2.5899, -1.7482]\n",
    "\n",
    "sigmoid(np.array(prob_all)@params[3]+bias[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0a4342ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8725, 1.1116, 0.7654, 0.4161],\n",
       "       [0.8156, 0.8958, 1.1997, 0.2859],\n",
       "       [0.8013, 0.7605, 0.3108, 1.1439],\n",
       "       [1.1736, 1.3776, 1.2645, 1.2353],\n",
       "       [1.5972, 1.7598, 1.5275, 0.4284]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ada7a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_predict(smi, enzyme):\n",
    "    ml = 'CNN'\n",
    "    known_drugs = [smi]\n",
    "\n",
    "    file_path = 'model/' + ml + '_' + enzyme + '.pt'\n",
    "#     print(file_path)\n",
    "    weight_dict = {1: torch.tensor([3.0, 1.0]), 2: torch.tensor([2.0, 1.0]), 3: torch.tensor([2.0, 1.0]),\n",
    "                    4: torch.tensor([2.0, 1.0])}\n",
    "    model = CNNforclassification(max_len, len(vocabulary))\n",
    "    model.load_state_dict(torch.load(file_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "\n",
    "    params = {'batch_size':16, 'shuffle':False, 'drop_last':False, 'num_workers':0}\n",
    "\n",
    "    known_df = pd.DataFrame(known_drugs)\n",
    "    known_df.columns = ['Smiles']\n",
    "    known_df['Activity'] = 0\n",
    "    known_data = jak_dataset(known_df)\n",
    "    known_loader = DataLoader(known_data, **params)\n",
    "    for idx, (X, y_true) in tqdm(enumerate(known_loader), total=len(known_loader)):\n",
    "#         print(X)\n",
    "        model.eval()\n",
    "#         print(X)\n",
    "        output = model(X.clone().detach())\n",
    "#         print(output)\n",
    "        a, y_pred = torch.max(output, 1)\n",
    "    #     print(a)\n",
    "    #     print(output)\n",
    "    #     print(torch.max(torch.softmax(output, 1), 1)[0].tolist())\n",
    "    #     print(a.tolist())\n",
    "    #     print(torch.max(torch.softmax(output, 1), 1)[1].tolist())\n",
    "        y_prob = torch.softmax(output,1)[:, 1].tolist()\n",
    "        # print(y_prob)\n",
    "        # print(y_pred.tolist())\n",
    "    return y_prob, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82bd667b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def GVAE_pred(smi, enzyme, model_path=model_path, device='cpu'): \n",
    "\n",
    "    smiles, nodes, edges, relations = preprocess_test([smi])\n",
    "    y = [0]*len(smiles)\n",
    "#     print(len(smiles))\n",
    "    \n",
    "    test_set = GDataset(nodes, edges, relations,y, range(len(smiles)))\n",
    "    test_loader = DataLoader(test_set, batch_size=len(smiles), shuffle=False)\n",
    "\n",
    "    model = torch.load(model_path+'GVAE'+ '_' + enzyme + '.pt')\n",
    "#     print(model_path+'GVAE'+ '_' + enzyme + '.pt')\n",
    "    model.eval()\n",
    "    for data in test_loader:\n",
    "        data.to(device)\n",
    "        preds = model(data.x, data.edge_index, data.edge_type, data.batch, 'fintune')\n",
    "#         print(preds)\n",
    "#         print(get_preds(preds)[0])\n",
    "        \n",
    "    return preds, get_preds(preds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b75226ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for enzyme in ['JAK1']:\n",
    "    data_path = 'data/' + enzyme + '_new.csv'\n",
    "    data = pd.read_csv(data_path)\n",
    "    y = data['Activity'].to_numpy()\n",
    "    probs = data.iloc[:,3:].to_numpy()\n",
    "    probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1cf46217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "probs = torch.Tensor(probs)\n",
    "ys = torch.Tensor(y)\n",
    "import torch.utils.data as utils\n",
    "use_cuda = False\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "dataset = utils.TensorDataset(probs, ys)\n",
    "\n",
    "split = 0.8\n",
    "train_num = int(split*probs.size(0))\n",
    "test_num = probs.size(0) - train_num\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_num, test_num], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=test_num, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e9855825",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(5, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fe94d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_BCE(output, target, weight=None):  \n",
    "    if weight is not None:     \n",
    "        loss = 1 * (target * torch.log(output)) + \\\n",
    "               weight * ((1 - target) * torch.log(1 - output))\n",
    "    else:\n",
    "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
    "    return torch.neg(torch.mean(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a481ffbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1:\n",
      "0.002126151665485471 0.9997771339425006 0.5009516428039931\n",
      "0.0 0.9991063449508489 0.49955317247542447\n",
      "epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uranaieiko_1/opt/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002126151665485471 1.0 0.5010630758327428\n",
      "0.0 0.9991063449508489 0.49955317247542447\n",
      "epoch 3:\n",
      "0.001417434443656981 1.0 0.5007087172218285\n",
      "0.0 0.9991063449508489 0.49955317247542447\n",
      "epoch 4:\n",
      "0.0007087172218284905 1.0 0.5003543586109143\n",
      "0.0 0.9991063449508489 0.49955317247542447\n",
      "epoch 5:\n",
      "0.0007087172218284905 1.0 0.5003543586109143\n",
      "0.0 1.0 0.5\n",
      "epoch 6:\n",
      "0.0007087172218284905 1.0 0.5003543586109143\n",
      "0.0 1.0 0.5\n",
      "epoch 7:\n",
      "0.0007087172218284905 1.0 0.5003543586109143\n",
      "0.0 1.0 0.5\n",
      "epoch 8:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 9:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 10:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 11:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 12:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 13:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 14:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 15:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 16:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 17:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 18:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 19:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 20:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 21:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 22:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 23:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 24:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 25:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 26:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 27:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 28:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 29:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 30:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 31:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 32:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 33:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 34:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 35:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 36:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 37:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 38:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 39:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 40:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 41:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 42:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 43:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 44:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 45:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 46:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 47:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 48:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 49:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 50:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 51:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 52:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 53:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 54:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 55:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 56:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 57:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 58:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 59:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 60:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 61:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 62:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 63:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 64:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 65:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 66:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 67:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 68:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 69:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 70:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 71:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 72:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 73:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 74:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 75:\n",
      "0.0 1.0 0.5\n",
      "0.0 1.0 0.5\n",
      "epoch 76:\n",
      "0.01559177888022679 1.0 0.5077958894401134\n",
      "0.10674157303370786 1.0 0.5533707865168539\n",
      "epoch 77:\n",
      "0.12756909992912827 1.0 0.5637845499645642\n",
      "0.1797752808988764 1.0 0.5898876404494382\n",
      "epoch 78:\n",
      "0.1785967399007796 1.0 0.5892983699503898\n",
      "0.23595505617977527 1.0 0.6179775280898876\n",
      "epoch 79:\n",
      "0.22749822820694543 1.0 0.6137491141034728\n",
      "0.28651685393258425 1.0 0.6432584269662921\n",
      "epoch 80:\n",
      "0.2721474131821403 1.0 0.6360737065910702\n",
      "0.3539325842696629 1.0 0.6769662921348314\n",
      "epoch 81:\n",
      "0.333805811481219 1.0 0.6669029057406095\n",
      "0.41853932584269665 1.0 0.7092696629213483\n",
      "epoch 82:\n",
      "0.3862508858965273 1.0 0.6931254429482636\n",
      "0.46629213483146065 1.0 0.7331460674157303\n",
      "epoch 83:\n",
      "0.44294826364280654 1.0 0.7214741318214033\n",
      "0.5280898876404494 1.0 0.7640449438202247\n",
      "epoch 84:\n",
      "0.4939759036144578 1.0 0.7469879518072289\n",
      "0.5702247191011236 1.0 0.7851123595505618\n",
      "epoch 85:\n",
      "0.5414599574769667 1.0 0.7707299787384834\n",
      "0.6264044943820225 1.0 0.8132022471910112\n",
      "epoch 86:\n",
      "0.5832742735648476 1.0 0.7916371367824238\n",
      "0.6544943820224719 1.0 0.827247191011236\n",
      "epoch 87:\n",
      "0.6151665485471297 1.0 0.8075832742735649\n",
      "0.6882022471910112 1.0 0.8441011235955056\n",
      "epoch 88:\n",
      "0.6491849751948973 1.0 0.8245924875974486\n",
      "0.699438202247191 1.0 0.8497191011235955\n",
      "epoch 89:\n",
      "0.6775336640680368 1.0 0.8387668320340185\n",
      "0.7106741573033708 1.0 0.8553370786516854\n",
      "epoch 90:\n",
      "0.6966690290574061 1.0 0.8483345145287031\n",
      "0.7275280898876404 1.0 0.8637640449438202\n",
      "epoch 91:\n",
      "0.7150956768249468 0.9997771339425006 0.8574364053837237\n",
      "0.7387640449438202 1.0 0.8693820224719101\n",
      "epoch 92:\n",
      "0.7313961729270021 0.9997771339425006 0.8655866534347514\n",
      "0.75 1.0 0.875\n",
      "epoch 93:\n",
      "0.7469879518072289 0.9997771339425006 0.8733825428748647\n",
      "0.7640449438202247 1.0 0.8820224719101124\n",
      "epoch 94:\n",
      "0.7569099929128278 0.9997771339425006 0.8783435634276642\n",
      "0.7724719101123596 1.0 0.8862359550561798\n",
      "epoch 95:\n",
      "0.7647058823529411 0.9995542678850011 0.8821300751189711\n",
      "0.7893258426966292 1.0 0.8946629213483146\n",
      "epoch 96:\n",
      "0.7710843373493976 0.9995542678850011 0.8853193026171994\n",
      "0.7921348314606742 1.0 0.8960674157303371\n",
      "epoch 97:\n",
      "0.784549964564139 0.9995542678850011 0.89205211622457\n",
      "0.8033707865168539 1.0 0.901685393258427\n",
      "epoch 98:\n",
      "0.7888022678951099 0.9995542678850011 0.8941782678900555\n",
      "0.8089887640449438 1.0 0.9044943820224719\n",
      "epoch 99:\n",
      "0.7944720056697377 0.9995542678850011 0.8970131367773695\n",
      "0.8117977528089888 1.0 0.9058988764044944\n",
      "epoch 100:\n",
      "0.8008504606661941 0.9995542678850011 0.9002023642755976\n",
      "0.8117977528089888 0.9991063449508489 0.9054520488799189\n",
      "epoch 101:\n",
      "0.8065201984408221 0.9995542678850011 0.9030372331629116\n",
      "0.8146067415730337 0.9991063449508489 0.9068565432619413\n",
      "epoch 102:\n",
      "0.810772501771793 0.9995542678850011 0.9051633848283971\n",
      "0.8174157303370787 0.9991063449508489 0.9082610376439638\n",
      "epoch 103:\n",
      "0.8128986534372785 0.9995542678850011 0.9062264606611399\n",
      "0.8202247191011236 0.9991063449508489 0.9096655320259863\n",
      "epoch 104:\n",
      "0.8228206945428774 0.9995542678850011 0.9111874812139393\n",
      "0.8258426966292135 0.9991063449508489 0.9124745207900312\n",
      "epoch 105:\n",
      "0.8284904323175053 0.9995542678850011 0.9140223501012532\n",
      "0.8314606741573034 0.9991063449508489 0.9152835095540761\n",
      "epoch 106:\n",
      "0.8334514528703048 0.9995542678850011 0.9165028603776529\n",
      "0.8314606741573034 0.9991063449508489 0.9152835095540761\n",
      "epoch 107:\n",
      "0.8384124734231042 0.9995542678850011 0.9189833706540527\n",
      "0.8314606741573034 0.9991063449508489 0.9152835095540761\n",
      "epoch 108:\n",
      "0.8405386250885897 0.9995542678850011 0.9200464464867955\n",
      "0.8370786516853933 0.9991063449508489 0.9180924983181211\n",
      "epoch 109:\n",
      "0.8454996456413891 0.9995542678850011 0.9225269567631951\n",
      "0.8398876404494382 0.9991063449508489 0.9194969927001435\n",
      "epoch 110:\n",
      "0.848334514528703 0.9995542678850011 0.9239443912068521\n",
      "0.8426966292134831 0.9991063449508489 0.920901487082166\n",
      "epoch 111:\n",
      "0.8518781006378455 0.9995542678850011 0.9257161842614233\n",
      "0.8455056179775281 0.9991063449508489 0.9223059814641885\n",
      "epoch 112:\n",
      "0.8525868178596739 0.9995542678850011 0.9260705428723375\n",
      "0.8455056179775281 0.9991063449508489 0.9223059814641885\n",
      "epoch 113:\n",
      "0.8532955350815025 0.9995542678850011 0.9264249014832517\n",
      "0.848314606741573 0.9991063449508489 0.9237104758462109\n",
      "epoch 114:\n",
      "0.8575478384124734 0.9993314018275017 0.9284396201199876\n",
      "0.848314606741573 0.9991063449508489 0.9237104758462109\n",
      "epoch 115:\n",
      "0.8582565556343019 0.9993314018275017 0.9287939787309019\n",
      "0.851123595505618 0.9991063449508489 0.9251149702282335\n",
      "epoch 116:\n",
      "0.8610914245216159 0.9993314018275017 0.9302114131745588\n",
      "0.851123595505618 0.9991063449508489 0.9251149702282335\n",
      "epoch 117:\n",
      "0.8625088589652729 0.9993314018275017 0.9309201303963872\n",
      "0.851123595505618 0.9991063449508489 0.9251149702282335\n",
      "epoch 118:\n",
      "0.8632175761871014 0.9993314018275017 0.9312744890073015\n",
      "0.8539325842696629 0.9991063449508489 0.9265194646102559\n",
      "epoch 119:\n",
      "0.8646350106307583 0.9993314018275017 0.93198320622913\n",
      "0.8567415730337079 0.9991063449508489 0.9279239589922784\n",
      "epoch 120:\n",
      "0.8653437278525868 0.9993314018275017 0.9323375648400443\n",
      "0.8567415730337079 0.9991063449508489 0.9279239589922784\n",
      "epoch 121:\n",
      "0.8660524450744153 0.9991085357700022 0.9325804904222088\n",
      "0.8567415730337079 0.9991063449508489 0.9279239589922784\n",
      "epoch 122:\n",
      "0.8667611622962438 0.9991085357700022 0.9329348490331231\n",
      "0.8595505617977528 0.9991063449508489 0.9293284533743009\n",
      "epoch 123:\n",
      "0.8667611622962438 0.9991085357700022 0.9329348490331231\n",
      "0.8595505617977528 0.9991063449508489 0.9293284533743009\n",
      "epoch 124:\n",
      "0.8674698795180723 0.9991085357700022 0.9332892076440373\n",
      "0.8623595505617978 0.9991063449508489 0.9307329477563233\n",
      "epoch 125:\n",
      "0.8688873139617292 0.9991085357700022 0.9339979248658657\n",
      "0.8623595505617978 0.9991063449508489 0.9307329477563233\n",
      "epoch 126:\n",
      "0.8695960311835578 0.9991085357700022 0.93435228347678\n",
      "0.8623595505617978 0.9991063449508489 0.9307329477563233\n",
      "epoch 127:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8695960311835578 0.9991085357700022 0.93435228347678\n",
      "0.8651685393258427 0.9991063449508489 0.9321374421383458\n",
      "epoch 128:\n",
      "0.8710134656272147 0.9991085357700022 0.9350610006986084\n",
      "0.8651685393258427 0.9991063449508489 0.9321374421383458\n",
      "epoch 129:\n",
      "0.8717221828490432 0.9988856697125028 0.935303926280773\n",
      "0.8679775280898876 0.9991063449508489 0.9335419365203683\n",
      "epoch 130:\n",
      "0.8752657689581856 0.9988856697125028 0.9370757193353443\n",
      "0.8679775280898876 0.9991063449508489 0.9335419365203683\n",
      "epoch 131:\n",
      "0.8766832034018427 0.9988856697125028 0.9377844365571728\n",
      "0.8679775280898876 0.9991063449508489 0.9335419365203683\n",
      "epoch 132:\n",
      "0.8773919206236711 0.9988856697125028 0.938138795168087\n",
      "0.8679775280898876 0.9991063449508489 0.9335419365203683\n",
      "epoch 133:\n",
      "0.8773919206236711 0.9988856697125028 0.938138795168087\n",
      "0.8679775280898876 0.9991063449508489 0.9335419365203683\n",
      "epoch 134:\n",
      "0.8795180722891566 0.9988856697125028 0.9392018710008296\n",
      "0.8679775280898876 0.9991063449508489 0.9335419365203683\n",
      "epoch 135:\n",
      "0.8816442239546421 0.9988856697125028 0.9402649468335724\n",
      "0.8679775280898876 0.9991063449508489 0.9335419365203683\n",
      "epoch 136:\n",
      "0.8816442239546421 0.9988856697125028 0.9402649468335724\n",
      "0.8679775280898876 0.9991063449508489 0.9335419365203683\n",
      "epoch 137:\n",
      "0.8823529411764706 0.9988856697125028 0.9406193054444867\n",
      "0.8679775280898876 0.9991063449508489 0.9335419365203683\n",
      "epoch 138:\n",
      "0.8830616583982991 0.9988856697125028 0.940973664055401\n",
      "0.8707865168539326 0.9991063449508489 0.9349464309023907\n",
      "epoch 139:\n",
      "0.884479092841956 0.9988856697125028 0.9416823812772295\n",
      "0.8735955056179775 0.9991063449508489 0.9363509252844132\n",
      "epoch 140:\n",
      "0.8858965272856131 0.9988856697125028 0.942391098499058\n",
      "0.8735955056179775 0.9991063449508489 0.9363509252844132\n",
      "epoch 141:\n",
      "0.8880226789510985 0.9988856697125028 0.9434541743318007\n",
      "0.8735955056179775 0.9991063449508489 0.9363509252844132\n",
      "epoch 142:\n",
      "0.8880226789510985 0.9986628036550034 0.943342741303051\n",
      "0.8735955056179775 0.9991063449508489 0.9363509252844132\n",
      "epoch 143:\n",
      "0.888731396172927 0.9986628036550034 0.9436970999139651\n",
      "0.8735955056179775 0.9991063449508489 0.9363509252844132\n",
      "epoch 144:\n",
      "0.890148830616584 0.9986628036550034 0.9444058171357936\n",
      "0.8735955056179775 0.9991063449508489 0.9363509252844132\n",
      "epoch 145:\n",
      "0.890148830616584 0.9986628036550034 0.9444058171357936\n",
      "0.8735955056179775 0.9991063449508489 0.9363509252844132\n",
      "epoch 146:\n",
      "0.891566265060241 0.9986628036550034 0.9451145343576222\n",
      "0.8735955056179775 0.9991063449508489 0.9363509252844132\n",
      "epoch 147:\n",
      "0.8922749822820695 0.9984399375975039 0.9453574599397867\n",
      "0.8735955056179775 0.9991063449508489 0.9363509252844132\n",
      "epoch 148:\n",
      "0.8944011339475549 0.9984399375975039 0.9464205357725295\n",
      "0.8735955056179775 0.9991063449508489 0.9363509252844132\n",
      "epoch 149:\n",
      "0.8951098511693835 0.9984399375975039 0.9467748943834438\n",
      "0.8735955056179775 0.9991063449508489 0.9363509252844132\n",
      "epoch 150:\n",
      "0.8972360028348689 0.9984399375975039 0.9478379702161864\n",
      "0.8735955056179775 0.9991063449508489 0.9363509252844132\n",
      "epoch 151:\n",
      "0.8972360028348689 0.9984399375975039 0.9478379702161864\n",
      "0.8735955056179775 0.998212689901698 0.9359040977598377\n",
      "epoch 152:\n",
      "0.8979447200566973 0.9984399375975039 0.9481923288271006\n",
      "0.8735955056179775 0.998212689901698 0.9359040977598377\n",
      "epoch 153:\n",
      "0.8986534372785259 0.9984399375975039 0.9485466874380148\n",
      "0.8764044943820225 0.998212689901698 0.9373085921418602\n",
      "epoch 154:\n",
      "0.8986534372785259 0.9982170715400045 0.9484352544092651\n",
      "0.8764044943820225 0.998212689901698 0.9373085921418602\n",
      "epoch 155:\n",
      "0.8986534372785259 0.9982170715400045 0.9484352544092651\n",
      "0.8764044943820225 0.998212689901698 0.9373085921418602\n",
      "epoch 156:\n",
      "0.8986534372785259 0.9982170715400045 0.9484352544092651\n",
      "0.8764044943820225 0.998212689901698 0.9373085921418602\n",
      "epoch 157:\n",
      "0.9014883061658399 0.9982170715400045 0.9498526888529222\n",
      "0.8764044943820225 0.998212689901698 0.9373085921418602\n",
      "epoch 158:\n",
      "0.9021970233876683 0.9982170715400045 0.9502070474638364\n",
      "0.8792134831460674 0.998212689901698 0.9387130865238826\n",
      "epoch 159:\n",
      "0.9029057406094968 0.9982170715400045 0.9505614060747507\n",
      "0.8820224719101124 0.998212689901698 0.9401175809059052\n",
      "epoch 160:\n",
      "0.9036144578313253 0.9982170715400045 0.950915764685665\n",
      "0.8820224719101124 0.998212689901698 0.9401175809059052\n",
      "epoch 161:\n",
      "0.9043231750531537 0.9982170715400045 0.9512701232965791\n",
      "0.8820224719101124 0.998212689901698 0.9401175809059052\n",
      "epoch 162:\n",
      "0.9064493267186393 0.9979942054825051 0.9522217661005722\n",
      "0.8820224719101124 0.998212689901698 0.9401175809059052\n",
      "epoch 163:\n",
      "0.9071580439404677 0.9979942054825051 0.9525761247114863\n",
      "0.8820224719101124 0.998212689901698 0.9401175809059052\n",
      "epoch 164:\n",
      "0.9071580439404677 0.9979942054825051 0.9525761247114863\n",
      "0.8820224719101124 0.998212689901698 0.9401175809059052\n",
      "epoch 165:\n",
      "0.9078667611622963 0.9979942054825051 0.9529304833224006\n",
      "0.8848314606741573 0.998212689901698 0.9415220752879276\n",
      "epoch 166:\n",
      "0.9092841956059532 0.9979942054825051 0.9536392005442291\n",
      "0.8848314606741573 0.998212689901698 0.9415220752879276\n",
      "epoch 167:\n",
      "0.9099929128277817 0.9979942054825051 0.9539935591551434\n",
      "0.8848314606741573 0.998212689901698 0.9415220752879276\n",
      "epoch 168:\n",
      "0.9114103472714387 0.9979942054825051 0.9547022763769719\n",
      "0.8876404494382022 0.998212689901698 0.94292656966995\n",
      "epoch 169:\n",
      "0.9128277817150957 0.9979942054825051 0.9554109935988004\n",
      "0.8876404494382022 0.998212689901698 0.94292656966995\n",
      "epoch 170:\n",
      "0.9128277817150957 0.9979942054825051 0.9554109935988004\n",
      "0.8876404494382022 0.998212689901698 0.94292656966995\n",
      "epoch 171:\n",
      "0.9142452161587526 0.9979942054825051 0.9561197108206289\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 172:\n",
      "0.9142452161587526 0.9979942054825051 0.9561197108206289\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 173:\n",
      "0.9142452161587526 0.9979942054825051 0.9561197108206289\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 174:\n",
      "0.9149539333805812 0.9979942054825051 0.9564740694315431\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 175:\n",
      "0.9149539333805812 0.9979942054825051 0.9564740694315431\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 176:\n",
      "0.9156626506024096 0.9979942054825051 0.9568284280424573\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 177:\n",
      "0.9163713678242381 0.9979942054825051 0.9571827866533715\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 178:\n",
      "0.9163713678242381 0.9979942054825051 0.9571827866533715\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 179:\n",
      "0.9170800850460666 0.9979942054825051 0.9575371452642858\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 180:\n",
      "0.9177888022678952 0.9979942054825051 0.9578915038752001\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 181:\n",
      "0.9177888022678952 0.9979942054825051 0.9578915038752001\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 182:\n",
      "0.9192062367115521 0.9979942054825051 0.9586002210970286\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 183:\n",
      "0.9192062367115521 0.9979942054825051 0.9586002210970286\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 184:\n",
      "0.9192062367115521 0.9979942054825051 0.9586002210970286\n",
      "0.8904494382022472 0.998212689901698 0.9443310640519726\n",
      "epoch 185:\n",
      "0.9192062367115521 0.9979942054825051 0.9586002210970286\n",
      "0.8932584269662921 0.998212689901698 0.945735558433995\n",
      "epoch 186:\n",
      "0.9192062367115521 0.9977713394250056 0.9584887880682789\n",
      "0.8932584269662921 0.998212689901698 0.945735558433995\n",
      "epoch 187:\n",
      "0.9192062367115521 0.9977713394250056 0.9584887880682789\n",
      "0.8932584269662921 0.998212689901698 0.945735558433995\n",
      "epoch 188:\n",
      "0.9192062367115521 0.9977713394250056 0.9584887880682789\n",
      "0.8932584269662921 0.998212689901698 0.945735558433995\n",
      "epoch 189:\n",
      "0.9192062367115521 0.9977713394250056 0.9584887880682789\n",
      "0.8932584269662921 0.998212689901698 0.945735558433995\n",
      "epoch 190:\n",
      "0.9192062367115521 0.9977713394250056 0.9584887880682789\n",
      "0.8932584269662921 0.998212689901698 0.945735558433995\n",
      "epoch 191:\n",
      "0.9192062367115521 0.9977713394250056 0.9584887880682789\n",
      "0.8932584269662921 0.998212689901698 0.945735558433995\n",
      "epoch 192:\n",
      "0.9192062367115521 0.9977713394250056 0.9584887880682789\n",
      "0.8932584269662921 0.998212689901698 0.945735558433995\n",
      "epoch 193:\n",
      "0.920623671155209 0.9977713394250056 0.9591975052901074\n",
      "0.8932584269662921 0.998212689901698 0.945735558433995\n",
      "epoch 194:\n",
      "0.920623671155209 0.9977713394250056 0.9591975052901074\n",
      "0.8932584269662921 0.998212689901698 0.945735558433995\n",
      "epoch 195:\n",
      "0.920623671155209 0.9977713394250056 0.9591975052901074\n",
      "0.8932584269662921 0.998212689901698 0.945735558433995\n",
      "epoch 196:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.920623671155209 0.9977713394250056 0.9591975052901074\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 197:\n",
      "0.920623671155209 0.9977713394250056 0.9591975052901074\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 198:\n",
      "0.9213323883770376 0.9977713394250056 0.9595518639010217\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 199:\n",
      "0.9220411055988661 0.9977713394250056 0.9599062225119359\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 200:\n",
      "0.923458540042523 0.9977713394250056 0.9606149397337643\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 201:\n",
      "0.923458540042523 0.9977713394250056 0.9606149397337643\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 202:\n",
      "0.9241672572643516 0.9977713394250056 0.9609692983446786\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 203:\n",
      "0.92487597448618 0.9977713394250056 0.9613236569555927\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 204:\n",
      "0.9255846917080085 0.9977713394250056 0.961678015566507\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 205:\n",
      "0.9270021261516654 0.9977713394250056 0.9623867327883355\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 206:\n",
      "0.9270021261516654 0.9977713394250056 0.9623867327883355\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 207:\n",
      "0.9270021261516654 0.9977713394250056 0.9623867327883355\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 208:\n",
      "0.9270021261516654 0.9977713394250056 0.9623867327883355\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 209:\n",
      "0.9270021261516654 0.9977713394250056 0.9623867327883355\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 210:\n",
      "0.9270021261516654 0.9977713394250056 0.9623867327883355\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 211:\n",
      "0.9270021261516654 0.9977713394250056 0.9623867327883355\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 212:\n",
      "0.9270021261516654 0.9977713394250056 0.9623867327883355\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 213:\n",
      "0.9270021261516654 0.9977713394250056 0.9623867327883355\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 214:\n",
      "0.927710843373494 0.9977713394250056 0.9627410913992498\n",
      "0.8960674157303371 0.998212689901698 0.9471400528160175\n",
      "epoch 215:\n",
      "0.9284195605953225 0.9977713394250056 0.9630954500101641\n",
      "0.898876404494382 0.998212689901698 0.94854454719804\n",
      "epoch 216:\n",
      "0.9291282778171509 0.9977713394250056 0.9634498086210783\n",
      "0.898876404494382 0.998212689901698 0.94854454719804\n",
      "epoch 217:\n",
      "0.9291282778171509 0.9977713394250056 0.9634498086210783\n",
      "0.898876404494382 0.998212689901698 0.94854454719804\n",
      "epoch 218:\n",
      "0.9291282778171509 0.9977713394250056 0.9634498086210783\n",
      "0.901685393258427 0.998212689901698 0.9499490415800624\n",
      "epoch 219:\n",
      "0.9298369950389794 0.9977713394250056 0.9638041672319926\n",
      "0.901685393258427 0.998212689901698 0.9499490415800624\n",
      "epoch 220:\n",
      "0.9298369950389794 0.9977713394250056 0.9638041672319926\n",
      "0.901685393258427 0.998212689901698 0.9499490415800624\n",
      "epoch 221:\n",
      "0.9298369950389794 0.9977713394250056 0.9638041672319926\n",
      "0.901685393258427 0.998212689901698 0.9499490415800624\n",
      "epoch 222:\n",
      "0.9298369950389794 0.9977713394250056 0.9638041672319926\n",
      "0.901685393258427 0.998212689901698 0.9499490415800624\n",
      "epoch 223:\n",
      "0.930545712260808 0.9977713394250056 0.9641585258429068\n",
      "0.901685393258427 0.998212689901698 0.9499490415800624\n",
      "epoch 224:\n",
      "0.930545712260808 0.9977713394250056 0.9641585258429068\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 225:\n",
      "0.9312544294826365 0.9977713394250056 0.9645128844538211\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 226:\n",
      "0.9319631467044649 0.9977713394250056 0.9648672430647353\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 227:\n",
      "0.9319631467044649 0.9977713394250056 0.9648672430647353\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 228:\n",
      "0.9319631467044649 0.9977713394250056 0.9648672430647353\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 229:\n",
      "0.9326718639262934 0.9975484733675062 0.9651101686468998\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 230:\n",
      "0.9326718639262934 0.9975484733675062 0.9651101686468998\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 231:\n",
      "0.9340892983699504 0.9975484733675062 0.9658188858687282\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 232:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 233:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 234:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 235:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 236:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 237:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 238:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 239:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 240:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 241:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 242:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 243:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 244:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 245:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 246:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 247:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9044943820224719 0.998212689901698 0.9513535359620849\n",
      "epoch 248:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9101123595505618 0.998212689901698 0.9541625247261298\n",
      "epoch 249:\n",
      "0.9347980155917789 0.9975484733675062 0.9661732444796425\n",
      "0.9101123595505618 0.998212689901698 0.9541625247261298\n",
      "epoch 250:\n",
      "0.9355067328136074 0.9975484733675062 0.9665276030905567\n",
      "0.9101123595505618 0.998212689901698 0.9541625247261298\n",
      "epoch 251:\n",
      "0.9355067328136074 0.9975484733675062 0.9665276030905567\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 252:\n",
      "0.9355067328136074 0.9975484733675062 0.9665276030905567\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 253:\n",
      "0.9355067328136074 0.9975484733675062 0.9665276030905567\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 254:\n",
      "0.9355067328136074 0.9975484733675062 0.9665276030905567\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 255:\n",
      "0.9355067328136074 0.9973256073100066 0.966416170061807\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 256:\n",
      "0.9355067328136074 0.9973256073100066 0.966416170061807\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 257:\n",
      "0.9362154500354358 0.9973256073100066 0.9667705286727213\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 258:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 259:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 260:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 261:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 262:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 263:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 264:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 265:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 266:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 267:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 268:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 269:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 270:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 271:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 272:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9129213483146067 0.998212689901698 0.9555670191081523\n",
      "epoch 273:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9157303370786517 0.998212689901698 0.9569715134901748\n",
      "epoch 274:\n",
      "0.9369241672572644 0.9973256073100066 0.9671248872836355\n",
      "0.9157303370786517 0.998212689901698 0.9569715134901748\n",
      "epoch 275:\n",
      "0.9376328844790929 0.9973256073100066 0.9674792458945498\n",
      "0.9185393258426966 0.998212689901698 0.9583760078721972\n",
      "epoch 276:\n",
      "0.9376328844790929 0.9973256073100066 0.9674792458945498\n",
      "0.9185393258426966 0.998212689901698 0.9583760078721972\n",
      "epoch 277:\n",
      "0.9376328844790929 0.9973256073100066 0.9674792458945498\n",
      "0.9185393258426966 0.998212689901698 0.9583760078721972\n",
      "epoch 278:\n",
      "0.9376328844790929 0.9973256073100066 0.9674792458945498\n",
      "0.9185393258426966 0.998212689901698 0.9583760078721972\n",
      "epoch 279:\n",
      "0.9383416017009213 0.9973256073100066 0.967833604505464\n",
      "0.9185393258426966 0.998212689901698 0.9583760078721972\n",
      "epoch 280:\n",
      "0.9383416017009213 0.9973256073100066 0.967833604505464\n",
      "0.9185393258426966 0.998212689901698 0.9583760078721972\n",
      "epoch 281:\n",
      "0.9383416017009213 0.9973256073100066 0.967833604505464\n",
      "0.9185393258426966 0.998212689901698 0.9583760078721972\n",
      "epoch 282:\n",
      "0.9390503189227498 0.9973256073100066 0.9681879631163782\n",
      "0.9185393258426966 0.998212689901698 0.9583760078721972\n",
      "epoch 283:\n",
      "0.9390503189227498 0.9973256073100066 0.9681879631163782\n",
      "0.9185393258426966 0.998212689901698 0.9583760078721972\n",
      "epoch 284:\n",
      "0.9390503189227498 0.9973256073100066 0.9681879631163782\n",
      "0.9185393258426966 0.998212689901698 0.9583760078721972\n",
      "epoch 285:\n",
      "0.9390503189227498 0.9973256073100066 0.9681879631163782\n",
      "0.9185393258426966 0.998212689901698 0.9583760078721972\n",
      "epoch 286:\n",
      "0.9390503189227498 0.9973256073100066 0.9681879631163782\n",
      "0.9185393258426966 0.998212689901698 0.9583760078721972\n",
      "epoch 287:\n",
      "0.9390503189227498 0.9973256073100066 0.9681879631163782\n",
      "0.9213483146067416 0.998212689901698 0.9597805022542198\n",
      "epoch 288:\n",
      "0.9390503189227498 0.9973256073100066 0.9681879631163782\n",
      "0.9213483146067416 0.998212689901698 0.9597805022542198\n",
      "epoch 289:\n",
      "0.9390503189227498 0.9973256073100066 0.9681879631163782\n",
      "0.9213483146067416 0.998212689901698 0.9597805022542198\n",
      "epoch 290:\n",
      "0.9390503189227498 0.9973256073100066 0.9681879631163782\n",
      "0.9213483146067416 0.998212689901698 0.9597805022542198\n",
      "epoch 291:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9213483146067416 0.998212689901698 0.9597805022542198\n",
      "epoch 292:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9213483146067416 0.998212689901698 0.9597805022542198\n",
      "epoch 293:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9213483146067416 0.998212689901698 0.9597805022542198\n",
      "epoch 294:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9213483146067416 0.998212689901698 0.9597805022542198\n",
      "epoch 295:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9213483146067416 0.9973190348525469 0.9593336747296443\n",
      "epoch 296:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9213483146067416 0.9973190348525469 0.9593336747296443\n",
      "epoch 297:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 298:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 299:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 300:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 301:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 302:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 303:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 304:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 305:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 306:\n",
      "0.9397590361445783 0.9973256073100066 0.9685423217272925\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 307:\n",
      "0.9397590361445783 0.9971027412525072 0.9684308886985428\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 308:\n",
      "0.9397590361445783 0.9971027412525072 0.9684308886985428\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 309:\n",
      "0.9397590361445783 0.9971027412525072 0.9684308886985428\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 310:\n",
      "0.9397590361445783 0.9971027412525072 0.9684308886985428\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 311:\n",
      "0.9397590361445783 0.9971027412525072 0.9684308886985428\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 312:\n",
      "0.9411764705882353 0.9971027412525072 0.9691396059203712\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 313:\n",
      "0.9411764705882353 0.9971027412525072 0.9691396059203712\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 314:\n",
      "0.9411764705882353 0.9971027412525072 0.9691396059203712\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 315:\n",
      "0.9411764705882353 0.9971027412525072 0.9691396059203712\n",
      "0.9241573033707865 0.9973190348525469 0.9607381691116668\n",
      "epoch 316:\n",
      "0.9418851878100638 0.9971027412525072 0.9694939645312854\n",
      "0.9269662921348315 0.9973190348525469 0.9621426634936892\n",
      "epoch 317:\n",
      "0.9425939050318922 0.9971027412525072 0.9698483231421997\n",
      "0.9269662921348315 0.9973190348525469 0.9621426634936892\n",
      "epoch 318:\n",
      "0.9425939050318922 0.9971027412525072 0.9698483231421997\n",
      "0.9269662921348315 0.9973190348525469 0.9621426634936892\n",
      "epoch 319:\n",
      "0.9425939050318922 0.9971027412525072 0.9698483231421997\n",
      "0.9269662921348315 0.9973190348525469 0.9621426634936892\n",
      "epoch 320:\n",
      "0.9433026222537207 0.9971027412525072 0.970202681753114\n",
      "0.9269662921348315 0.9973190348525469 0.9621426634936892\n",
      "epoch 321:\n",
      "0.9433026222537207 0.9971027412525072 0.970202681753114\n",
      "0.9269662921348315 0.9973190348525469 0.9621426634936892\n",
      "epoch 322:\n",
      "0.9433026222537207 0.9971027412525072 0.970202681753114\n",
      "0.9297752808988764 0.9973190348525469 0.9635471578757117\n",
      "epoch 323:\n",
      "0.9433026222537207 0.9968798751950078 0.9700912487243643\n",
      "0.9297752808988764 0.9973190348525469 0.9635471578757117\n",
      "epoch 324:\n",
      "0.9433026222537207 0.9968798751950078 0.9700912487243643\n",
      "0.9297752808988764 0.9973190348525469 0.9635471578757117\n",
      "epoch 325:\n",
      "0.9433026222537207 0.9968798751950078 0.9700912487243643\n",
      "0.9297752808988764 0.9973190348525469 0.9635471578757117\n",
      "epoch 326:\n",
      "0.9433026222537207 0.9968798751950078 0.9700912487243643\n",
      "0.9297752808988764 0.9973190348525469 0.9635471578757117\n",
      "epoch 327:\n",
      "0.9433026222537207 0.9968798751950078 0.9700912487243643\n",
      "0.9297752808988764 0.9973190348525469 0.9635471578757117\n",
      "epoch 328:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9297752808988764 0.9973190348525469 0.9635471578757117\n",
      "epoch 329:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9297752808988764 0.9973190348525469 0.9635471578757117\n",
      "epoch 330:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9297752808988764 0.9964253798033958 0.9631003303511361\n",
      "epoch 331:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9325842696629213 0.9964253798033958 0.9645048247331586\n",
      "epoch 332:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9325842696629213 0.9964253798033958 0.9645048247331586\n",
      "epoch 333:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9325842696629213 0.9964253798033958 0.9645048247331586\n",
      "epoch 334:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9325842696629213 0.9964253798033958 0.9645048247331586\n",
      "epoch 335:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9325842696629213 0.9964253798033958 0.9645048247331586\n",
      "epoch 336:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9353932584269663 0.9964253798033958 0.9659093191151811\n",
      "epoch 337:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9353932584269663 0.9964253798033958 0.9659093191151811\n",
      "epoch 338:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9353932584269663 0.9964253798033958 0.9659093191151811\n",
      "epoch 339:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9353932584269663 0.9964253798033958 0.9659093191151811\n",
      "epoch 340:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9382022471910112 0.9964253798033958 0.9673138134972035\n",
      "epoch 341:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9382022471910112 0.9964253798033958 0.9673138134972035\n",
      "epoch 342:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9382022471910112 0.9964253798033958 0.9673138134972035\n",
      "epoch 343:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9410112359550562 0.9964253798033958 0.9687183078792261\n",
      "epoch 344:\n",
      "0.9447200566973778 0.9968798751950078 0.9707999659461928\n",
      "0.9410112359550562 0.9964253798033958 0.9687183078792261\n",
      "epoch 345:\n",
      "0.9454287739192062 0.9968798751950078 0.971154324557107\n",
      "0.9410112359550562 0.9964253798033958 0.9687183078792261\n",
      "epoch 346:\n",
      "0.9454287739192062 0.9968798751950078 0.971154324557107\n",
      "0.9410112359550562 0.9964253798033958 0.9687183078792261\n",
      "epoch 347:\n",
      "0.9454287739192062 0.9968798751950078 0.971154324557107\n",
      "0.9410112359550562 0.9964253798033958 0.9687183078792261\n",
      "epoch 348:\n",
      "0.9454287739192062 0.9966570091375083 0.9710428915283573\n",
      "0.9410112359550562 0.9964253798033958 0.9687183078792261\n",
      "epoch 349:\n",
      "0.9461374911410347 0.9966570091375083 0.9713972501392716\n",
      "0.9410112359550562 0.9964253798033958 0.9687183078792261\n",
      "epoch 350:\n",
      "0.9461374911410347 0.9966570091375083 0.9713972501392716\n",
      "0.9410112359550562 0.9964253798033958 0.9687183078792261\n",
      "epoch 351:\n",
      "0.9461374911410347 0.9966570091375083 0.9713972501392716\n",
      "0.9410112359550562 0.9964253798033958 0.9687183078792261\n",
      "epoch 352:\n",
      "0.9461374911410347 0.9966570091375083 0.9713972501392716\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 353:\n",
      "0.9461374911410347 0.9966570091375083 0.9713972501392716\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 354:\n",
      "0.9461374911410347 0.9966570091375083 0.9713972501392716\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 355:\n",
      "0.9461374911410347 0.9966570091375083 0.9713972501392716\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 356:\n",
      "0.9461374911410347 0.9966570091375083 0.9713972501392716\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 357:\n",
      "0.9461374911410347 0.9966570091375083 0.9713972501392716\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 358:\n",
      "0.9461374911410347 0.9966570091375083 0.9713972501392716\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 359:\n",
      "0.9461374911410347 0.9966570091375083 0.9713972501392716\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 360:\n",
      "0.9468462083628633 0.9966570091375083 0.9717516087501858\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 361:\n",
      "0.9468462083628633 0.9966570091375083 0.9717516087501858\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 362:\n",
      "0.9468462083628633 0.9966570091375083 0.9717516087501858\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 363:\n",
      "0.9468462083628633 0.9966570091375083 0.9717516087501858\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 364:\n",
      "0.9468462083628633 0.9966570091375083 0.9717516087501858\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 365:\n",
      "0.9482636428065202 0.9966570091375083 0.9724603259720143\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 366:\n",
      "0.9482636428065202 0.9966570091375083 0.9724603259720143\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 367:\n",
      "0.9482636428065202 0.9966570091375083 0.9724603259720143\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 368:\n",
      "0.9482636428065202 0.9966570091375083 0.9724603259720143\n",
      "0.9438202247191011 0.9964253798033958 0.9701228022612485\n",
      "epoch 369:\n",
      "0.9482636428065202 0.9966570091375083 0.9724603259720143\n",
      "0.9466292134831461 0.9964253798033958 0.971527296643271\n",
      "epoch 370:\n",
      "0.9482636428065202 0.9966570091375083 0.9724603259720143\n",
      "0.9466292134831461 0.9964253798033958 0.971527296643271\n",
      "epoch 371:\n",
      "0.9482636428065202 0.9966570091375083 0.9724603259720143\n",
      "0.9466292134831461 0.9964253798033958 0.971527296643271\n",
      "epoch 372:\n",
      "0.9482636428065202 0.9966570091375083 0.9724603259720143\n",
      "0.9466292134831461 0.9964253798033958 0.971527296643271\n",
      "epoch 373:\n",
      "0.9482636428065202 0.9966570091375083 0.9724603259720143\n",
      "0.9466292134831461 0.9964253798033958 0.971527296643271\n",
      "epoch 374:\n",
      "0.9482636428065202 0.9964341430800089 0.9723488929432645\n",
      "0.9466292134831461 0.9964253798033958 0.971527296643271\n",
      "epoch 375:\n",
      "0.9482636428065202 0.9964341430800089 0.9723488929432645\n",
      "0.9466292134831461 0.9964253798033958 0.971527296643271\n",
      "epoch 376:\n",
      "0.9482636428065202 0.9964341430800089 0.9723488929432645\n",
      "0.9466292134831461 0.9964253798033958 0.971527296643271\n",
      "epoch 377:\n",
      "0.9482636428065202 0.9964341430800089 0.9723488929432645\n",
      "0.9466292134831461 0.9964253798033958 0.971527296643271\n",
      "epoch 378:\n",
      "0.9482636428065202 0.9964341430800089 0.9723488929432645\n",
      "0.9466292134831461 0.9964253798033958 0.971527296643271\n",
      "epoch 379:\n",
      "0.9482636428065202 0.9962112770225094 0.9722374599145148\n",
      "0.9466292134831461 0.9964253798033958 0.971527296643271\n",
      "epoch 380:\n",
      "0.9482636428065202 0.9962112770225094 0.9722374599145148\n",
      "0.9466292134831461 0.9964253798033958 0.971527296643271\n",
      "epoch 381:\n",
      "0.9482636428065202 0.9962112770225094 0.9722374599145148\n",
      "0.949438202247191 0.9964253798033958 0.9729317910252935\n",
      "epoch 382:\n",
      "0.9482636428065202 0.9962112770225094 0.9722374599145148\n",
      "0.949438202247191 0.9964253798033958 0.9729317910252935\n",
      "epoch 383:\n",
      "0.9482636428065202 0.9962112770225094 0.9722374599145148\n",
      "0.949438202247191 0.9964253798033958 0.9729317910252935\n",
      "epoch 384:\n",
      "0.9482636428065202 0.9962112770225094 0.9722374599145148\n",
      "0.949438202247191 0.9964253798033958 0.9729317910252935\n",
      "epoch 385:\n",
      "0.9482636428065202 0.9962112770225094 0.9722374599145148\n",
      "0.949438202247191 0.9964253798033958 0.9729317910252935\n",
      "epoch 386:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.949438202247191 0.9955317247542449 0.972484963500718\n",
      "epoch 387:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.949438202247191 0.9955317247542449 0.972484963500718\n",
      "epoch 388:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.949438202247191 0.9955317247542449 0.972484963500718\n",
      "epoch 389:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.949438202247191 0.9955317247542449 0.972484963500718\n",
      "epoch 390:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.949438202247191 0.9955317247542449 0.972484963500718\n",
      "epoch 391:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.949438202247191 0.9955317247542449 0.972484963500718\n",
      "epoch 392:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.949438202247191 0.9955317247542449 0.972484963500718\n",
      "epoch 393:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.949438202247191 0.9955317247542449 0.972484963500718\n",
      "epoch 394:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.949438202247191 0.9955317247542449 0.972484963500718\n",
      "epoch 395:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.949438202247191 0.9955317247542449 0.972484963500718\n",
      "epoch 396:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.952247191011236 0.9946380697050938 0.9734426303581649\n",
      "epoch 397:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.952247191011236 0.9946380697050938 0.9734426303581649\n",
      "epoch 398:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.952247191011236 0.9946380697050938 0.9734426303581649\n",
      "epoch 399:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 400:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 401:\n",
      "0.9489723600283487 0.9962112770225094 0.9725918185254291\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 402:\n",
      "0.9496810772501771 0.9962112770225094 0.9729461771363432\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 403:\n",
      "0.9496810772501771 0.9962112770225094 0.9729461771363432\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 404:\n",
      "0.9496810772501771 0.9962112770225094 0.9729461771363432\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 405:\n",
      "0.9496810772501771 0.9962112770225094 0.9729461771363432\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 406:\n",
      "0.9496810772501771 0.9962112770225094 0.9729461771363432\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 407:\n",
      "0.9496810772501771 0.9962112770225094 0.9729461771363432\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 408:\n",
      "0.9496810772501771 0.9962112770225094 0.9729461771363432\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 409:\n",
      "0.9503897944720057 0.9962112770225094 0.9733005357472575\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 410:\n",
      "0.9503897944720057 0.9962112770225094 0.9733005357472575\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 411:\n",
      "0.9503897944720057 0.9962112770225094 0.9733005357472575\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 412:\n",
      "0.9503897944720057 0.9962112770225094 0.9733005357472575\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 413:\n",
      "0.9503897944720057 0.9962112770225094 0.9733005357472575\n",
      "0.9550561797752809 0.9946380697050938 0.9748471247401873\n",
      "epoch 414:\n",
      "0.9503897944720057 0.9962112770225094 0.9733005357472575\n",
      "0.9550561797752809 0.9937444146559428 0.9744002972156118\n",
      "epoch 415:\n",
      "0.9503897944720057 0.9962112770225094 0.9733005357472575\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 416:\n",
      "0.9510985116938342 0.9962112770225094 0.9736548943581718\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 417:\n",
      "0.9518072289156626 0.9962112770225094 0.974009252969086\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 418:\n",
      "0.9518072289156626 0.9962112770225094 0.974009252969086\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 419:\n",
      "0.9518072289156626 0.9962112770225094 0.974009252969086\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 420:\n",
      "0.9518072289156626 0.9962112770225094 0.974009252969086\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 421:\n",
      "0.9518072289156626 0.9962112770225094 0.974009252969086\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 422:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 423:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 424:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 425:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 426:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 427:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 428:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 429:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 430:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 431:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 432:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 433:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 434:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 435:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 436:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 437:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 438:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 439:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 440:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 441:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9578651685393258 0.9937444146559428 0.9758047915976342\n",
      "epoch 442:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 443:\n",
      "0.9532246633593197 0.9962112770225094 0.9747179701909146\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 444:\n",
      "0.9539333805811481 0.9962112770225094 0.9750723288018288\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 445:\n",
      "0.9539333805811481 0.9962112770225094 0.9750723288018288\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 446:\n",
      "0.9539333805811481 0.9962112770225094 0.9750723288018288\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 447:\n",
      "0.9539333805811481 0.9962112770225094 0.9750723288018288\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 448:\n",
      "0.9539333805811481 0.9962112770225094 0.9750723288018288\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 449:\n",
      "0.9539333805811481 0.9962112770225094 0.9750723288018288\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 450:\n",
      "0.9539333805811481 0.9962112770225094 0.9750723288018288\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 451:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 452:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 453:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 454:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9606741573033708 0.9937444146559428 0.9772092859796568\n",
      "epoch 455:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 456:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 457:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 458:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 459:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 460:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 461:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 462:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 463:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 464:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 465:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 466:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 467:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 468:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 469:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 470:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 471:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 472:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 473:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 474:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 475:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 476:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 477:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 478:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 479:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 480:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 481:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9937444146559428 0.9786137803616792\n",
      "epoch 482:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9928507596067918 0.9781669528371038\n",
      "epoch 483:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9928507596067918 0.9781669528371038\n",
      "epoch 484:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9928507596067918 0.9781669528371038\n",
      "epoch 485:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9928507596067918 0.9781669528371038\n",
      "epoch 486:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9928507596067918 0.9781669528371038\n",
      "epoch 487:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9928507596067918 0.9781669528371038\n",
      "epoch 488:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9928507596067918 0.9781669528371038\n",
      "epoch 489:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9634831460674157 0.9928507596067918 0.9781669528371038\n",
      "epoch 490:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9662921348314607 0.9928507596067918 0.9795714472191263\n",
      "epoch 491:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9662921348314607 0.9928507596067918 0.9795714472191263\n",
      "epoch 492:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9662921348314607 0.9928507596067918 0.9795714472191263\n",
      "epoch 493:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9662921348314607 0.9928507596067918 0.9795714472191263\n",
      "epoch 494:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9662921348314607 0.9928507596067918 0.9795714472191263\n",
      "epoch 495:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 496:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 497:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 498:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 499:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 500:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 501:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 502:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 503:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 504:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 505:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 506:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 507:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 508:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 509:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 510:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 511:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 512:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 513:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 514:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 515:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 516:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 517:\n",
      "0.9546420978029766 0.9962112770225094 0.9754266874127431\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 518:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 519:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 520:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 521:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 522:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 523:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 524:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 525:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 526:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 527:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 528:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 529:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 530:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 531:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 532:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 533:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 534:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 535:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 536:\n",
      "0.9553508150248051 0.9962112770225094 0.9757810460236573\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 537:\n",
      "0.9560595322466336 0.9962112770225094 0.9761354046345716\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 538:\n",
      "0.9560595322466336 0.9962112770225094 0.9761354046345716\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 539:\n",
      "0.9560595322466336 0.9962112770225094 0.9761354046345716\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 540:\n",
      "0.9560595322466336 0.9962112770225094 0.9761354046345716\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 541:\n",
      "0.9560595322466336 0.9962112770225094 0.9761354046345716\n",
      "0.9691011235955056 0.9928507596067918 0.9809759416011488\n",
      "epoch 542:\n",
      "0.9560595322466336 0.9962112770225094 0.9761354046345716\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 543:\n",
      "0.9560595322466336 0.9962112770225094 0.9761354046345716\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 544:\n",
      "0.9560595322466336 0.9962112770225094 0.9761354046345716\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 545:\n",
      "0.9560595322466336 0.9962112770225094 0.9761354046345716\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 546:\n",
      "0.9560595322466336 0.9962112770225094 0.9761354046345716\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 547:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 548:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 549:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 550:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 551:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 552:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 553:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 554:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 555:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 556:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 557:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 558:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 559:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 560:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 561:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 562:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 563:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 564:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 565:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 566:\n",
      "0.9567682494684621 0.9962112770225094 0.9764897632454858\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 567:\n",
      "0.9574769666902906 0.9962112770225094 0.9768441218564\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 568:\n",
      "0.9574769666902906 0.9962112770225094 0.9768441218564\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 569:\n",
      "0.9581856839121191 0.9962112770225094 0.9771984804673143\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 570:\n",
      "0.9581856839121191 0.9962112770225094 0.9771984804673143\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 571:\n",
      "0.9581856839121191 0.9962112770225094 0.9771984804673143\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 572:\n",
      "0.9581856839121191 0.9962112770225094 0.9771984804673143\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 573:\n",
      "0.9581856839121191 0.9962112770225094 0.9771984804673143\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 574:\n",
      "0.9581856839121191 0.9962112770225094 0.9771984804673143\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 575:\n",
      "0.9581856839121191 0.9962112770225094 0.9771984804673143\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 576:\n",
      "0.9581856839121191 0.9962112770225094 0.9771984804673143\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 577:\n",
      "0.9581856839121191 0.9962112770225094 0.9771984804673143\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 578:\n",
      "0.9581856839121191 0.9962112770225094 0.9771984804673143\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 579:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 580:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 581:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 582:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 583:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 584:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 585:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 586:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 587:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 588:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 589:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 590:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 591:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 592:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 593:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 594:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 595:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 596:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 597:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 598:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 599:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 600:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 601:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 602:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 603:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 604:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 605:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 606:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 607:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 608:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 609:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 610:\n",
      "0.9588944011339475 0.9962112770225094 0.9775528390782284\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 611:\n",
      "0.959603118355776 0.9962112770225094 0.9779071976891427\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 612:\n",
      "0.959603118355776 0.9962112770225094 0.9779071976891427\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 613:\n",
      "0.959603118355776 0.9962112770225094 0.9779071976891427\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 614:\n",
      "0.959603118355776 0.9962112770225094 0.9779071976891427\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 615:\n",
      "0.959603118355776 0.9962112770225094 0.9779071976891427\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 616:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 617:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 618:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 619:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 620:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9719101123595506 0.9928507596067918 0.9823804359831712\n",
      "epoch 621:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 622:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 623:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 624:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 625:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 626:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 627:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 628:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 629:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 630:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 631:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 632:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 633:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 634:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 635:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 636:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 637:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 638:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 639:\n",
      "0.9603118355776046 0.9962112770225094 0.978261556300057\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 640:\n",
      "0.961020552799433 0.99598841096501 0.9785044818822215\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 641:\n",
      "0.961020552799433 0.99598841096501 0.9785044818822215\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 642:\n",
      "0.961020552799433 0.99598841096501 0.9785044818822215\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 643:\n",
      "0.961020552799433 0.99598841096501 0.9785044818822215\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 644:\n",
      "0.961020552799433 0.99598841096501 0.9785044818822215\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 645:\n",
      "0.961020552799433 0.99598841096501 0.9785044818822215\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 646:\n",
      "0.961020552799433 0.99598841096501 0.9785044818822215\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 647:\n",
      "0.961020552799433 0.99598841096501 0.9785044818822215\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 648:\n",
      "0.961020552799433 0.99598841096501 0.9785044818822215\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 649:\n",
      "0.961020552799433 0.99598841096501 0.9785044818822215\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 650:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 651:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 652:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 653:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 654:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 655:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 656:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 657:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 658:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 659:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 660:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 661:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 662:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 663:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9747191011235955 0.9928507596067918 0.9837849303651937\n",
      "epoch 664:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 665:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 666:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 667:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 668:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 669:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 670:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 671:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 672:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 673:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 674:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 675:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 676:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 677:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 678:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 679:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 680:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 681:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 682:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 683:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 684:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 685:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 686:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 687:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 688:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 689:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 690:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 691:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 692:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 693:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 694:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 695:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 696:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 697:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 698:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 699:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 700:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 701:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 702:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 703:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 704:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 705:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 706:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 707:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 708:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 709:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 710:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 711:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 712:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 713:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 714:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 715:\n",
      "0.961020552799433 0.9957655449075106 0.9783930488534718\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 716:\n",
      "0.9617292700212615 0.9957655449075106 0.978747407464386\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 717:\n",
      "0.9617292700212615 0.9957655449075106 0.978747407464386\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 718:\n",
      "0.9617292700212615 0.9957655449075106 0.978747407464386\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 719:\n",
      "0.9617292700212615 0.9957655449075106 0.978747407464386\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 720:\n",
      "0.9617292700212615 0.9957655449075106 0.978747407464386\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 721:\n",
      "0.9617292700212615 0.9957655449075106 0.978747407464386\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 722:\n",
      "0.9617292700212615 0.9957655449075106 0.978747407464386\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 723:\n",
      "0.9617292700212615 0.9957655449075106 0.978747407464386\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 724:\n",
      "0.9617292700212615 0.9957655449075106 0.978747407464386\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 725:\n",
      "0.9617292700212615 0.9957655449075106 0.978747407464386\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 726:\n",
      "0.9617292700212615 0.9957655449075106 0.978747407464386\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 727:\n",
      "0.9617292700212615 0.9957655449075106 0.978747407464386\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 728:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 729:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 730:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 731:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 732:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 733:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 734:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 735:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 736:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 737:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 738:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 739:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 740:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 741:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 742:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 743:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 744:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 745:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 746:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 747:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 748:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 749:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 750:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 751:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 752:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 753:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 754:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 755:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 756:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 757:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 758:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 759:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 760:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 761:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 762:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 763:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 764:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 765:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 766:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 767:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 768:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 769:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 770:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 771:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 772:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 773:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 774:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 775:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 776:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 777:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 778:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 779:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 780:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 781:\n",
      "0.96243798724309 0.9957655449075106 0.9791017660753003\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 782:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 783:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 784:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 785:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 786:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 787:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 788:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 789:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 790:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 791:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 792:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 793:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 794:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 795:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 796:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 797:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 798:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 799:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 800:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 801:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 802:\n",
      "0.96243798724309 0.9955426788500111 0.9789903330465506\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 803:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96243798724309 0.9953198127925117 0.9788789000178009\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 804:\n",
      "0.96243798724309 0.9953198127925117 0.9788789000178009\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 805:\n",
      "0.96243798724309 0.9953198127925117 0.9788789000178009\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 806:\n",
      "0.96243798724309 0.9953198127925117 0.9788789000178009\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 807:\n",
      "0.96243798724309 0.9953198127925117 0.9788789000178009\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 808:\n",
      "0.96243798724309 0.9953198127925117 0.9788789000178009\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 809:\n",
      "0.96243798724309 0.9953198127925117 0.9788789000178009\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 810:\n",
      "0.96243798724309 0.9953198127925117 0.9788789000178009\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 811:\n",
      "0.96243798724309 0.9953198127925117 0.9788789000178009\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 812:\n",
      "0.96243798724309 0.9953198127925117 0.9788789000178009\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 813:\n",
      "0.96243798724309 0.9953198127925117 0.9788789000178009\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 814:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 815:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 816:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 817:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 818:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 819:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 820:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 821:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 822:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 823:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 824:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 825:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 826:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 827:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 828:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 829:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 830:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 831:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 832:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 833:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 834:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 835:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 836:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 837:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 838:\n",
      "0.96243798724309 0.9950969467350123 0.9787674669890511\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 839:\n",
      "0.96243798724309 0.9948740806775128 0.9786560339603014\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 840:\n",
      "0.96243798724309 0.9948740806775128 0.9786560339603014\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 841:\n",
      "0.96243798724309 0.9948740806775128 0.9786560339603014\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 842:\n",
      "0.96243798724309 0.9948740806775128 0.9786560339603014\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 843:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 844:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 845:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 846:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 847:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 848:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 849:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 850:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 851:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 852:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 853:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 854:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 855:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 856:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 857:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 858:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 859:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 860:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 861:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 862:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 863:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 864:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 865:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 866:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 867:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 868:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 869:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 870:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 872:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 873:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 874:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 875:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 876:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 877:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 878:\n",
      "0.9631467044649185 0.9948740806775128 0.9790103925712157\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 879:\n",
      "0.9631467044649185 0.9946512146200134 0.978898959542466\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 880:\n",
      "0.9631467044649185 0.9946512146200134 0.978898959542466\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 881:\n",
      "0.9631467044649185 0.9946512146200134 0.978898959542466\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 882:\n",
      "0.9631467044649185 0.9946512146200134 0.978898959542466\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 883:\n",
      "0.9631467044649185 0.9946512146200134 0.978898959542466\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 884:\n",
      "0.9631467044649185 0.9946512146200134 0.978898959542466\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 885:\n",
      "0.9631467044649185 0.9946512146200134 0.978898959542466\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 886:\n",
      "0.9631467044649185 0.9946512146200134 0.978898959542466\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 887:\n",
      "0.9631467044649185 0.9946512146200134 0.978898959542466\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 888:\n",
      "0.9631467044649185 0.9946512146200134 0.978898959542466\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 889:\n",
      "0.9631467044649185 0.9946512146200134 0.978898959542466\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 890:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 891:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 892:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 893:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 894:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 895:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 896:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 897:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 898:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 899:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 900:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 901:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 902:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 903:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 904:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 905:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 906:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 907:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 908:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 909:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 910:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 911:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 912:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 913:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 914:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 915:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 916:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 917:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 918:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 919:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 920:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 921:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 922:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 923:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 924:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 925:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 926:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 927:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 928:\n",
      "0.963855421686747 0.9946512146200134 0.9792533181533802\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 929:\n",
      "0.9645641389085755 0.9946512146200134 0.9796076767642945\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 930:\n",
      "0.9645641389085755 0.9946512146200134 0.9796076767642945\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 931:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 932:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 933:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 934:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 935:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 936:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 937:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 938:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 939:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 940:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 941:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 942:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 943:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 944:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 945:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 946:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 947:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 948:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 949:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 950:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 951:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 952:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 953:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 954:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 955:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 956:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 957:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 958:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 959:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 960:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 961:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 962:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 963:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 964:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 965:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 966:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 967:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 968:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 969:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 970:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 971:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 972:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 973:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 974:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 975:\n",
      "0.9652728561304039 0.9946512146200134 0.9799620353752087\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 976:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 977:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 978:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 979:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 980:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 981:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 982:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 983:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 984:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 985:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 986:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 987:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 988:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 989:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 990:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 991:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 992:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 993:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 994:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 995:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 996:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 997:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 998:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 999:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n",
      "epoch 1000:\n",
      "0.9659815733522324 0.9946512146200134 0.9803163939861229\n",
      "0.9775280898876404 0.9928507596067918 0.9851894247472162\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-4)\n",
    "for epoch in range(1000):\n",
    "        print('epoch {}:'.format(epoch+1))\n",
    "        preds = []\n",
    "        labels = []\n",
    "        for x, y in train_loader:\n",
    "            x.to(device)\n",
    "            pred = model(x)\n",
    "#             print(pred)\n",
    "#             print(y)\n",
    "            loss = weighted_BCE(pred.squeeze(), y, 3)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            preds.append((pred.detach().numpy()))\n",
    "            labels.append(y.detach().numpy())\n",
    "        \n",
    "        preds  = np.concatenate(preds)\n",
    "        preds = np.array(preds)\n",
    "        labels  = np.concatenate(labels)\n",
    "        labels = np.array(labels)\n",
    "            \n",
    "        comp = np.concatenate((((preds>0.5)*1).reshape(-1,1),labels.reshape(-1,1)),1)\n",
    "\n",
    "        train_0 = sum((comp[:,0]==0) * (comp[:,1]==0)*1) / sum((comp[:,1]==0)*1)\n",
    "        train_1 = sum((comp[:,0]==1) * (comp[:,1]==1)*1) / sum((comp[:,1]==1)*1)\n",
    "            \n",
    "        print(train_0, train_1, (train_0+train_1)/2)\n",
    "            \n",
    "        for x, y in test_loader:\n",
    "            x.to(device)\n",
    "            preds = model(x).detach().numpy()\n",
    "            labels = y.detach().numpy()\n",
    "        \n",
    "        comp = np.concatenate((((preds>0.5)*1).reshape(-1,1),labels.reshape(-1,1)),1)\n",
    "\n",
    "        test_0 = sum((comp[:,0]==0) * (comp[:,1]==0)*1) / sum((comp[:,1]==0)*1)\n",
    "        test_1 = sum((comp[:,0]==1) * (comp[:,1]==1)*1) / sum((comp[:,1]==1)*1)\n",
    "        \n",
    "        print(test_0, test_1, (test_0+test_1)/2)\n",
    "    \n",
    "        if train_0>0.98 and train_1>0.98 and abs(train_0-train_1)<0.1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ffa4cae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.8725, 0.8156, 0.8013, 1.1736, 1.5972]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-2.1325], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc8eb7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = pd.DataFrame()\n",
    "# -2.2434\n",
    "params['SVM'] = [1.0379/(1.0379+0.9895+1.2842+0.6227+1.3942)]\n",
    "params['RF'] = [0.9895/(1.0379+0.9895+1.2842+0.6227+1.3942)]\n",
    "params['XGBoost'] = [1.2842/(1.0379+0.9895+1.2842+0.6227+1.3942)]\n",
    "params_JAK1['Graph'] = [0.6227/(1.0379+0.9895+1.2842+0.6227+1.3942)]\n",
    "params_JAK1['ChemBert'] = [1.3942/(1.0379+0.9895+1.2842+0.6227+1.3942)]\n",
    "params_JAK1.index = ['JAK1']\n",
    "# params_JAK1 = np.array([1.0379, 0.9895, 1.2842, 0.6227, 1.3942]).reshape(-1,1)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(params_JAK1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91181a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAK1\n",
    "# Parameter containing:\n",
    "# tensor([[1.0379, 0.9895, 1.2842, 0.6227, 1.3942]], requires_grad=True)\n",
    "# Parameter containing:\n",
    "# tensor([-2.2434], requires_grad=True)\n",
    "\n",
    "# Parameter containing:\n",
    "# tensor([[0.8725, 0.8156, 0.8013, 1.1736, 1.5972]], requires_grad=True)\n",
    "# Parameter containing:\n",
    "# tensor([-2.1325], requires_grad=True)\n",
    "\n",
    "# JAK2\n",
    "# Parameter containing:\n",
    "# tensor([[1.1116, 0.8958, 0.7605, 1.3776, 1.7598]], requires_grad=True)\n",
    "# Parameter containing:\n",
    "# tensor([-2.9552], requires_grad=True)\n",
    "\n",
    "# Parameter containing:\n",
    "# tensor([[0.7218, 0.8260, 1.3243, 1.2601, 1.8034]], requires_grad=True)\n",
    "# Parameter containing:\n",
    "# tensor([-2.9857], requires_grad=True)\n",
    "\n",
    "# JAK3\n",
    "# Parameter containing:\n",
    "# tensor([[0.7654, 1.1997, 0.3108, 1.2645, 1.5275]], requires_grad=True)\n",
    "# Parameter containing:\n",
    "# tensor([-2.5899], requires_grad=True)\n",
    "\n",
    "# TYK2\n",
    "# Parameter containing:\n",
    "# tensor([[0.4161, 0.2859, 1.1439, 1.2353, 0.4284]], requires_grad=True)\n",
    "# Parameter containing:\n",
    "# tensor([-1.7482], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "14a657eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.243079221682321"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8725*0.981885318619119+0.8156+0.8013*0.9989202+1.1736*0.999644875526428+1.5972*0.99997889995575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4eb71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model/comodel_TYK2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "40c095c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "params = np.array([[0.8725, 0.8156, 0.8013, 1.1736, 1.5972],\\\n",
    "          [1.1116, 0.8958, 0.7605, 1.3776, 1.7598],\\\n",
    "          [0.7654, 1.1997, 0.3108, 1.2645, 1.5275],\\\n",
    "          [0.4161, 0.2859, 1.1439, 1.2353, 0.4284]\n",
    "         ])\n",
    "bias = [-2.1325, -2.955, -2.5899, -1.7482]\n",
    "\n",
    "params = params\n",
    "\n",
    "\n",
    "params_df = pd.DataFrame()\n",
    "# -2.2434\n",
    "params_df['SVM'] = params[:,0]\n",
    "params_df['RF'] = params[:,1]\n",
    "params_df['XGBoost'] = params[:,2]\n",
    "params_df['Graph'] = params[:,3]\n",
    "params_df['ChemBert'] = params[:,4]\n",
    "params_df.index = ['JAK1', 'JAK2', 'JAK3', 'TYK2']\n",
    "# params_JAK1 = np.array([1.0379, 0.9895, 1.2842, 0.6227, 1.3942]).reshape(-1,1)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(params_df, annot=True, cmap='GnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8b2286fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1475, 5])\n",
      "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
      "& 0.989  &  0.985  &          0.993  &     0.993  &0.978  &0.993 &0.999 &   0.970 &   1.000\n",
      "torch.Size([2033, 5])\n",
      "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
      "& 0.975  &  0.974  &          0.986  &     0.977  &0.971  &0.981 &0.996 &   0.943 &   0.998\n",
      "torch.Size([1545, 5])\n",
      "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
      "& 0.970  &  0.969  &          0.986  &     0.970  &0.969  &0.978 &0.993 &   0.930 &   0.997\n",
      "torch.Size([485, 5])\n",
      "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
      "& 0.988  &  0.985  &          0.987  &     0.994  &0.977  &0.990 &0.999 &   0.973 &   0.999\n"
     ]
    }
   ],
   "source": [
    "enzymes = ['JAK1', 'JAK2', 'JAK3', 'TYK2']\n",
    "for enzyme in enzymes:\n",
    "    ind = enzymes.index(enzyme)\n",
    "    data_path = 'data/' + enzyme + '_new.csv'\n",
    "    data = pd.read_csv(data_path)\n",
    "    y = data['Activity'].to_numpy()\n",
    "    \n",
    "    probs = data.iloc[:,3:].to_numpy()\n",
    "    \n",
    "\n",
    "    probs = torch.Tensor(probs)\n",
    "    ys = torch.Tensor(y)\n",
    "    import torch.utils.data as utils\n",
    "    use_cuda = False\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    dataset = utils.TensorDataset(probs, ys)\n",
    "\n",
    "    split = 0.8\n",
    "    train_num = int(split*probs.size(0))\n",
    "    test_num = probs.size(0) - train_num\n",
    "\n",
    "    train_set, test_set = torch.utils.data.random_split(dataset, [train_num, test_num], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=test_num, shuffle=False)\n",
    "\n",
    "    sigmoid = lambda x: 1/(1+np.exp(-x))\n",
    "\n",
    "    for x, y in test_loader:\n",
    "    #     model = torch.load('model/comodel_' + enzyme + '.pt')\n",
    "    #     prob = model(x)\n",
    "    #     print(sigmoid(params[3:4]@x.detach().numpy().T+bias[3]))\n",
    "        print(x.size())\n",
    "    prob = sigmoid(params[ind:(ind+1)]@x.detach().numpy().T+bias[ind])[0]\n",
    "    y = y.detach().numpy()\n",
    "    pred = get_preds(prob)\n",
    "\n",
    "    evaluate(y, pred, prob)\n",
    "    t, f = get_tpr_fpr(y, prob)\n",
    "    save_tpr_fpr('comodel', enzyme, t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "138ec4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, weighted accuracy, precision, recall/SE, SP,     F1,     AUC,     MCC,     AP\n",
      "& 0.988  &  0.985  &          0.987  &     0.994  &0.977  &0.990 &0.999 &   0.973 &   0.999\n"
     ]
    }
   ],
   "source": [
    "def get_preds(probabilities, threshold=0.5):\n",
    "        return [1 if prob > threshold else 0 for prob in probabilities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "80a4d3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "148f5b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98       176\n",
      "         1.0       0.99      0.99      0.99       309\n",
      "\n",
      "    accuracy                           0.99       485\n",
      "   macro avg       0.99      0.99      0.99       485\n",
      "weighted avg       0.99      0.99      0.99       485\n",
      "\n",
      "\ttest acc = 98.76\tap = 99.92\tf1 = 99.03\troc = 99.85\n"
     ]
    }
   ],
   "source": [
    "labels = y\n",
    "probas = prob1\n",
    "thre = 0.5\n",
    "print(classification_report(labels, probas>thre))\n",
    "print('\\ttest acc = {}\\tap = {}\\tf1 = {}\\troc = {}'.format(round(accuracy_score(labels, (probas>thre)*1)*100, 2), \\\n",
    "             round(average_precision_score(labels, probas)*100, 2), round(f1_score(labels, (probas>thre)*1)*100, 2), round(roc_auc_score(labels, probas)*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a7fd5197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98       176\n",
      "         1.0       0.99      0.99      0.99       309\n",
      "\n",
      "    accuracy                           0.99       485\n",
      "   macro avg       0.99      0.99      0.99       485\n",
      "weighted avg       0.99      0.99      0.99       485\n",
      "\n",
      "\ttest acc = 98.76\tap = 99.92\tf1 = 99.03\troc = 99.85\n"
     ]
    }
   ],
   "source": [
    "labels = y\n",
    "probas = prob2\n",
    "thre = 0.5\n",
    "print(classification_report(labels, probas>thre))\n",
    "print('\\ttest acc = {}\\tap = {}\\tf1 = {}\\troc = {}'.format(round(accuracy_score(labels, (probas>thre)*1)*100, 2), \\\n",
    "             round(average_precision_score(labels, probas)*100, 2), round(f1_score(labels, (probas>thre)*1)*100, 2), round(roc_auc_score(labels, probas)*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "52980fa0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.17670052e-05, -7.07720858e-07, -8.27197621e-07, -3.04042627e-07,\n",
       "       -1.19797877e-05, -9.37099602e-07, -1.19602600e-05, -2.80498551e-07,\n",
       "       -1.21199295e-05, -8.21453273e-06, -1.15330966e-05, -1.30589323e-05,\n",
       "       -1.12080411e-05, -1.18632580e-05, -1.16990301e-05, -1.43981945e-05,\n",
       "       -1.16255050e-05, -6.98460706e-07, -1.16046822e-05, -1.16318182e-05,\n",
       "       -6.49588077e-07, -1.15427426e-05, -1.11558681e-05, -1.16969546e-05,\n",
       "       -1.16682492e-05, -6.51131094e-07, -1.10703625e-05, -4.22773073e-07,\n",
       "       -6.54377661e-07, -1.20257101e-05, -8.11977102e-06, -1.17145386e-05,\n",
       "       -7.27440026e-07, -1.20009180e-05, -1.14713862e-05, -1.80989133e-06,\n",
       "       -9.27560214e-07, -3.51428161e-07, -1.16791829e-05, -1.17378499e-05,\n",
       "       -1.20405496e-05, -1.15974154e-05, -1.16097578e-05, -1.12892161e-05,\n",
       "       -1.15825147e-05, -4.73409201e-07, -1.16092745e-05, -1.16149582e-05,\n",
       "       -3.79913625e-07, -1.18281689e-05, -1.16357874e-05, -1.16200251e-05,\n",
       "       -1.18630995e-05, -1.15928392e-05, -1.16892999e-05, -1.18927668e-05,\n",
       "       -2.90651595e-06, -1.18218545e-05, -1.16650758e-05, -1.17282609e-05,\n",
       "       -1.19135170e-05, -6.06491828e-07, -3.99031362e-07, -1.53840397e-05,\n",
       "       -1.16096857e-05, -1.18464968e-05, -1.15880902e-05, -1.18340410e-05,\n",
       "       -1.16125218e-05, -1.20138361e-05, -3.64861176e-07, -1.15442531e-05,\n",
       "       -1.17730410e-05, -1.16213861e-05, -1.14229342e-05, -1.18371897e-05,\n",
       "       -1.21737165e-05, -1.15793952e-05, -1.17361919e-05, -1.19120350e-05,\n",
       "       -5.37984749e-07, -1.16848047e-05, -1.16447890e-05, -5.35656142e-07,\n",
       "       -1.16151765e-05, -1.16219252e-05, -1.16855898e-05, -1.24205694e-05,\n",
       "       -1.16878112e-05, -1.16978586e-05, -1.15598647e-05, -1.13922371e-05,\n",
       "       -8.01699368e-07, -1.30891737e-05, -1.17456359e-05, -5.03700325e-07,\n",
       "       -1.13759184e-05, -1.16630072e-05, -3.60573188e-06, -1.14637670e-05,\n",
       "       -1.18533224e-05, -1.21147799e-05, -1.16215886e-05, -3.28542020e-07,\n",
       "       -1.16309906e-05, -5.56719005e-07, -2.93778780e-07, -7.80945186e-06,\n",
       "       -1.16038744e-05, -1.16771755e-05, -1.37059116e-05, -6.28720979e-07,\n",
       "       -1.19954200e-05, -1.16646156e-05, -1.81712646e-05, -9.78846011e-07,\n",
       "       -1.16611244e-05, -2.18897694e-06, -3.30218681e-06, -1.51193054e-06,\n",
       "       -2.31700629e-06, -1.82526272e-06, -8.32814609e-07, -1.14583082e-05,\n",
       "       -1.16446665e-05, -1.16135938e-05, -1.15919951e-05, -1.19176440e-05,\n",
       "       -1.18355728e-05, -6.24244783e-07, -1.27356104e-05, -4.62208733e-07,\n",
       "       -1.19894629e-05, -1.16857232e-05, -2.18388931e-06, -1.16149811e-05,\n",
       "       -1.16847835e-05, -1.16097714e-05, -1.21508718e-05, -1.06343149e-06,\n",
       "       -1.15771970e-05, -1.16314581e-05, -1.42624714e-05, -1.16597614e-05,\n",
       "       -2.53010087e-07, -1.05458961e-06, -1.14805084e-05, -1.16157757e-05,\n",
       "       -1.15521099e-05, -2.52910899e-07, -1.19614501e-05, -5.70601934e-06,\n",
       "       -1.18050193e-05, -4.32303435e-07, -2.72515779e-07, -1.17927310e-05,\n",
       "       -5.79797252e-07, -3.25768817e-07, -1.47202043e-05, -1.16172458e-05,\n",
       "       -1.62446644e-05, -1.16360119e-05, -1.18342579e-05, -1.16616235e-05,\n",
       "       -1.19690062e-05, -1.16873491e-05, -1.15367660e-05, -1.16147568e-05,\n",
       "       -1.15522699e-05, -5.20063036e-07, -1.19658627e-05, -1.20155894e-05,\n",
       "       -1.16449357e-05, -1.16631843e-05, -1.43579008e-06, -1.19829116e-05,\n",
       "       -9.03905651e-07, -1.15995777e-05, -1.16774382e-05, -4.75984439e-07,\n",
       "       -1.15579605e-05, -2.55493658e-06, -1.41184042e-06, -3.85394481e-07,\n",
       "       -1.17592803e-05, -1.17670195e-05, -1.10400236e-05, -1.17695126e-05,\n",
       "       -1.17878500e-05, -1.17605880e-05, -2.79914819e-07, -1.16591169e-05,\n",
       "       -1.16988881e-05, -7.92242889e-07, -1.06327479e-06, -1.17413721e-05,\n",
       "       -4.79939561e-07, -2.90237505e-06, -1.22234300e-05, -1.15581336e-05,\n",
       "       -3.67933158e-07, -1.18029661e-05, -1.18088451e-05, -1.16913446e-05,\n",
       "       -1.19745919e-05, -6.59762892e-07, -1.15072277e-05, -1.14816778e-05,\n",
       "       -1.16788395e-05, -1.16551802e-05, -1.15371839e-05, -2.92475325e-07,\n",
       "       -1.13481142e-05, -1.16313823e-05, -1.19333588e-05, -1.16193913e-05,\n",
       "       -1.16321197e-05, -1.17115892e-05, -2.79826139e-06, -1.18839230e-05,\n",
       "       -1.15584191e-05, -1.15746070e-05, -1.80274628e-06, -1.16597569e-05,\n",
       "       -2.71593352e-07, -2.57823738e-07, -1.16558553e-05, -1.33411702e-05,\n",
       "       -1.49944308e-05, -1.23459069e-05, -1.69521940e-05, -1.44384308e-06,\n",
       "       -3.07844241e-07, -2.05622371e-06, -1.16934232e-05, -1.15331997e-05,\n",
       "       -1.16189686e-05, -5.00381819e-06, -1.09945114e-05, -1.19906112e-05,\n",
       "       -1.16367121e-05, -9.18414162e-07, -5.44273342e-07, -8.02355181e-07,\n",
       "       -1.17479779e-05, -3.93887613e-07, -1.10896397e-05, -7.64500067e-07,\n",
       "       -1.17125789e-05, -1.26126621e-05, -1.32615260e-05, -1.15950841e-05,\n",
       "       -1.15748065e-05, -1.15730807e-05, -1.16163084e-05, -1.15906974e-05,\n",
       "       -1.16330401e-05, -1.16701774e-05, -1.37924830e-05, -1.33745778e-05,\n",
       "       -1.17114763e-05, -1.58533007e-05, -6.11323507e-07, -1.36743672e-06,\n",
       "       -1.50578481e-06, -1.01386952e-05, -1.16252902e-05, -2.32508039e-06,\n",
       "       -1.17261511e-05, -1.12640093e-05, -1.28835482e-05, -1.15591525e-05,\n",
       "       -1.82301508e-06, -1.15868444e-05, -1.18023476e-05, -1.18284407e-05,\n",
       "       -7.40356474e-06, -1.55581704e-05, -1.34432231e-05, -9.04381454e-06,\n",
       "       -6.31654780e-07, -8.31826248e-07, -1.46257458e-06, -1.19615683e-05,\n",
       "       -1.82601804e-06, -1.17182415e-06, -1.17502629e-05, -1.17132487e-05,\n",
       "       -1.16457046e-05, -1.17427450e-05, -7.97235131e-06, -1.19499511e-05,\n",
       "       -1.24121324e-05, -1.16001643e-05, -1.16743795e-05, -6.82724012e-06,\n",
       "       -1.18700656e-05, -1.09668395e-06, -3.27553272e-07, -1.20187725e-05,\n",
       "       -1.17560902e-05, -1.17485729e-05, -1.17272560e-05, -1.15639343e-05,\n",
       "       -1.44541115e-05, -1.15675537e-05, -1.16365194e-05, -1.21759958e-06,\n",
       "       -1.18345971e-05, -2.24586134e-07, -7.03052741e-07, -1.16241660e-05,\n",
       "       -1.15812037e-05, -1.17872394e-05, -1.16363685e-05, -1.27936358e-05,\n",
       "       -1.16863771e-05, -1.24751343e-05, -1.15394286e-05, -1.13156535e-05,\n",
       "       -3.75772662e-07, -1.16385833e-05, -1.16759238e-05, -1.04015663e-06,\n",
       "       -1.19825338e-05, -1.46999460e-05, -1.15855675e-05, -1.15715949e-05,\n",
       "       -1.16342277e-05, -1.18816654e-05, -3.43275111e-07, -1.21359694e-05,\n",
       "       -1.03518538e-05, -5.92542931e-07, -1.16141500e-05, -1.53137588e-05,\n",
       "       -1.19282593e-05, -1.63788827e-05, -1.20764892e-05, -1.51723719e-05,\n",
       "       -2.47445691e-06, -4.59563837e-06, -1.17080395e-05, -1.40176575e-06,\n",
       "       -1.17535385e-05, -1.19661081e-05, -1.18941374e-05, -2.34215140e-07,\n",
       "       -1.15993329e-05, -2.48309010e-07, -1.16553109e-05, -1.15835971e-05,\n",
       "       -1.41829646e-05, -2.20984192e-06, -1.20147407e-05, -1.80734182e-06,\n",
       "       -4.33298154e-07, -1.19676448e-05, -1.28063083e-05, -1.09413070e-05,\n",
       "       -1.16864296e-05, -1.17976741e-05, -1.14921796e-05, -1.14096852e-05,\n",
       "       -1.19558031e-05, -1.20372636e-05, -1.20088906e-05, -3.98104300e-07,\n",
       "       -8.95967372e-06, -1.18996639e-05, -1.15838883e-05, -1.19552007e-05,\n",
       "       -1.19230572e-05, -8.08931090e-06, -1.15688998e-05, -6.55375642e-07,\n",
       "       -1.22239977e-05, -1.16335850e-05, -6.49282614e-07, -1.03798810e-05,\n",
       "       -1.17274121e-05, -9.41352326e-07, -1.38514228e-05, -1.17682355e-05,\n",
       "       -1.19751338e-05, -1.56671744e-07, -1.16188868e-05, -1.18494975e-05,\n",
       "       -1.09028621e-06, -6.01374093e-07, -1.14280079e-05, -1.19371372e-05,\n",
       "       -1.17301832e-05, -1.20493691e-05, -1.16260601e-05, -7.15203735e-07,\n",
       "       -9.71806028e-06, -1.18005894e-05, -3.00071217e-07, -7.78838798e-07,\n",
       "       -1.15661801e-05, -7.02492954e-07, -1.16948258e-05, -1.06069486e-05,\n",
       "       -4.73120894e-06, -1.03351088e-06, -1.18374385e-05, -2.78315542e-07,\n",
       "       -7.72308378e-06, -1.15860940e-05, -1.86586188e-07, -1.18922281e-05,\n",
       "       -1.18365191e-05, -1.16366297e-05, -4.92144916e-07, -4.96777925e-07,\n",
       "       -1.40449815e-06, -1.16241208e-05, -7.86340085e-06, -1.17652770e-05,\n",
       "       -3.43417570e-07, -1.16215886e-05, -1.10551701e-06, -1.18538768e-05,\n",
       "       -1.35430470e-05, -1.19552687e-05, -1.16296257e-05, -1.17216205e-05,\n",
       "       -7.39985319e-07, -1.16420163e-05, -2.99807104e-06, -1.17322287e-05,\n",
       "       -1.27120848e-05, -1.15770368e-05, -4.38675445e-06, -3.18509851e-07,\n",
       "       -1.16682520e-05, -1.22116776e-05, -1.16763410e-05, -3.50833363e-07,\n",
       "       -6.49750643e-07, -1.17133846e-05, -1.17196973e-05, -2.01453381e-06,\n",
       "       -6.56529183e-07, -1.60140716e-06, -1.15273241e-06, -1.16678243e-05,\n",
       "       -1.19116124e-05, -1.17510582e-05, -1.15880921e-05, -4.84153886e-07,\n",
       "       -1.20966991e-05, -3.64679073e-07, -1.13074623e-05, -7.36855473e-06,\n",
       "       -1.19761140e-05, -1.81203366e-05, -7.92720279e-07, -1.15726599e-05,\n",
       "       -1.00461483e-06, -1.19584872e-05, -5.14206085e-06, -1.16608691e-05,\n",
       "       -1.16355791e-05, -4.29824624e-07, -1.19296280e-05, -1.22727653e-05,\n",
       "       -1.12813753e-05, -1.06501266e-05, -1.15837704e-05, -2.33912768e-07,\n",
       "       -1.31942563e-06, -8.03174718e-07, -1.16895963e-05, -1.21560435e-05,\n",
       "       -1.12828254e-06, -2.74993963e-07, -1.17422187e-05, -1.16209890e-05,\n",
       "       -1.17851387e-05, -1.15885978e-05, -2.98543636e-07, -4.39067844e-07,\n",
       "       -1.16827431e-05])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob1-prob2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f457159b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9551485180854797], [0.9394961595535278], [0.9560286998748779], [0.9560626149177551], [0.9561312794685364], [0.6630614399909973], [0.09734168648719788], [0.9480807185173035], [0.5528764724731445], [0.9079599380493164], [0.9553178548812866], [0.9544700384140015], [0.2112559974193573], [0.9512469172477722], [0.9326515793800354], [0.9489774703979492], [0.09869345277547836], [0.9558058381080627], [0.9552768468856812], [0.9562686085700989], [0.12520436942577362], [0.9516208171844482], [0.8747493028640747], [0.10243256390094757], [0.953078031539917], [0.10204314440488815], [0.9556024670600891], [0.9546800851821899], [0.9562672972679138], [0.9561081528663635], [0.9548352956771851], [0.954982578754425], [0.9518288969993591], [0.09846193343400955], [0.9490709900856018], [0.9552074670791626], [0.10668034851551056], [0.10968535393476486], [0.9553405046463013], [0.10698626190423965], [0.9314979910850525], [0.9559139013290405], [0.9470242261886597], [0.10473676770925522], [0.09652774780988693], [0.10052450001239777], [0.12780611217021942], [0.7920399904251099], [0.9362887740135193], [0.9559528827667236], [0.9235429167747498], [0.9495782852172852], [0.953775942325592], [0.9519963264465332], [0.9530227184295654], [0.9464561343193054], [0.9558950662612915], [0.10014621913433075], [0.9510971903800964], [0.16939710080623627], [0.9559486508369446], [0.801093578338623], [0.9332678318023682], [0.9540513157844543], [0.9196873307228088], [0.9562674164772034], [0.921530544757843], [0.0965246632695198], [0.9215415120124817], [0.9544315934181213], [0.9556107521057129], [0.9559311866760254], [0.9562661647796631], [0.9537686705589294], [0.09635238349437714], [0.9562683701515198], [0.9558097720146179], [0.9561318159103394], [0.9470102190971375], [0.9558278322219849], [0.8867256045341492], [0.9544019103050232], [0.95626300573349], [0.956013023853302], [0.1323588788509369], [0.9560376405715942], [0.9481947422027588], [0.9466948509216309], [0.9545800685882568], [0.955746591091156], [0.10517822206020355], [0.9530106782913208], [0.9562607407569885], [0.9127858877182007], [0.1053551509976387], [0.9562562704086304], [0.8279445171356201], [0.9562562704086304], [0.956264853477478], [0.9189258813858032], [0.9314591884613037], [0.11161787062883377], [0.9460600018501282], [0.1004265695810318], [0.9562687873840332], [0.11292454600334167], [0.9482137560844421], [0.9560127854347229], [0.10332401096820831], [0.9560918211936951], [0.9187772274017334], [0.951137125492096], [0.9550133347511292], [0.9503834247589111], [0.9559065103530884], [0.7947925925254822], [0.11598632484674454], [0.9562607407569885], [0.9560127854347229], [0.10155510902404785], [0.9560104012489319], [0.9551309943199158], [0.9562652111053467], [0.10469064116477966], [0.954706609249115], [0.2694195508956909], [0.11428835242986679], [0.9537189602851868], [0.9534237384796143], [0.11329112946987152], [0.9476904273033142], [0.9561237096786499], [0.1296614706516266], [0.9550614953041077], [0.18610188364982605], [0.9553200602531433], [0.10456618666648865], [0.9562607407569885], [0.951407790184021], [0.8988723754882812], [0.9560757875442505], [0.9553906321525574], [0.7549235820770264], [0.9560104012489319], [0.9555326700210571], [0.11012747138738632], [0.9523079991340637], [0.10730283707380295], [0.10617562383413315], [0.9228116273880005], [0.9562664031982422], [0.9559061527252197], [0.11234082281589508], [0.4308844208717346], [0.9562661051750183], [0.956230640411377], [0.9562634825706482], [0.09837140887975693], [0.952552318572998], [0.9552398920059204], [0.10878393054008484], [0.9556107521057129], [0.956264853477478], [0.9213849306106567], [0.9543842673301697], [0.38869771361351013], [0.1015605479478836], [0.1374729424715042], [0.9085677266120911], [0.9528802633285522], [0.9552330374717712], [0.10656606405973434], [0.9560487866401672], [0.09664605557918549], [0.10925891995429993], [0.8346269726753235], [0.9548105001449585], [0.7385422587394714], [0.9542036056518555], [0.10538735240697861], [0.9554013013839722], [0.94016033411026], [0.9459125399589539], [0.9539937376976013], [0.14224521815776825], [0.09634760022163391], [0.9529170393943787], [0.921516478061676], [0.9556695222854614], [0.09927365183830261], [0.9552426934242249], [0.15501686930656433], [0.9562687873840332], [0.12087655812501907], [0.910578191280365], [0.955615758895874], [0.9554779529571533], [0.9486081004142761], [0.9492173790931702], [0.9489498138427734], [0.9559493064880371], [0.9559036493301392], [0.13567209243774414], [0.9549036622047424], [0.9527024626731873], [0.952090859413147], [0.9554318785667419], [0.9548175930976868], [0.9562666416168213], [0.10195372253656387], [0.9549556374549866], [0.5181922912597656], [0.13817836344242096], [0.10184573382139206], [0.9562645554542542], [0.8730223178863525], [0.11035121232271194], [0.9118611216545105], [0.10438656806945801], [0.9553834795951843], [0.9558250904083252], [0.953414261341095], [0.8178471326828003], [0.9530949592590332], [0.9562668204307556], [0.9525406360626221], [0.9558951258659363], [0.9554592967033386], [0.9524903297424316], [0.9549175500869751], [0.9491009712219238], [0.9215388894081116], [0.95607990026474], [0.9519972205162048], [0.9556757211685181], [0.9481494426727295], [0.09835898131132126], [0.9536331295967102], [0.8390697240829468], [0.9562656283378601], [0.9558812379837036], [0.9552422761917114], [0.11649767309427261], [0.9203778505325317], [0.09659253060817719], [0.48881950974464417], [0.9206894636154175], [0.9559447169303894], [0.09776493906974792], [0.9448355436325073], [0.9517497420310974], [0.9451603293418884], [0.12404962629079819], [0.12049852311611176], [0.9558081030845642], [0.9383255839347839], [0.9552905559539795], [0.9447252154350281], [0.9554745554924011], [0.9187706708908081], [0.1094382256269455], [0.9552354216575623], [0.9558573365211487], [0.9552541375160217], [0.9535406827926636], [0.9269676804542542], [0.9461687207221985], [0.9562408924102783], [0.11684100329875946], [0.9471614360809326], [0.09911934286355972], [0.9562354683876038], [0.955312967300415], [0.12242154031991959], [0.9552410840988159], [0.10982107371091843], [0.9540228247642517], [0.9476913809776306], [0.9557713270187378], [0.9555516242980957], [0.10851991921663284], [0.9554080963134766], [0.9515714049339294], [0.8997419476509094], [0.9538830518722534], [0.9541141390800476], [0.9541569352149963], [0.9553416967391968], [0.9539374113082886], [0.9215359091758728], [0.9535356760025024], [0.9562561511993408], [0.9215342402458191], [0.9550197720527649], [0.9546805620193481], [0.9545506238937378], [0.9501880407333374], [0.9549588561058044], [0.9561314582824707], [0.9559763073921204], [0.9559528827667236], [0.9552205204963684], [0.11601833254098892], [0.09719465672969818], [0.9547752737998962], [0.9078972339630127], [0.9535535573959351], [0.897824227809906], [0.3523332476615906], [0.954781711101532], [0.9519442319869995], [0.9554610848426819], [0.9553046226501465], [0.9215471744537354], [0.09772885590791702], [0.8997307419776917], [0.9558041095733643], [0.9538018107414246], [0.9529578685760498], [0.09800344705581665], [0.9561140537261963], [0.9537845849990845], [0.9538660645484924], [0.9562625885009766], [0.9215111136436462], [0.10642705112695694], [0.10981834679841995], [0.9215158820152283], [0.9562683701515198], [0.9555997252464294], [0.9484903216362], [0.9120645523071289], [0.9559528827667236], [0.9562686681747437], [0.9556271433830261], [0.9489560127258301], [0.956232488155365], [0.9553311467170715], [0.9553708434104919], [0.9556766152381897], [0.9445382952690125], [0.9214960336685181], [0.9558641314506531], [0.9553452730178833], [0.9522907137870789], [0.9556592702865601], [0.11114100366830826], [0.10618887096643448], [0.9528869986534119], [0.954811692237854], [0.09983871132135391], [0.30976593494415283], [0.9215415120124817], [0.9211931824684143], [0.9491649866104126], [0.9556350111961365], [0.9034687280654907], [0.9558197855949402], [0.9550109505653381], [0.955165684223175], [0.9525614976882935], [0.9476882219314575], [0.09741771221160889], [0.9559789299964905], [0.9554198384284973], [0.909263014793396], [0.9524415731430054], [0.9546804428100586], [0.9215282201766968], [0.955011248588562], [0.9499163627624512], [0.10095879435539246], [0.9549261331558228], [0.9542772173881531], [0.11511774361133575], [0.9562674760818481], [0.9558892846107483], [0.9516685605049133], [0.8658797144889832], [0.17045868933200836], [0.9539854526519775], [0.13705328106880188], [0.9560273885726929], [0.956233024597168], [0.13789816200733185], [0.867998480796814], [0.8973721861839294], [0.942572295665741], [0.9534181952476501], [0.956088125705719], [0.9487254023551941], [0.9561377763748169], [0.9552960991859436], [0.09653421491384506], [0.9561775922775269], [0.9536221623420715], [0.9562646746635437], [0.8700059652328491], [0.950054407119751], [0.9214958548545837], [0.9497488141059875], [0.9319872260093689], [0.11552982777357101], [0.952471911907196], [0.9502260684967041], [0.8603236675262451], [0.10788846015930176], [0.09726569801568985], [0.9176018834114075], [0.945268988609314], [0.9535215497016907], [0.9562695622444153], [0.15414473414421082], [0.9543071389198303], [0.9529301524162292], [0.09668795019388199], [0.9562633633613586], [0.9553787112236023], [0.11128974705934525], [0.9528446793556213], [0.9562664031982422], [0.9215291738510132], [0.9562599658966064], [0.10359155386686325], [0.9558862447738647], [0.13565370440483093], [0.10755600780248642], [0.9498379826545715], [0.1010676920413971], [0.9560960531234741], [0.9554904699325562], [0.9529512524604797], [0.9534751772880554], [0.9550226926803589], [0.9469549655914307], [0.9511898756027222], [0.9562690258026123], [0.9560344815254211], [0.10640305280685425], [0.9554194808006287], [0.9558548331260681], [0.9551483988761902], [0.9559449553489685], [0.9531832337379456], [0.9558598399162292], [0.09637919813394547], [0.955947995185852], [0.09676840156316757], [0.9553760886192322], [0.09635431319475174], [0.9542706608772278], [0.11141736060380936], [0.9554749727249146], [0.10332828015089035], [0.9522192478179932], [0.9528817534446716], [0.11030545085668564], [0.9542096853256226], [0.12206409871578217], [0.09755527228116989], [0.15091672539710999], [0.506605863571167], [0.09800349175930023], [0.9562678337097168], [0.9214641451835632], [0.9510096311569214], [0.9541270732879639], [0.9547210931777954], [0.11278843134641647], [0.9535344839096069], [0.11203587055206299], [0.09635432809591293], [0.43292349576950073], [0.9559528827667236], [0.955913782119751], [0.9558562636375427], [0.9562646746635437], [0.11692855507135391], [0.9561213254928589], [0.09668239206075668], [0.9542896747589111], [0.9560040831565857], [0.955812931060791], [0.9561395645141602], [0.9558908939361572], [0.9558876156806946], [0.9215229749679565], [0.9519659876823425], [0.7416711449623108], [0.9560789465904236], [0.9562661647796631], [0.10013057291507721], [0.955741822719574], [0.9562695622444153], [0.9560757875442505], [0.9562689065933228], [0.9556599259376526], [0.13637486100196838], [0.951429545879364], [0.9196316003799438], [0.9518445730209351], [0.9560157656669617], [0.9551984071731567], [0.9558283686637878], [0.9522818326950073], [0.9557291865348816], [0.9533026814460754], [0.10259043425321579], [0.9555220007896423], [0.9562659859657288], [0.09706714004278183], [0.9556026458740234], [0.9125941395759583], [0.11307606101036072], [0.9554083943367004], [0.9538090825080872], [0.9559677243232727], [0.9529757499694824], [0.9562686681747437], [0.9554592370986938], [0.9552398920059204], [0.9543704390525818], [0.9562498331069946], [0.5523077249526978], [0.9562209248542786], [0.956108033657074], [0.311806321144104], [0.17571605741977692], [0.9557245969772339], [0.9562677145004272], [0.9190956354141235], [0.9562686085700989], [0.9340039491653442], [0.10884314030408859], [0.9557346105575562], [0.24832746386528015], [0.9558553099632263], [0.9209728837013245], [0.9558289051055908], [0.9552497863769531], [0.9445165991783142], [0.9562562704086304], [0.9521053433418274], [0.10956598818302155], [0.9557597637176514], [0.95609050989151], [0.9215128421783447], [0.1333964318037033], [0.11594069749116898], [0.1108236089348793], [0.947045087814331], [0.1050632894039154], [0.9201217293739319], [0.10703036934137344], [0.9556894302368164], [0.9555467367172241], [0.9039273858070374], [0.9562664031982422], [0.09632653743028641], [0.9562452435493469], [0.9181381464004517], [0.9532536268234253], [0.9562675952911377], [0.9545926451683044], [0.9552260637283325], [0.11973276734352112], [0.14828552305698395], [0.8409977555274963], [0.9490562081336975], [0.955142617225647], [0.10966016352176666], [0.9534388780593872], [0.9548238515853882], [0.95572829246521], [0.9098997712135315], [0.9562570452690125], [0.10370121896266937], [0.10299043357372284], [0.5154634714126587], [0.8641916513442993], [0.9551617503166199], [0.9562686681747437], [0.12201055139303207], [0.9215842485427856], [0.9544157385826111], [0.9560521245002747], [0.9543787240982056], [0.9558837413787842], [0.9492909908294678], [0.9510606527328491], [0.956092119216919], [0.09874678403139114], [0.9523997902870178], [0.11628665030002594], [0.10458239167928696], [0.1178603321313858], [0.09694381803274155], [0.9556334614753723], [0.9361335039138794], [0.9215291738510132], [0.9550995826721191], [0.6614431142807007], [0.9558905959129333], [0.10450590401887894], [0.955293595790863], [0.9205740690231323], [0.9560267329216003], [0.9562661647796631], [0.955491840839386], [0.9560368061065674], [0.09676727652549744], [0.9557312726974487], [0.12210139632225037], [0.9562182426452637], [0.22102153301239014], [0.9538892507553101], [0.8900070190429688], [0.9536383152008057], [0.9561057686805725], [0.9215127825737], [0.9423016905784607], [0.8905235528945923], [0.10477804392576218], [0.10424919426441193], [0.9551764726638794], [0.1370803266763687], [0.9562608599662781], [0.9562670588493347], [0.9562602043151855], [0.09684210270643234], [0.9561057686805725], [0.9551295638084412], [0.954143226146698], [0.954811692237854], [0.9557896256446838], [0.9554443955421448], [0.12986673414707184], [0.09667795151472092], [0.9562633633613586], [0.9562644362449646], [0.11077200621366501], [0.9543048739433289], [0.9556359648704529], [0.9113279581069946], [0.9529839754104614], [0.38619351387023926], [0.9199609756469727], [0.1088743582367897], [0.9562202095985413], [0.955743134021759], [0.95417720079422], [0.9536228179931641], [0.9084420800209045], [0.9557896256446838], [0.9562550783157349], [0.149214506149292], [0.9548352956771851], [0.9507851600646973], [0.9159364104270935], [0.9208139777183533], [0.9560823440551758], [0.9554390907287598], [0.9555762410163879], [0.9560884237289429], [0.1409938782453537], [0.5985097289085388], [0.9507036805152893], [0.10230100899934769], [0.9560467004776001], [0.9381664991378784], [0.10592599958181381], [0.9534186124801636], [0.955643355846405], [0.9547505378723145], [0.9481176137924194], [0.13436363637447357], [0.951266348361969], [0.11592631042003632], [0.9510549306869507], [0.1410606950521469], [0.12460429221391678], [0.9557310342788696], [0.956108570098877], [0.09645996242761612], [0.9550675749778748], [0.956202507019043], [0.10238680243492126], [0.5873103141784668], [0.956264853477478], [0.9551567435264587], [0.9197767972946167], [0.26855871081352234], [0.954910397529602], [0.9474242329597473], [0.9557426571846008], [0.9450356364250183], [0.9550353288650513], [0.9562644362449646], [0.9552187919616699], [0.9523009061813354], [0.9562632441520691], [0.9545511603355408], [0.9545971155166626], [0.09790723770856857], [0.10643332451581955], [0.9558635950088501], [0.1024308055639267], [0.9522808790206909], [0.9548483490943909], [0.9562678337097168], [0.9560972452163696], [0.19364693760871887], [0.9557338356971741], [0.9493011832237244], [0.9519206285476685], [0.9557743668556213], [0.9546800851821899], [0.9560210704803467], [0.11962742358446121], [0.9202239513397217], [0.10550713539123535], [0.942110538482666], [0.9498358964920044], [0.956260621547699], [0.09794303774833679], [0.9554377794265747], [0.9559528827667236], [0.12345428764820099], [0.9560463428497314], [0.9554928541183472], [0.9510834217071533], [0.9552963376045227], [0.16976220905780792], [0.11168299615383148], [0.14463038742542267], [0.9554020762443542], [0.9553354978561401], [0.9532119035720825], [0.9558629989624023], [0.956248939037323], [0.09629202634096146], [0.09968820214271545], [0.9508677124977112], [0.9562650918960571], [0.36455172300338745], [0.9561712741851807], [0.8720829486846924], [0.9546287059783936], [0.7416303753852844], [0.10414382070302963], [0.9495022296905518], [0.9553219079971313], [0.9215391874313354], [0.9533798098564148], [0.9544321298599243], [0.9553611874580383], [0.9480940103530884], [0.10441414266824722], [0.9562682509422302], [0.9559410214424133], [0.9562397003173828], [0.944532036781311], [0.9559195637702942], [0.9536192417144775], [0.9515298008918762], [0.9558115005493164], [0.9064202904701233], [0.097950279712677], [0.9562659859657288], [0.11830251663923264], [0.9557505249977112], [0.955950915813446], [0.42951589822769165], [0.12481710314750671], [0.9561886787414551], [0.12557204067707062], [0.9532421231269836], [0.9392703771591187], [0.9559528827667236], [0.9559323787689209], [0.9556096196174622], [0.9562625885009766], [0.9215826988220215], [0.10578958690166473], [0.9549207091331482], [0.9155315160751343], [0.9454208016395569], [0.9528937935829163], [0.9399534463882446], [0.9561290740966797], [0.9132803678512573], [0.9546802043914795], [0.13297463953495026], [0.9554792642593384], [0.10868043452501297], [0.9558351635932922], [0.9559756517410278], [0.9373397827148438], [0.12840935587882996], [0.9556217193603516], [0.955242931842804], [0.95626300573349], [0.1105002760887146], [0.9544575214385986], [0.9562568068504333], [0.9186230897903442], [0.9562689065933228], [0.0966055616736412], [0.9557564854621887], [0.0991722121834755], [0.3259240686893463], [0.955741822719574], [0.9547389149665833], [0.9535086750984192], [0.9562686681747437], [0.9559522271156311], [0.9544659852981567], [0.9518532156944275], [0.954763650894165], [0.9552105069160461], [0.9562659859657288], [0.9544064998626709], [0.9562686681747437], [0.9558892846107483], [0.9562572240829468], [0.9526543021202087], [0.3203409016132355], [0.9562397003173828], [0.9562632441520691], [0.9558826088905334], [0.9536834359169006], [0.9560986757278442], [0.9529845118522644], [0.9556766152381897], [0.11202383041381836], [0.9552320241928101], [0.9559445977210999], [0.9560914635658264], [0.9138343334197998], [0.1951511800289154], [0.9549418091773987], [0.47209250926971436], [0.6705567240715027], [0.926156222820282], [0.9521980881690979], [0.9535377025604248], [0.955777108669281], [0.9550108313560486], [0.9539269208908081], [0.14760102331638336], [0.9542140364646912], [0.09631985425949097], [0.10002446174621582], [0.1063297688961029], [0.09859176725149155], [0.8392430543899536], [0.2320171743631363], [0.9497204422950745], [0.9507014155387878], [0.9562515616416931], [0.09660817682743073], [0.9477418661117554], [0.11606504768133163], [0.9214180111885071], [0.09657641500234604], [0.921560525894165], [0.9561052322387695], [0.9561994671821594], [0.9559389352798462], [0.956091046333313], [0.9538058638572693], [0.10864409804344177], [0.9520699977874756], [0.10036975890398026], [0.9485840797424316], [0.9544582962989807], [0.09660813212394714], [0.2677789330482483], [0.9542321562767029], [0.9562566876411438], [0.3598214387893677], [0.0969189777970314], [0.13207069039344788], [0.913681149482727], [0.9127354025840759], [0.11625733226537704], [0.9328669309616089], [0.12048736214637756], [0.11904435604810715], [0.09628211706876755], [0.9556812644004822], [0.9562645554542542], [0.11457353830337524], [0.20936037600040436], [0.9562686085700989], [0.9543102979660034], [0.9554745554924011], [0.9561225175857544], [0.5335545539855957], [0.0991944745182991], [0.1048036590218544], [0.955396831035614], [0.9562656283378601], [0.09635431319475174], [0.09779709577560425], [0.09887091815471649], [0.9557044506072998], [0.9541131854057312], [0.9548603892326355], [0.9215261936187744], [0.9528675675392151], [0.9562585353851318], [0.10634642094373703], [0.9554659724235535], [0.9549038410186768], [0.09745731204748154], [0.9201551079750061], [0.13736553490161896], [0.9120093584060669], [0.9549563527107239], [0.9210783839225769], [0.10632043331861496], [0.10962645709514618], [0.11501748859882355], [0.14171048998832703], [0.10181717574596405], [0.12374453246593475], [0.9330339431762695], [0.13664336502552032], [0.09660813212394714], [0.9552566409111023], [0.9562591314315796], [0.9538276791572571], [0.18808679282665253], [0.9549916982650757], [0.9561653733253479], [0.9557934403419495], [0.9534721374511719], [0.1586768478155136], [0.10033880174160004], [0.9562429785728455], [0.9558188915252686], [0.9555948376655579], [0.10819023847579956], [0.1136782094836235], [0.9215366244316101], [0.9553325772285461], [0.9557346105575562], [0.09706196933984756], [0.9560363292694092], [0.14656737446784973], [0.9545741081237793], [0.955244779586792], [0.9558545351028442], [0.9508501291275024], [0.9215829372406006], [0.9540056586265564], [0.9544147253036499], [0.9515959024429321], [0.9562686681747437], [0.10181708633899689], [0.9560256600379944], [0.10353756695985794], [0.955450177192688], [0.9069852828979492], [0.9547727108001709], [0.9168065190315247], [0.09644105285406113], [0.9524486660957336], [0.9379433393478394], [0.2564583420753479], [0.9215754270553589], [0.9557453989982605], [0.9562658667564392], [0.8970774412155151], [0.9182332754135132], [0.9520343542098999], [0.1147666946053505], [0.9523342847824097], [0.9562599658966064], [0.956120491027832], [0.9457565546035767], [0.9562678337097168], [0.9559685587882996], [0.9214677810668945], [0.30037206411361694], [0.9514943361282349], [0.9519657492637634], [0.10371842235326767], [0.9537073969841003], [0.09996802359819412], [0.9559966921806335], [0.9543655514717102], [0.9562597870826721], [0.9545580148696899], [0.9562553763389587], [0.9526520371437073], [0.9559789299964905], [0.1106175109744072], [0.9540579319000244], [0.9471656084060669], [0.9550655484199524], [0.9426611661911011], [0.9363864064216614], [0.9197137355804443], [0.9561139345169067], [0.15069274604320526], [0.956092357635498], [0.9560026526451111], [0.9557154774665833], [0.9175085425376892], [0.951265811920166], [0.9561284184455872], [0.13842163980007172], [0.09937216341495514], [0.10989800840616226], [0.9548570513725281], [0.9562641382217407], [0.9556766152381897], [0.9562661647796631], [0.9215672016143799], [0.9562066793441772], [0.9394413232803345], [0.10635394603013992], [0.9560654163360596], [0.9551129341125488], [0.952261745929718], [0.839430034160614], [0.9500377178192139], [0.9557325839996338], [0.9171674847602844], [0.10027869790792465], [0.9560277462005615], [0.9562374353408813], [0.9237852096557617], [0.9545463919639587], [0.14375628530979156], [0.9533302187919617], [0.9550303220748901], [0.954853892326355], [0.14304393529891968], [0.251492977142334], [0.9537796974182129], [0.9451618194580078], [0.9559046030044556], [0.1493358016014099], [0.9560448527336121], [0.1269024759531021], [0.9560179114341736], [0.9559454917907715], [0.9518214464187622], [0.11205010861158371], [0.954092800617218], [0.919762134552002], [0.1388138383626938], [0.12755998969078064], [0.09660816192626953], [0.11166301369667053], [0.9562573432922363], [0.11563657969236374], [0.9556180238723755], [0.1095743477344513], [0.9534503817558289], [0.9562644362449646], [0.24001646041870117], [0.9561157822608948], [0.9553329944610596], [0.11317575722932816], [0.9560363292694092], [0.9495378732681274], [0.9468692541122437], [0.3903138339519501], [0.10369372367858887], [0.9562699198722839], [0.9215744137763977], [0.16379830241203308], [0.9506780505180359], [0.9562596678733826], [0.9557543396949768], [0.956153392791748], [0.9562690258026123], [0.24019581079483032], [0.13182665407657623], [0.9553641080856323], [0.955835223197937], [0.9559444189071655], [0.9559376239776611], [0.9417334198951721], [0.9522713422775269], [0.10527385026216507], [0.9559827446937561], [0.9526593685150146], [0.9530314803123474], [0.9516342282295227], [0.9562653303146362], [0.9558374285697937], [0.954535722732544], [0.9557584524154663], [0.9546722769737244], [0.9214624166488647], [0.9514796137809753], [0.10677149146795273], [0.9535270929336548], [0.9557759165763855], [0.947913408279419], [0.9557792544364929], [0.9557245969772339], [0.95342618227005], [0.9543549418449402], [0.9518355131149292], [0.7988250255584717], [0.7429010272026062], [0.09676007926464081], [0.0997498407959938], [0.919139564037323], [0.9511817693710327], [0.9203477501869202], [0.9562596678733826], [0.9556326270103455], [0.9462593197822571], [0.10230418294668198], [0.9527381658554077], [0.9554102420806885], [0.23005498945713043], [0.9542129039764404], [0.9544019103050232], [0.9534833431243896], [0.9545942544937134], [0.9562369585037231], [0.9287796020507812], [0.9232086539268494], [0.10983342677354813], [0.9553369283676147], [0.1166154220700264], [0.7908425331115723], [0.954887866973877], [0.9559878706932068], [0.955551266670227], [0.9561323523521423], [0.955329418182373], [0.10248488187789917], [0.11410626769065857], [0.9481461048126221], [0.9560003876686096], [0.9396058917045593], [0.9173994660377502], [0.15155541896820068], [0.9550769329071045], [0.9560932517051697], [0.12396795302629471], [0.2821960151195526], [0.9497737884521484], [0.9562686681747437], [0.9211927652359009], [0.9562683701515198], [0.19760926067829132], [0.22968751192092896], [0.9535052180290222], [0.9561198949813843], [0.9559532999992371], [0.9401014447212219], [0.9542361497879028], [0.3571224510669708], [0.9555178880691528], [0.0997045710682869], [0.27808570861816406], [0.946532130241394], [0.9021197557449341], [0.9215319156646729], [0.12162517756223679], [0.9214634299278259], [0.9562562704086304], [0.6493039727210999], [0.9545470476150513], [0.9546805620193481], [0.9506136178970337], [0.9562665224075317], [0.09660813212394714], [0.9486240744590759], [0.9559571146965027], [0.9525127410888672], [0.955715000629425], [0.9416406154632568], [0.9539409875869751], [0.8939970135688782], [0.9318605661392212], [0.9408777356147766], [0.10949195921421051], [0.10592704266309738], [0.9558213353157043], [0.8028007745742798], [0.9557245969772339], [0.9555355310440063], [0.9530073404312134], [0.950332760810852], [0.9560131430625916], [0.95591801404953], [0.2782948315143585], [0.9546003937721252], [0.9545367360115051], [0.9562602043151855], [0.9521069526672363], [0.9522173404693604], [0.955561101436615], [0.956261157989502], [0.9556296467781067], [0.9557875394821167], [0.9562689065933228], [0.9551309943199158], [0.9550122618675232], [0.9462174773216248], [0.9555217027664185], [0.10260950773954391], [0.9533902406692505], [0.9538277387619019], [0.9534152746200562], [0.13915427029132843], [0.955288827419281], [0.948564350605011], [0.9562684893608093], [0.9557213187217712], [0.9538674354553223], [0.921555757522583], [0.9533249139785767], [0.9537588953971863], [0.9559224843978882], [0.12942494451999664], [0.95606529712677], [0.9562209248542786], [0.9215526580810547], [0.9561435580253601], [0.9555915594100952], [0.096616730093956], [0.9562497138977051], [0.47410428524017334], [0.9538205862045288], [0.9560286998748779], [0.9556434750556946], [0.9561891555786133], [0.643684446811676], [0.9557140469551086], [0.955758810043335], [0.9553591012954712], [0.9215284585952759], [0.9558885097503662], [0.9492861032485962], [0.9538029432296753], [0.9551088213920593], [0.10664088279008865], [0.9535711407661438], [0.9426341652870178], [0.9552776217460632], [0.15082257986068726], [0.9526585340499878], [0.9511428475379944], [0.9535673260688782], [0.955948531627655], [0.9562654495239258], [0.1178215816617012], [0.9139035940170288], [0.9214990139007568], [0.20562011003494263], [0.9562706351280212], [0.9548751711845398], [0.9526035785675049], [0.9562594294548035], [0.9556378126144409], [0.9166745543479919], [0.9555768966674805], [0.18345801532268524], [0.9468303322792053], [0.9537072777748108], [0.10706314444541931], [0.1292116791009903], [0.9555952548980713], [0.10751006752252579], [0.9562426209449768], [0.9562649726867676], [0.9215364456176758], [0.9545677900314331], [0.9559390544891357], [0.955711841583252], [0.6891747713088989], [0.952172040939331], [0.11176170408725739], [0.9534396529197693], [0.9551435112953186], [0.9514231085777283], [0.9489774703979492], [0.9549427628517151], [0.9542808532714844], [0.9562594294548035], [0.9501165151596069], [0.09858720749616623], [0.10255281627178192], [0.9557558298110962], [0.9546561241149902], [0.9556651711463928], [0.9487693905830383], [0.09896264970302582], [0.9557531476020813], [0.9524115920066833], [0.95599365234375], [0.9511489868164062], [0.14462141692638397], [0.9558629989624023], [0.9400963187217712], [0.9516227841377258], [0.9215699434280396], [0.9528711438179016], [0.9552368521690369], [0.921528160572052], [0.9562646746635437], [0.9411383271217346], [0.9020142555236816], [0.9212621450424194], [0.9562671780586243], [0.9552217125892639], [0.9521195888519287], [0.9557559490203857], [0.9040870666503906], [0.9215012192726135], [0.9215725660324097], [0.9538674354553223], [0.955641508102417], [0.9556596875190735], [0.9554041624069214], [0.9558837413787842], [0.11010825634002686], [0.6801201105117798], [0.9541850090026855], [0.9559199810028076], [0.10971066355705261], [0.9425928592681885], [0.4937863349914551], [0.9557028412818909], [0.9559026956558228], [0.9562675952911377], [0.9550407528877258], [0.9553729295730591], [0.09823841601610184], [0.9554783701896667], [0.9560698866844177], [0.9509678483009338], [0.955758810043335], [0.12261706590652466], [0.9562394022941589], [0.9554265737533569], [0.9531790018081665], [0.954887866973877], [0.9549229741096497], [0.10570897907018661], [0.9484211802482605], [0.9559532999992371], [0.1445421725511551], [0.10879386961460114], [0.10313702374696732], [0.9562684893608093], [0.9558945298194885], [0.9186843633651733], [0.9214957356452942], [0.9538830518722534], [0.9216984510421753], [0.1112791895866394], [0.950481653213501], [0.9559532999992371], [0.9562510251998901], [0.9402691125869751], [0.9553423523902893], [0.9560798406600952], [0.9553448557853699], [0.9554387331008911], [0.920163631439209], [0.9542592763900757], [0.11058596521615982], [0.15335504710674286], [0.9561296105384827], [0.9505581259727478], [0.14152371883392334], [0.9561399817466736], [0.9561319351196289], [0.9549105167388916], [0.9527629613876343], [0.8801084756851196], [0.18052558600902557], [0.9140077829360962], [0.9514222145080566], [0.9533913135528564], [0.10210368037223816], [0.9532338976860046], [0.9559528827667236], [0.9551973342895508], [0.9519826173782349], [0.9551022052764893], [0.9554457068443298], [0.951884388923645], [0.9535502791404724], [0.956257700920105], [0.9560176134109497], [0.0967264398932457], [0.9536579251289368], [0.09660816192626953], [0.10657884925603867], [0.9262223839759827], [0.10783970355987549], [0.9532505869865417], [0.955376923084259], [0.9557559490203857], [0.10489821434020996], [0.9562661051750183], [0.10872546583414078], [0.9558302164077759], [0.10380903631448746], [0.7352990508079529], [0.9558427929878235], [0.10688159614801407], [0.951327919960022], [0.9558837413787842], [0.9537555575370789], [0.9545119404792786], [0.12677867710590363], [0.9558079242706299], [0.10014677792787552], [0.9539854526519775], [0.9561396241188049], [0.9555730819702148], [0.9538733959197998], [0.9559487700462341], [0.9212861657142639], [0.10905026644468307], [0.9554783701896667], [0.23934324085712433], [0.9541959762573242], [0.1383930891752243], [0.9513658285140991], [0.9559661746025085], [0.9532568454742432], [0.9546443819999695], [0.8695794939994812], [0.9559141993522644], [0.955879807472229], [0.8953297734260559], [0.9164080619812012], [0.9560028910636902], [0.953217089176178], [0.9557139277458191], [0.9552904367446899], [0.9556453227996826], [0.956030011177063], [0.09744823724031448], [0.9529176950454712], [0.9560207724571228], [0.8391864895820618], [0.1136380210518837], [0.9215288758277893], [0.09702643752098083], [0.11437847465276718], [0.9561159014701843], [0.9560363292694092], [0.954929530620575], [0.9556904435157776], [0.123688243329525], [0.9562631249427795], [0.9560615420341492], [0.921554684638977], [0.9562632441520691], [0.9562586545944214], [0.9556122422218323], [0.10079092532396317], [0.9562126398086548], [0.11269175261259079], [0.95501309633255], [0.955778956413269], [0.9558128118515015], [0.9559603929519653]]\n"
     ]
    }
   ],
   "source": [
    "print(pred.detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068396f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
